{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T20:53:47.521798Z",
     "start_time": "2023-04-21T20:53:16.275982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip3: not found\r\n",
      "[sudo] password for yangsen: \r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gym pyvirtualdisplay\n",
    "!sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade setuptools --user\n",
    "!pip3 install ez_setup \n",
    "!pip3 install gym[atari] \n",
    "!pip3 install gym[accept-rom-license] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T21:16:53.800000Z",
     "start_time": "2023-04-21T21:16:52.259662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Yangsen/Desktop/assignment5/model.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN, DQN_LSTM\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://www.gymlibrary.dev/environments/atari/breakout/. \n",
    "\n",
    "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T21:17:24.587187Z",
     "start_time": "2023-04-21T21:17:24.362881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/home/yangsen/anaconda3/envs/py37/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/home/yangsen/anaconda3/envs/py37/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/home/yangsen/anaconda3/envs/py37/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:191: UserWarning: \u001B[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001B[0m\n",
      "  \"Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\"\n",
      "/home/yangsen/anaconda3/envs/py37/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:138: UserWarning: \u001B[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'tuple'>\u001B[0m\n",
      "  f\"{pre} was expecting a numpy array, actual type: {type(obs)}\"\n",
      "/home/yangsen/anaconda3/envs/py37/lib/python3.7/site-packages/gym/spaces/box.py:226: UserWarning: \u001B[33mWARN: Casting input x to numpy array.\u001B[0m\n",
      "  logger.warn(\"Casting input x to numpy array.\")\n",
      "/home/yangsen/anaconda3/envs/py37/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:167: UserWarning: \u001B[33mWARN: The obs returned by the `reset()` method is not within the observation space with exception: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\u001B[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space with exception: {e}\")\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "state = env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T21:17:24.845146Z",
     "start_time": "2023-04-21T21:17:24.840635Z"
    }
   },
   "outputs": [],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T00:47:52.236459Z",
     "start_time": "2023-04-22T00:47:51.937421Z"
    }
   },
   "outputs": [],
   "source": [
    "double_dqn = False # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "    from agent_double import Agent\n",
    "else:\n",
    "    from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T09:18:21.141190Z",
     "start_time": "2023-04-22T00:47:54.121777Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 2.0   memory length: 198   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 1   score: 3.0   memory length: 444   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 2   score: 1.0   memory length: 614   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 3   score: 2.0   memory length: 833   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 4   score: 0.0   memory length: 956   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 5   score: 2.0   memory length: 1153   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 6   score: 2.0   memory length: 1350   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.7142857142857142\n",
      "episode: 7   score: 5.0   memory length: 1648   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 2.125\n",
      "episode: 8   score: 3.0   memory length: 1915   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 2.2222222222222223\n",
      "episode: 9   score: 4.0   memory length: 2157   epsilon: 1.0    steps: 242    lr: 0.0001     evaluation reward: 2.4\n",
      "episode: 10   score: 2.0   memory length: 2355   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.3636363636363638\n",
      "episode: 11   score: 1.0   memory length: 2526   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 2.25\n",
      "episode: 12   score: 4.0   memory length: 2804   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 2.3846153846153846\n",
      "episode: 13   score: 0.0   memory length: 2926   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 2.2142857142857144\n",
      "episode: 14   score: 0.0   memory length: 3048   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 2.066666666666667\n",
      "episode: 15   score: 2.0   memory length: 3245   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 2.0625\n",
      "episode: 16   score: 1.0   memory length: 3414   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 17   score: 2.0   memory length: 3611   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 18   score: 1.0   memory length: 3780   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.9473684210526316\n",
      "episode: 19   score: 0.0   memory length: 3903   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 20   score: 1.0   memory length: 4075   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.8095238095238095\n",
      "episode: 21   score: 4.0   memory length: 4354   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.9090909090909092\n",
      "episode: 22   score: 1.0   memory length: 4505   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.8695652173913044\n",
      "episode: 23   score: 3.0   memory length: 4733   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.9166666666666667\n",
      "episode: 24   score: 2.0   memory length: 4952   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.92\n",
      "episode: 25   score: 1.0   memory length: 5103   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.8846153846153846\n",
      "episode: 26   score: 1.0   memory length: 5272   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.8518518518518519\n",
      "episode: 27   score: 2.0   memory length: 5493   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.8571428571428572\n",
      "episode: 28   score: 2.0   memory length: 5709   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.8620689655172413\n",
      "episode: 29   score: 1.0   memory length: 5878   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.8333333333333333\n",
      "episode: 30   score: 1.0   memory length: 6028   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.8064516129032258\n",
      "episode: 31   score: 0.0   memory length: 6150   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 32   score: 3.0   memory length: 6394   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.7878787878787878\n",
      "episode: 33   score: 1.0   memory length: 6544   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.7647058823529411\n",
      "episode: 34   score: 0.0   memory length: 6667   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7142857142857142\n",
      "episode: 35   score: 0.0   memory length: 6790   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 36   score: 0.0   memory length: 6913   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6216216216216217\n",
      "episode: 37   score: 3.0   memory length: 7175   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.6578947368421053\n",
      "episode: 38   score: 2.0   memory length: 7373   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 39   score: 2.0   memory length: 7591   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.675\n",
      "episode: 40   score: 1.0   memory length: 7759   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6585365853658536\n",
      "episode: 41   score: 2.0   memory length: 7976   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 42   score: 1.0   memory length: 8126   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.6511627906976745\n",
      "episode: 43   score: 1.0   memory length: 8277   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6363636363636365\n",
      "episode: 44   score: 1.0   memory length: 8428   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6222222222222222\n",
      "episode: 45   score: 3.0   memory length: 8696   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.6521739130434783\n",
      "episode: 46   score: 0.0   memory length: 8819   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6170212765957446\n",
      "episode: 47   score: 1.0   memory length: 8990   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6041666666666667\n",
      "episode: 48   score: 2.0   memory length: 9206   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.6122448979591837\n",
      "episode: 49   score: 1.0   memory length: 9378   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 50   score: 0.0   memory length: 9500   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5686274509803921\n",
      "episode: 51   score: 0.0   memory length: 9622   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5384615384615385\n",
      "episode: 52   score: 3.0   memory length: 9869   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.5660377358490567\n",
      "episode: 53   score: 1.0   memory length: 10020   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5555555555555556\n",
      "episode: 54   score: 2.0   memory length: 10219   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.5636363636363637\n",
      "episode: 55   score: 4.0   memory length: 10500   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.6071428571428572\n",
      "episode: 56   score: 2.0   memory length: 10679   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.6140350877192982\n",
      "episode: 57   score: 0.0   memory length: 10802   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5862068965517242\n",
      "episode: 58   score: 0.0   memory length: 10925   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5593220338983051\n",
      "episode: 59   score: 4.0   memory length: 11243   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 60   score: 0.0   memory length: 11366   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5737704918032787\n",
      "episode: 61   score: 1.0   memory length: 11535   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.564516129032258\n",
      "episode: 62   score: 3.0   memory length: 11781   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5873015873015872\n",
      "episode: 63   score: 3.0   memory length: 12046   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.609375\n",
      "episode: 64   score: 2.0   memory length: 12265   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.6153846153846154\n",
      "episode: 65   score: 2.0   memory length: 12463   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.621212121212121\n",
      "episode: 66   score: 1.0   memory length: 12631   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.6119402985074627\n",
      "episode: 67   score: 3.0   memory length: 12879   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.6323529411764706\n",
      "episode: 68   score: 1.0   memory length: 13048   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6231884057971016\n",
      "episode: 69   score: 2.0   memory length: 13264   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.6285714285714286\n",
      "episode: 70   score: 0.0   memory length: 13387   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6056338028169015\n",
      "episode: 71   score: 0.0   memory length: 13510   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5833333333333333\n",
      "episode: 72   score: 2.0   memory length: 13708   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5890410958904109\n",
      "episode: 73   score: 1.0   memory length: 13877   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5810810810810811\n",
      "episode: 74   score: 1.0   memory length: 14048   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5733333333333333\n",
      "episode: 75   score: 3.0   memory length: 14294   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5921052631578947\n",
      "episode: 76   score: 3.0   memory length: 14522   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.6103896103896105\n",
      "episode: 77   score: 0.0   memory length: 14645   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5897435897435896\n",
      "episode: 78   score: 2.0   memory length: 14843   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5949367088607596\n",
      "episode: 79   score: 4.0   memory length: 15141   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.625\n",
      "episode: 80   score: 0.0   memory length: 15263   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6049382716049383\n",
      "episode: 81   score: 0.0   memory length: 15386   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5853658536585367\n",
      "episode: 82   score: 1.0   memory length: 15556   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5783132530120483\n",
      "episode: 83   score: 3.0   memory length: 15783   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.5952380952380953\n",
      "episode: 84   score: 2.0   memory length: 15982   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 85   score: 2.0   memory length: 16182   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6046511627906976\n",
      "episode: 86   score: 1.0   memory length: 16333   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5977011494252873\n",
      "episode: 87   score: 0.0   memory length: 16456   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5795454545454546\n",
      "episode: 88   score: 1.0   memory length: 16626   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5730337078651686\n",
      "episode: 89   score: 1.0   memory length: 16797   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5666666666666667\n",
      "episode: 90   score: 0.0   memory length: 16920   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5494505494505495\n",
      "episode: 91   score: 0.0   memory length: 17043   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5326086956521738\n",
      "episode: 92   score: 0.0   memory length: 17166   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5161290322580645\n",
      "episode: 93   score: 0.0   memory length: 17288   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 94   score: 0.0   memory length: 17410   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4842105263157894\n",
      "episode: 95   score: 3.0   memory length: 17679   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 96   score: 2.0   memory length: 17898   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5051546391752577\n",
      "episode: 97   score: 2.0   memory length: 18095   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.510204081632653\n",
      "episode: 98   score: 3.0   memory length: 18321   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.5252525252525253\n",
      "episode: 99   score: 1.0   memory length: 18493   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 100   score: 3.0   memory length: 18724   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 101   score: 2.0   memory length: 18921   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 102   score: 1.0   memory length: 19090   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 103   score: 4.0   memory length: 19384   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 104   score: 1.0   memory length: 19534   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 105   score: 1.0   memory length: 19704   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 106   score: 0.0   memory length: 19826   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 107   score: 2.0   memory length: 20045   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 108   score: 2.0   memory length: 20262   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 109   score: 2.0   memory length: 20480   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 110   score: 0.0   memory length: 20603   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 111   score: 0.0   memory length: 20726   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 112   score: 1.0   memory length: 20877   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 113   score: 2.0   memory length: 21075   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 114   score: 0.0   memory length: 21197   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 115   score: 2.0   memory length: 21395   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 116   score: 0.0   memory length: 21518   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 117   score: 1.0   memory length: 21669   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 118   score: 1.0   memory length: 21837   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 119   score: 2.0   memory length: 22054   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 120   score: 2.0   memory length: 22251   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 121   score: 2.0   memory length: 22449   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 122   score: 0.0   memory length: 22571   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 123   score: 0.0   memory length: 22694   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 124   score: 1.0   memory length: 22864   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 125   score: 3.0   memory length: 23130   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 126   score: 1.0   memory length: 23280   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 127   score: 1.0   memory length: 23449   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 128   score: 1.0   memory length: 23621   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 129   score: 0.0   memory length: 23744   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 130   score: 0.0   memory length: 23866   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 131   score: 2.0   memory length: 24084   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 132   score: 0.0   memory length: 24207   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 133   score: 2.0   memory length: 24424   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 134   score: 1.0   memory length: 24595   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 135   score: 3.0   memory length: 24841   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 136   score: 2.0   memory length: 25038   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 137   score: 2.0   memory length: 25236   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 138   score: 3.0   memory length: 25483   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 139   score: 1.0   memory length: 25655   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 140   score: 2.0   memory length: 25873   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 141   score: 0.0   memory length: 25996   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 142   score: 4.0   memory length: 26272   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 143   score: 2.0   memory length: 26469   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 144   score: 2.0   memory length: 26667   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 145   score: 1.0   memory length: 26836   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 146   score: 2.0   memory length: 27053   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 147   score: 4.0   memory length: 27311   epsilon: 1.0    steps: 258    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 148   score: 1.0   memory length: 27481   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 149   score: 2.0   memory length: 27699   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 150   score: 1.0   memory length: 27870   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 151   score: 2.0   memory length: 28068   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 152   score: 0.0   memory length: 28191   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 153   score: 5.0   memory length: 28535   epsilon: 1.0    steps: 344    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 154   score: 0.0   memory length: 28658   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 155   score: 1.0   memory length: 28829   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 156   score: 2.0   memory length: 29046   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 157   score: 0.0   memory length: 29169   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 158   score: 0.0   memory length: 29292   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 159   score: 0.0   memory length: 29415   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 160   score: 3.0   memory length: 29662   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 161   score: 3.0   memory length: 29893   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 162   score: 1.0   memory length: 30044   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 163   score: 1.0   memory length: 30194   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 164   score: 2.0   memory length: 30391   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 165   score: 1.0   memory length: 30560   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 166   score: 2.0   memory length: 30777   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 167   score: 3.0   memory length: 31003   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 168   score: 1.0   memory length: 31172   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 169   score: 0.0   memory length: 31295   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 170   score: 1.0   memory length: 31463   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 171   score: 1.0   memory length: 31631   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 172   score: 2.0   memory length: 31847   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 173   score: 1.0   memory length: 32017   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 174   score: 0.0   memory length: 32140   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 175   score: 0.0   memory length: 32263   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 176   score: 4.0   memory length: 32523   epsilon: 1.0    steps: 260    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 177   score: 2.0   memory length: 32720   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 178   score: 2.0   memory length: 32941   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 179   score: 0.0   memory length: 33064   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 180   score: 0.0   memory length: 33186   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 181   score: 1.0   memory length: 33358   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 182   score: 2.0   memory length: 33556   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 183   score: 0.0   memory length: 33679   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 184   score: 2.0   memory length: 33894   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 185   score: 2.0   memory length: 34091   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 186   score: 0.0   memory length: 34214   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 187   score: 0.0   memory length: 34337   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 188   score: 1.0   memory length: 34487   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 189   score: 4.0   memory length: 34775   epsilon: 1.0    steps: 288    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 190   score: 2.0   memory length: 34973   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 191   score: 0.0   memory length: 35096   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 192   score: 1.0   memory length: 35264   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 193   score: 0.0   memory length: 35387   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 194   score: 1.0   memory length: 35538   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 195   score: 4.0   memory length: 35813   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 196   score: 2.0   memory length: 36032   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 197   score: 0.0   memory length: 36154   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 198   score: 3.0   memory length: 36419   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 199   score: 0.0   memory length: 36542   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 200   score: 1.0   memory length: 36693   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 201   score: 0.0   memory length: 36816   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 202   score: 1.0   memory length: 36967   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 203   score: 0.0   memory length: 37089   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 204   score: 0.0   memory length: 37211   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 205   score: 1.0   memory length: 37361   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 206   score: 2.0   memory length: 37558   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 207   score: 1.0   memory length: 37727   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 208   score: 0.0   memory length: 37850   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 209   score: 2.0   memory length: 38068   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 210   score: 0.0   memory length: 38191   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 211   score: 1.0   memory length: 38341   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 212   score: 1.0   memory length: 38509   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 213   score: 1.0   memory length: 38660   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 214   score: 3.0   memory length: 38891   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 215   score: 0.0   memory length: 39014   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 216   score: 1.0   memory length: 39183   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 217   score: 2.0   memory length: 39401   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 218   score: 2.0   memory length: 39599   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 219   score: 0.0   memory length: 39722   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 220   score: 0.0   memory length: 39845   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 221   score: 1.0   memory length: 39995   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 222   score: 3.0   memory length: 40260   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 223   score: 0.0   memory length: 40383   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 224   score: 0.0   memory length: 40506   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 225   score: 2.0   memory length: 40724   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 226   score: 1.0   memory length: 40875   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 227   score: 2.0   memory length: 41075   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 228   score: 3.0   memory length: 41320   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 229   score: 1.0   memory length: 41489   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 230   score: 2.0   memory length: 41687   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 231   score: 1.0   memory length: 41856   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 232   score: 0.0   memory length: 41978   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 233   score: 1.0   memory length: 42128   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 234   score: 1.0   memory length: 42298   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 235   score: 3.0   memory length: 42566   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 236   score: 1.0   memory length: 42737   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 237   score: 1.0   memory length: 42907   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 238   score: 1.0   memory length: 43075   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 239   score: 0.0   memory length: 43198   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 240   score: 2.0   memory length: 43395   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 241   score: 3.0   memory length: 43663   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 242   score: 4.0   memory length: 43940   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 243   score: 0.0   memory length: 44062   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 244   score: 1.0   memory length: 44231   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 245   score: 0.0   memory length: 44354   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 246   score: 3.0   memory length: 44604   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 247   score: 1.0   memory length: 44772   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 248   score: 0.0   memory length: 44895   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 249   score: 3.0   memory length: 45161   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 250   score: 0.0   memory length: 45284   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 251   score: 0.0   memory length: 45407   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 252   score: 3.0   memory length: 45651   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 253   score: 3.0   memory length: 45917   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 254   score: 0.0   memory length: 46040   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 255   score: 2.0   memory length: 46257   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 256   score: 4.0   memory length: 46533   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 257   score: 2.0   memory length: 46751   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 258   score: 4.0   memory length: 47025   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 259   score: 2.0   memory length: 47244   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 260   score: 0.0   memory length: 47366   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 261   score: 4.0   memory length: 47635   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 262   score: 2.0   memory length: 47852   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 263   score: 3.0   memory length: 48120   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 264   score: 2.0   memory length: 48335   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 265   score: 3.0   memory length: 48563   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 266   score: 0.0   memory length: 48686   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 267   score: 0.0   memory length: 48809   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 268   score: 2.0   memory length: 49007   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 269   score: 1.0   memory length: 49157   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 270   score: 1.0   memory length: 49307   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 271   score: 1.0   memory length: 49457   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 272   score: 4.0   memory length: 49731   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 273   score: 2.0   memory length: 49948   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 274   score: 2.0   memory length: 50146   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 275   score: 0.0   memory length: 50269   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 276   score: 4.0   memory length: 50528   epsilon: 1.0    steps: 259    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 277   score: 1.0   memory length: 50678   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 278   score: 2.0   memory length: 50876   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 279   score: 2.0   memory length: 51092   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 280   score: 1.0   memory length: 51262   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 281   score: 0.0   memory length: 51385   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 282   score: 2.0   memory length: 51603   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 283   score: 0.0   memory length: 51725   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 284   score: 3.0   memory length: 51974   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 285   score: 4.0   memory length: 52271   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 286   score: 2.0   memory length: 52452   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 287   score: 2.0   memory length: 52650   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 288   score: 2.0   memory length: 52848   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 289   score: 0.0   memory length: 52971   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 290   score: 0.0   memory length: 53093   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 291   score: 1.0   memory length: 53262   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 292   score: 3.0   memory length: 53525   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 293   score: 4.0   memory length: 53844   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 294   score: 0.0   memory length: 53967   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 295   score: 1.0   memory length: 54138   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 296   score: 2.0   memory length: 54354   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 297   score: 2.0   memory length: 54572   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 298   score: 1.0   memory length: 54723   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 299   score: 0.0   memory length: 54846   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 300   score: 2.0   memory length: 55063   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 301   score: 2.0   memory length: 55281   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 302   score: 2.0   memory length: 55499   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 303   score: 0.0   memory length: 55622   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 304   score: 2.0   memory length: 55840   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 305   score: 2.0   memory length: 56022   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 306   score: 2.0   memory length: 56241   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 307   score: 3.0   memory length: 56490   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 308   score: 4.0   memory length: 56765   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 309   score: 1.0   memory length: 56934   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 310   score: 1.0   memory length: 57105   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 311   score: 3.0   memory length: 57331   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 312   score: 2.0   memory length: 57528   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 313   score: 5.0   memory length: 57820   epsilon: 1.0    steps: 292    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 314   score: 0.0   memory length: 57943   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 315   score: 1.0   memory length: 58113   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 316   score: 1.0   memory length: 58285   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 317   score: 0.0   memory length: 58408   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 318   score: 2.0   memory length: 58606   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 319   score: 3.0   memory length: 58879   epsilon: 1.0    steps: 273    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 320   score: 1.0   memory length: 59047   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 321   score: 4.0   memory length: 59342   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 322   score: 1.0   memory length: 59511   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 323   score: 0.0   memory length: 59634   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 324   score: 1.0   memory length: 59802   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 325   score: 3.0   memory length: 60046   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 326   score: 0.0   memory length: 60168   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 327   score: 2.0   memory length: 60389   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 328   score: 0.0   memory length: 60512   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 329   score: 0.0   memory length: 60635   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 330   score: 1.0   memory length: 60804   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 331   score: 2.0   memory length: 60985   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 332   score: 3.0   memory length: 61235   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 333   score: 1.0   memory length: 61387   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 334   score: 1.0   memory length: 61538   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 335   score: 2.0   memory length: 61736   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 336   score: 3.0   memory length: 62003   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 337   score: 0.0   memory length: 62125   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 338   score: 0.0   memory length: 62247   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 339   score: 1.0   memory length: 62418   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 340   score: 1.0   memory length: 62568   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 341   score: 1.0   memory length: 62718   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 342   score: 5.0   memory length: 63022   epsilon: 1.0    steps: 304    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 343   score: 2.0   memory length: 63221   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 344   score: 1.0   memory length: 63392   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 345   score: 1.0   memory length: 63562   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 346   score: 2.0   memory length: 63778   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 347   score: 1.0   memory length: 63947   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 348   score: 2.0   memory length: 64129   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 349   score: 1.0   memory length: 64280   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 350   score: 2.0   memory length: 64478   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 351   score: 3.0   memory length: 64743   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 352   score: 1.0   memory length: 64913   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 353   score: 2.0   memory length: 65111   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 354   score: 2.0   memory length: 65329   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 355   score: 1.0   memory length: 65480   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 356   score: 2.0   memory length: 65681   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 357   score: 2.0   memory length: 65878   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 358   score: 2.0   memory length: 66076   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 359   score: 1.0   memory length: 66226   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 360   score: 0.0   memory length: 66349   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 361   score: 3.0   memory length: 66577   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 362   score: 1.0   memory length: 66727   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 363   score: 1.0   memory length: 66896   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 364   score: 0.0   memory length: 67018   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 365   score: 1.0   memory length: 67188   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 366   score: 1.0   memory length: 67358   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 367   score: 0.0   memory length: 67481   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 368   score: 4.0   memory length: 67763   epsilon: 1.0    steps: 282    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 369   score: 2.0   memory length: 67961   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 370   score: 2.0   memory length: 68159   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 371   score: 2.0   memory length: 68356   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 372   score: 0.0   memory length: 68478   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 373   score: 2.0   memory length: 68675   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 374   score: 3.0   memory length: 68918   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 375   score: 0.0   memory length: 69041   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 376   score: 1.0   memory length: 69191   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 377   score: 2.0   memory length: 69388   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 378   score: 1.0   memory length: 69539   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 379   score: 1.0   memory length: 69708   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 380   score: 2.0   memory length: 69905   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 381   score: 1.0   memory length: 70056   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 382   score: 0.0   memory length: 70179   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 383   score: 1.0   memory length: 70348   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 384   score: 2.0   memory length: 70567   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 385   score: 3.0   memory length: 70814   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 386   score: 3.0   memory length: 71061   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 387   score: 2.0   memory length: 71277   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 388   score: 3.0   memory length: 71545   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 389   score: 3.0   memory length: 71813   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 390   score: 0.0   memory length: 71936   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 391   score: 1.0   memory length: 72087   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 392   score: 3.0   memory length: 72312   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 393   score: 4.0   memory length: 72606   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 394   score: 0.0   memory length: 72729   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 395   score: 1.0   memory length: 72900   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 396   score: 0.0   memory length: 73022   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 397   score: 1.0   memory length: 73191   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 398   score: 2.0   memory length: 73410   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 399   score: 0.0   memory length: 73533   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 400   score: 2.0   memory length: 73733   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 401   score: 1.0   memory length: 73884   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 402   score: 1.0   memory length: 74035   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 403   score: 0.0   memory length: 74158   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 404   score: 3.0   memory length: 74372   epsilon: 1.0    steps: 214    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 405   score: 0.0   memory length: 74495   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 406   score: 0.0   memory length: 74618   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 407   score: 1.0   memory length: 74790   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 408   score: 0.0   memory length: 74912   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 409   score: 0.0   memory length: 75035   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 410   score: 1.0   memory length: 75207   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 411   score: 1.0   memory length: 75376   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 412   score: 0.0   memory length: 75499   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 413   score: 0.0   memory length: 75622   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 414   score: 1.0   memory length: 75772   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 415   score: 1.0   memory length: 75940   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 416   score: 1.0   memory length: 76112   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 417   score: 2.0   memory length: 76311   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 418   score: 3.0   memory length: 76558   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 419   score: 3.0   memory length: 76766   epsilon: 1.0    steps: 208    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 420   score: 0.0   memory length: 76889   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 421   score: 1.0   memory length: 77040   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 422   score: 1.0   memory length: 77191   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 423   score: 0.0   memory length: 77314   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 424   score: 0.0   memory length: 77437   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 425   score: 3.0   memory length: 77649   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 426   score: 2.0   memory length: 77847   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 427   score: 0.0   memory length: 77969   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 428   score: 3.0   memory length: 78197   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 429   score: 1.0   memory length: 78348   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 430   score: 1.0   memory length: 78517   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 431   score: 3.0   memory length: 78785   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 432   score: 2.0   memory length: 78964   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 433   score: 3.0   memory length: 79211   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 434   score: 2.0   memory length: 79429   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 435   score: 1.0   memory length: 79598   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 436   score: 2.0   memory length: 79796   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 437   score: 2.0   memory length: 79982   epsilon: 1.0    steps: 186    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 438   score: 1.0   memory length: 80154   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 439   score: 2.0   memory length: 80372   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 440   score: 0.0   memory length: 80495   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 441   score: 1.0   memory length: 80664   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 442   score: 2.0   memory length: 80862   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 443   score: 1.0   memory length: 81033   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 444   score: 1.0   memory length: 81183   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 445   score: 7.0   memory length: 81603   epsilon: 1.0    steps: 420    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 446   score: 1.0   memory length: 81772   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 447   score: 3.0   memory length: 82001   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 448   score: 1.0   memory length: 82172   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 449   score: 2.0   memory length: 82388   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 450   score: 0.0   memory length: 82511   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 451   score: 1.0   memory length: 82662   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 452   score: 2.0   memory length: 82877   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 453   score: 5.0   memory length: 83157   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 454   score: 2.0   memory length: 83355   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 455   score: 0.0   memory length: 83478   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 456   score: 0.0   memory length: 83601   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 457   score: 3.0   memory length: 83845   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 458   score: 1.0   memory length: 84016   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 459   score: 0.0   memory length: 84139   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 460   score: 2.0   memory length: 84358   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 461   score: 5.0   memory length: 84681   epsilon: 1.0    steps: 323    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 462   score: 0.0   memory length: 84803   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 463   score: 3.0   memory length: 85050   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 464   score: 0.0   memory length: 85173   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 465   score: 1.0   memory length: 85324   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 466   score: 1.0   memory length: 85475   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 467   score: 0.0   memory length: 85597   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 468   score: 1.0   memory length: 85766   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 469   score: 1.0   memory length: 85917   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 470   score: 2.0   memory length: 86114   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 471   score: 2.0   memory length: 86335   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 472   score: 2.0   memory length: 86532   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 473   score: 3.0   memory length: 86745   epsilon: 1.0    steps: 213    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 474   score: 3.0   memory length: 87011   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 475   score: 3.0   memory length: 87238   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 476   score: 1.0   memory length: 87408   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 477   score: 4.0   memory length: 87705   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 478   score: 0.0   memory length: 87828   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 479   score: 2.0   memory length: 88026   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 480   score: 0.0   memory length: 88149   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 481   score: 1.0   memory length: 88300   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 482   score: 2.0   memory length: 88498   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 483   score: 1.0   memory length: 88667   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 484   score: 3.0   memory length: 88898   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 485   score: 0.0   memory length: 89021   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 486   score: 2.0   memory length: 89220   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 487   score: 1.0   memory length: 89390   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 488   score: 2.0   memory length: 89588   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 489   score: 1.0   memory length: 89756   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 490   score: 2.0   memory length: 89974   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 491   score: 1.0   memory length: 90124   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 492   score: 2.0   memory length: 90322   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 493   score: 0.0   memory length: 90445   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 494   score: 2.0   memory length: 90643   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 495   score: 3.0   memory length: 90892   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 496   score: 0.0   memory length: 91015   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 497   score: 3.0   memory length: 91241   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 498   score: 3.0   memory length: 91490   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 499   score: 3.0   memory length: 91735   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 500   score: 2.0   memory length: 91932   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 501   score: 2.0   memory length: 92152   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 502   score: 0.0   memory length: 92274   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 503   score: 1.0   memory length: 92425   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 504   score: 0.0   memory length: 92548   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 505   score: 1.0   memory length: 92717   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 506   score: 0.0   memory length: 92840   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 507   score: 0.0   memory length: 92962   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 508   score: 0.0   memory length: 93085   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 509   score: 0.0   memory length: 93208   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 510   score: 0.0   memory length: 93331   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 511   score: 0.0   memory length: 93454   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 512   score: 0.0   memory length: 93577   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 513   score: 2.0   memory length: 93794   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 514   score: 2.0   memory length: 94012   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 515   score: 0.0   memory length: 94135   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 516   score: 2.0   memory length: 94333   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 517   score: 3.0   memory length: 94559   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 518   score: 1.0   memory length: 94710   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 519   score: 3.0   memory length: 94936   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 520   score: 1.0   memory length: 95104   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 521   score: 0.0   memory length: 95226   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 522   score: 1.0   memory length: 95394   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 523   score: 1.0   memory length: 95544   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 524   score: 3.0   memory length: 95790   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 525   score: 3.0   memory length: 96015   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 526   score: 3.0   memory length: 96243   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 527   score: 0.0   memory length: 96366   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 528   score: 3.0   memory length: 96613   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 529   score: 0.0   memory length: 96736   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 530   score: 0.0   memory length: 96859   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 531   score: 0.0   memory length: 96981   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 532   score: 2.0   memory length: 97178   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 533   score: 0.0   memory length: 97300   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 534   score: 3.0   memory length: 97526   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 535   score: 3.0   memory length: 97772   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 536   score: 1.0   memory length: 97944   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 537   score: 2.0   memory length: 98142   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 538   score: 3.0   memory length: 98386   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 539   score: 1.0   memory length: 98555   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 540   score: 2.0   memory length: 98775   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 541   score: 0.0   memory length: 98897   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 542   score: 1.0   memory length: 99066   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 543   score: 2.0   memory length: 99264   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 544   score: 0.0   memory length: 99387   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 545   score: 1.0   memory length: 99538   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 546   score: 0.0   memory length: 99661   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 547   score: 1.0   memory length: 99811   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 548   score: 4.0   memory length: 100068   epsilon: 0.999863380000003    steps: 257    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 549   score: 3.0   memory length: 100332   epsilon: 0.9993406600000143    steps: 264    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 550   score: 1.0   memory length: 100501   epsilon: 0.9990060400000216    steps: 169    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 551   score: 0.0   memory length: 100624   epsilon: 0.9987625000000269    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 552   score: 1.0   memory length: 100774   epsilon: 0.9984655000000333    steps: 150    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 553   score: 1.0   memory length: 100945   epsilon: 0.9981269200000407    steps: 171    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 554   score: 3.0   memory length: 101193   epsilon: 0.9976358800000513    steps: 248    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 555   score: 3.0   memory length: 101419   epsilon: 0.997188400000061    steps: 226    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 556   score: 1.0   memory length: 101591   epsilon: 0.9968478400000684    steps: 172    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 557   score: 0.0   memory length: 101713   epsilon: 0.9966062800000737    steps: 122    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 558   score: 0.0   memory length: 101836   epsilon: 0.996362740000079    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 559   score: 3.0   memory length: 102083   epsilon: 0.9958736800000896    steps: 247    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 560   score: 1.0   memory length: 102254   epsilon: 0.9955351000000969    steps: 171    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 561   score: 1.0   memory length: 102422   epsilon: 0.9952024600001041    steps: 168    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 562   score: 1.0   memory length: 102591   epsilon: 0.9948678400001114    steps: 169    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 563   score: 0.0   memory length: 102714   epsilon: 0.9946243000001167    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 564   score: 3.0   memory length: 102959   epsilon: 0.9941392000001272    steps: 245    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 565   score: 1.0   memory length: 103130   epsilon: 0.9938006200001346    steps: 171    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 566   score: 1.0   memory length: 103281   epsilon: 0.9935016400001411    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 567   score: 2.0   memory length: 103478   epsilon: 0.9931115800001495    steps: 197    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 568   score: 0.0   memory length: 103600   epsilon: 0.9928700200001548    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 569   score: 1.0   memory length: 103771   epsilon: 0.9925314400001621    steps: 171    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 570   score: 0.0   memory length: 103893   epsilon: 0.9922898800001674    steps: 122    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 571   score: 4.0   memory length: 104188   epsilon: 0.9917057800001801    steps: 295    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 572   score: 1.0   memory length: 104357   epsilon: 0.9913711600001873    steps: 169    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 573   score: 0.0   memory length: 104480   epsilon: 0.9911276200001926    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 574   score: 1.0   memory length: 104632   epsilon: 0.9908266600001991    steps: 152    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 575   score: 1.0   memory length: 104802   epsilon: 0.9904900600002065    steps: 170    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 576   score: 1.0   memory length: 104974   epsilon: 0.9901495000002138    steps: 172    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 577   score: 0.0   memory length: 105097   epsilon: 0.9899059600002191    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 578   score: 2.0   memory length: 105294   epsilon: 0.9895159000002276    steps: 197    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 579   score: 2.0   memory length: 105494   epsilon: 0.9891199000002362    steps: 200    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 580   score: 2.0   memory length: 105673   epsilon: 0.9887654800002439    steps: 179    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 581   score: 0.0   memory length: 105796   epsilon: 0.9885219400002492    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 582   score: 3.0   memory length: 106043   epsilon: 0.9880328800002598    steps: 247    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 583   score: 1.0   memory length: 106194   epsilon: 0.9877339000002663    steps: 151    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 584   score: 0.0   memory length: 106317   epsilon: 0.9874903600002716    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 585   score: 1.0   memory length: 106468   epsilon: 0.9871913800002781    steps: 151    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 586   score: 2.0   memory length: 106666   epsilon: 0.9867993400002866    steps: 198    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 587   score: 0.0   memory length: 106789   epsilon: 0.9865558000002919    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 588   score: 0.0   memory length: 106912   epsilon: 0.9863122600002971    steps: 123    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 589   score: 1.0   memory length: 107063   epsilon: 0.9860132800003036    steps: 151    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 590   score: 3.0   memory length: 107288   epsilon: 0.9855677800003133    steps: 225    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 591   score: 1.0   memory length: 107457   epsilon: 0.9852331600003206    steps: 169    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 592   score: 0.0   memory length: 107579   epsilon: 0.9849916000003258    steps: 122    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 593   score: 0.0   memory length: 107702   epsilon: 0.9847480600003311    steps: 123    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 594   score: 0.0   memory length: 107825   epsilon: 0.9845045200003364    steps: 123    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 595   score: 1.0   memory length: 107994   epsilon: 0.9841699000003437    steps: 169    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 596   score: 3.0   memory length: 108221   epsilon: 0.9837204400003534    steps: 227    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 597   score: 0.0   memory length: 108343   epsilon: 0.9834788800003587    steps: 122    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 598   score: 2.0   memory length: 108540   epsilon: 0.9830888200003671    steps: 197    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 599   score: 1.0   memory length: 108712   epsilon: 0.9827482600003745    steps: 172    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 600   score: 1.0   memory length: 108863   epsilon: 0.982449280000381    steps: 151    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 601   score: 0.0   memory length: 108986   epsilon: 0.9822057400003863    steps: 123    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 602   score: 2.0   memory length: 109184   epsilon: 0.9818137000003948    steps: 198    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 603   score: 0.0   memory length: 109306   epsilon: 0.9815721400004    steps: 122    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 604   score: 1.0   memory length: 109457   epsilon: 0.9812731600004065    steps: 151    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 605   score: 0.0   memory length: 109580   epsilon: 0.9810296200004118    steps: 123    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 606   score: 2.0   memory length: 109797   epsilon: 0.9805999600004212    steps: 217    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 607   score: 0.0   memory length: 109920   epsilon: 0.9803564200004264    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 608   score: 2.0   memory length: 110138   epsilon: 0.9799247800004358    steps: 218    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 609   score: 2.0   memory length: 110335   epsilon: 0.9795347200004443    steps: 197    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 610   score: 2.0   memory length: 110533   epsilon: 0.9791426800004528    steps: 198    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 611   score: 3.0   memory length: 110761   epsilon: 0.9786912400004626    steps: 228    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 612   score: 2.0   memory length: 110959   epsilon: 0.9782992000004711    steps: 198    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 613   score: 0.0   memory length: 111081   epsilon: 0.9780576400004763    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 614   score: 1.0   memory length: 111253   epsilon: 0.9777170800004837    steps: 172    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 615   score: 3.0   memory length: 111496   epsilon: 0.9772359400004942    steps: 243    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 616   score: 1.0   memory length: 111665   epsilon: 0.9769013200005014    steps: 169    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 617   score: 0.0   memory length: 111787   epsilon: 0.9766597600005067    steps: 122    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 618   score: 0.0   memory length: 111909   epsilon: 0.9764182000005119    steps: 122    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 619   score: 0.0   memory length: 112032   epsilon: 0.9761746600005172    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 620   score: 0.0   memory length: 112155   epsilon: 0.9759311200005225    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 621   score: 2.0   memory length: 112353   epsilon: 0.975539080000531    steps: 198    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 622   score: 1.0   memory length: 112504   epsilon: 0.9752401000005375    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 623   score: 0.0   memory length: 112627   epsilon: 0.9749965600005428    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 624   score: 1.0   memory length: 112795   epsilon: 0.97466392000055    steps: 168    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 625   score: 1.0   memory length: 112965   epsilon: 0.9743273200005573    steps: 170    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 626   score: 1.0   memory length: 113117   epsilon: 0.9740263600005639    steps: 152    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 627   score: 0.0   memory length: 113240   epsilon: 0.9737828200005691    steps: 123    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 628   score: 1.0   memory length: 113410   epsilon: 0.9734462200005765    steps: 170    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 629   score: 0.0   memory length: 113533   epsilon: 0.9732026800005817    steps: 123    lr: 0.0001     evaluation reward: 1.15\n",
      "episode: 630   score: 1.0   memory length: 113704   epsilon: 0.9728641000005891    steps: 171    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 631   score: 2.0   memory length: 113920   epsilon: 0.9724364200005984    steps: 216    lr: 0.0001     evaluation reward: 1.18\n",
      "episode: 632   score: 1.0   memory length: 114070   epsilon: 0.9721394200006048    steps: 150    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 633   score: 2.0   memory length: 114268   epsilon: 0.9717473800006133    steps: 198    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 634   score: 4.0   memory length: 114564   epsilon: 0.9711613000006261    steps: 296    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 635   score: 6.0   memory length: 114940   epsilon: 0.9704168200006422    steps: 376    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 636   score: 0.0   memory length: 115063   epsilon: 0.9701732800006475    steps: 123    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 637   score: 0.0   memory length: 115186   epsilon: 0.9699297400006528    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 638   score: 0.0   memory length: 115309   epsilon: 0.9696862000006581    steps: 123    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 639   score: 4.0   memory length: 115601   epsilon: 0.9691080400006706    steps: 292    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 640   score: 1.0   memory length: 115772   epsilon: 0.968769460000678    steps: 171    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 641   score: 0.0   memory length: 115895   epsilon: 0.9685259200006833    steps: 123    lr: 0.0001     evaluation reward: 1.19\n",
      "episode: 642   score: 2.0   memory length: 116095   epsilon: 0.9681299200006919    steps: 200    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 643   score: 2.0   memory length: 116315   epsilon: 0.9676943200007013    steps: 220    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 644   score: 2.0   memory length: 116516   epsilon: 0.96729634000071    steps: 201    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 645   score: 2.0   memory length: 116735   epsilon: 0.9668627200007194    steps: 219    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 646   score: 1.0   memory length: 116886   epsilon: 0.9665637400007259    steps: 151    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 647   score: 1.0   memory length: 117038   epsilon: 0.9662627800007324    steps: 152    lr: 0.0001     evaluation reward: 1.24\n",
      "episode: 648   score: 3.0   memory length: 117283   epsilon: 0.9657776800007429    steps: 245    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 649   score: 0.0   memory length: 117405   epsilon: 0.9655361200007482    steps: 122    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 650   score: 1.0   memory length: 117577   epsilon: 0.9651955600007556    steps: 172    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 651   score: 1.0   memory length: 117746   epsilon: 0.9648609400007628    steps: 169    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 652   score: 1.0   memory length: 117914   epsilon: 0.9645283000007701    steps: 168    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 653   score: 0.0   memory length: 118037   epsilon: 0.9642847600007753    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 654   score: 0.0   memory length: 118159   epsilon: 0.9640432000007806    steps: 122    lr: 0.0001     evaluation reward: 1.17\n",
      "episode: 655   score: 2.0   memory length: 118360   epsilon: 0.9636452200007892    steps: 201    lr: 0.0001     evaluation reward: 1.16\n",
      "episode: 656   score: 5.0   memory length: 118702   epsilon: 0.9629680600008039    steps: 342    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 657   score: 2.0   memory length: 118921   epsilon: 0.9625344400008133    steps: 219    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 658   score: 1.0   memory length: 119090   epsilon: 0.9621998200008206    steps: 169    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 659   score: 1.0   memory length: 119241   epsilon: 0.9619008400008271    steps: 151    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 660   score: 2.0   memory length: 119460   epsilon: 0.9614672200008365    steps: 219    lr: 0.0001     evaluation reward: 1.22\n",
      "episode: 661   score: 0.0   memory length: 119582   epsilon: 0.9612256600008418    steps: 122    lr: 0.0001     evaluation reward: 1.21\n",
      "episode: 662   score: 3.0   memory length: 119827   epsilon: 0.9607405600008523    steps: 245    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 663   score: 0.0   memory length: 119950   epsilon: 0.9604970200008576    steps: 123    lr: 0.0001     evaluation reward: 1.23\n",
      "episode: 664   score: 5.0   memory length: 120274   epsilon: 0.9598555000008715    steps: 324    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 665   score: 2.0   memory length: 120493   epsilon: 0.9594218800008809    steps: 219    lr: 0.0001     evaluation reward: 1.26\n",
      "episode: 666   score: 2.0   memory length: 120711   epsilon: 0.9589902400008903    steps: 218    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 667   score: 4.0   memory length: 120989   epsilon: 0.9584398000009022    steps: 278    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 668   score: 0.0   memory length: 121111   epsilon: 0.9581982400009075    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 669   score: 2.0   memory length: 121328   epsilon: 0.9577685800009168    steps: 217    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 670   score: 1.0   memory length: 121497   epsilon: 0.9574339600009241    steps: 169    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 671   score: 1.0   memory length: 121666   epsilon: 0.9570993400009313    steps: 169    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 672   score: 1.0   memory length: 121837   epsilon: 0.9567607600009387    steps: 171    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 673   score: 1.0   memory length: 122008   epsilon: 0.956422180000946    steps: 171    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 674   score: 2.0   memory length: 122206   epsilon: 0.9560301400009545    steps: 198    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 675   score: 4.0   memory length: 122499   epsilon: 0.9554500000009671    steps: 293    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 676   score: 0.0   memory length: 122622   epsilon: 0.9552064600009724    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 677   score: 0.0   memory length: 122744   epsilon: 0.9549649000009777    steps: 122    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 678   score: 0.0   memory length: 122866   epsilon: 0.9547233400009829    steps: 122    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 679   score: 3.0   memory length: 123092   epsilon: 0.9542758600009926    steps: 226    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 680   score: 1.0   memory length: 123263   epsilon: 0.953937280001    steps: 171    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 681   score: 2.0   memory length: 123442   epsilon: 0.9535828600010077    steps: 179    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 682   score: 0.0   memory length: 123564   epsilon: 0.9533413000010129    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 683   score: 5.0   memory length: 123896   epsilon: 0.9526839400010272    steps: 332    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 684   score: 3.0   memory length: 124141   epsilon: 0.9521988400010377    steps: 245    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 685   score: 1.0   memory length: 124311   epsilon: 0.951862240001045    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 686   score: 1.0   memory length: 124462   epsilon: 0.9515632600010515    steps: 151    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 687   score: 0.0   memory length: 124584   epsilon: 0.9513217000010568    steps: 122    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 688   score: 0.0   memory length: 124707   epsilon: 0.951078160001062    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 689   score: 1.0   memory length: 124858   epsilon: 0.9507791800010685    steps: 151    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 690   score: 3.0   memory length: 125107   epsilon: 0.9502861600010792    steps: 249    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 691   score: 3.0   memory length: 125377   epsilon: 0.9497515600010908    steps: 270    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 692   score: 3.0   memory length: 125622   epsilon: 0.9492664600011014    steps: 245    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 693   score: 2.0   memory length: 125820   epsilon: 0.9488744200011099    steps: 198    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 694   score: 0.0   memory length: 125943   epsilon: 0.9486308800011152    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 695   score: 0.0   memory length: 126066   epsilon: 0.9483873400011205    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 696   score: 4.0   memory length: 126360   epsilon: 0.9478052200011331    steps: 294    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 697   score: 1.0   memory length: 126511   epsilon: 0.9475062400011396    steps: 151    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 698   score: 3.0   memory length: 126737   epsilon: 0.9470587600011493    steps: 226    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 699   score: 2.0   memory length: 126954   epsilon: 0.9466291000011586    steps: 217    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 700   score: 3.0   memory length: 127202   epsilon: 0.9461380600011693    steps: 248    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 701   score: 1.0   memory length: 127354   epsilon: 0.9458371000011758    steps: 152    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 702   score: 3.0   memory length: 127599   epsilon: 0.9453520000011864    steps: 245    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 703   score: 2.0   memory length: 127815   epsilon: 0.9449243200011956    steps: 216    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 704   score: 1.0   memory length: 127986   epsilon: 0.944585740001203    steps: 171    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 705   score: 1.0   memory length: 128137   epsilon: 0.9442867600012095    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 706   score: 1.0   memory length: 128288   epsilon: 0.943987780001216    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 707   score: 4.0   memory length: 128563   epsilon: 0.9434432800012278    steps: 275    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 708   score: 1.0   memory length: 128731   epsilon: 0.943110640001235    steps: 168    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 709   score: 2.0   memory length: 128929   epsilon: 0.9427186000012435    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 710   score: 2.0   memory length: 129129   epsilon: 0.9423226000012521    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 711   score: 2.0   memory length: 129327   epsilon: 0.9419305600012606    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 712   score: 2.0   memory length: 129545   epsilon: 0.94149892000127    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 713   score: 3.0   memory length: 129796   epsilon: 0.9410019400012808    steps: 251    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 714   score: 0.0   memory length: 129919   epsilon: 0.9407584000012861    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 715   score: 1.0   memory length: 130088   epsilon: 0.9404237800012933    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 716   score: 0.0   memory length: 130210   epsilon: 0.9401822200012986    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 717   score: 0.0   memory length: 130333   epsilon: 0.9399386800013039    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 718   score: 1.0   memory length: 130504   epsilon: 0.9396001000013112    steps: 171    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 719   score: 1.0   memory length: 130655   epsilon: 0.9393011200013177    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 720   score: 3.0   memory length: 130923   epsilon: 0.9387704800013292    steps: 268    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 721   score: 0.0   memory length: 131046   epsilon: 0.9385269400013345    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 722   score: 1.0   memory length: 131215   epsilon: 0.9381923200013418    steps: 169    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 723   score: 0.0   memory length: 131338   epsilon: 0.9379487800013471    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 724   score: 0.0   memory length: 131460   epsilon: 0.9377072200013523    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 725   score: 0.0   memory length: 131583   epsilon: 0.9374636800013576    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 726   score: 1.0   memory length: 131752   epsilon: 0.9371290600013649    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 727   score: 4.0   memory length: 132041   epsilon: 0.9365568400013773    steps: 289    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 728   score: 0.0   memory length: 132163   epsilon: 0.9363152800013825    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 729   score: 2.0   memory length: 132382   epsilon: 0.935881660001392    steps: 219    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 730   score: 1.0   memory length: 132533   epsilon: 0.9355826800013984    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 731   score: 0.0   memory length: 132655   epsilon: 0.9353411200014037    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 732   score: 4.0   memory length: 132952   epsilon: 0.9347530600014164    steps: 297    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 733   score: 3.0   memory length: 133199   epsilon: 0.9342640000014271    steps: 247    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 734   score: 2.0   memory length: 133396   epsilon: 0.9338739400014355    steps: 197    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 735   score: 1.0   memory length: 133567   epsilon: 0.9335353600014429    steps: 171    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 736   score: 1.0   memory length: 133718   epsilon: 0.9332363800014494    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 737   score: 1.0   memory length: 133869   epsilon: 0.9329374000014559    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 738   score: 0.0   memory length: 133992   epsilon: 0.9326938600014612    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 739   score: 3.0   memory length: 134262   epsilon: 0.9321592600014728    steps: 270    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 740   score: 1.0   memory length: 134433   epsilon: 0.9318206800014801    steps: 171    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 741   score: 1.0   memory length: 134583   epsilon: 0.9315236800014866    steps: 150    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 742   score: 3.0   memory length: 134809   epsilon: 0.9310762000014963    steps: 226    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 743   score: 0.0   memory length: 134932   epsilon: 0.9308326600015016    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 744   score: 0.0   memory length: 135055   epsilon: 0.9305891200015068    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 745   score: 0.0   memory length: 135177   epsilon: 0.9303475600015121    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 746   score: 3.0   memory length: 135407   epsilon: 0.929892160001522    steps: 230    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 747   score: 0.0   memory length: 135529   epsilon: 0.9296506000015272    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 748   score: 2.0   memory length: 135727   epsilon: 0.9292585600015357    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 749   score: 0.0   memory length: 135849   epsilon: 0.929017000001541    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 750   score: 0.0   memory length: 135971   epsilon: 0.9287754400015462    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 751   score: 2.0   memory length: 136151   epsilon: 0.928419040001554    steps: 180    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 752   score: 0.0   memory length: 136274   epsilon: 0.9281755000015592    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 753   score: 0.0   memory length: 136396   epsilon: 0.9279339400015645    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 754   score: 4.0   memory length: 136659   epsilon: 0.9274132000015758    steps: 263    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 755   score: 0.0   memory length: 136781   epsilon: 0.927171640001581    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 756   score: 0.0   memory length: 136904   epsilon: 0.9269281000015863    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 757   score: 1.0   memory length: 137073   epsilon: 0.9265934800015936    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 758   score: 2.0   memory length: 137290   epsilon: 0.9261638200016029    steps: 217    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 759   score: 2.0   memory length: 137509   epsilon: 0.9257302000016123    steps: 219    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 760   score: 2.0   memory length: 137707   epsilon: 0.9253381600016208    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 761   score: 2.0   memory length: 137927   epsilon: 0.9249025600016303    steps: 220    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 762   score: 1.0   memory length: 138078   epsilon: 0.9246035800016368    steps: 151    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 763   score: 2.0   memory length: 138276   epsilon: 0.9242115400016453    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 764   score: 0.0   memory length: 138399   epsilon: 0.9239680000016506    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 765   score: 0.0   memory length: 138522   epsilon: 0.9237244600016559    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 766   score: 4.0   memory length: 138818   epsilon: 0.9231383800016686    steps: 296    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 767   score: 3.0   memory length: 139064   epsilon: 0.9226513000016792    steps: 246    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 768   score: 2.0   memory length: 139264   epsilon: 0.9222553000016878    steps: 200    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 769   score: 2.0   memory length: 139462   epsilon: 0.9218632600016963    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 770   score: 1.0   memory length: 139634   epsilon: 0.9215227000017037    steps: 172    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 771   score: 3.0   memory length: 139878   epsilon: 0.9210395800017142    steps: 244    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 772   score: 1.0   memory length: 140047   epsilon: 0.9207049600017214    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 773   score: 1.0   memory length: 140198   epsilon: 0.9204059800017279    steps: 151    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 774   score: 4.0   memory length: 140493   epsilon: 0.9198218800017406    steps: 295    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 775   score: 2.0   memory length: 140691   epsilon: 0.9194298400017491    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 776   score: 3.0   memory length: 140919   epsilon: 0.9189784000017589    steps: 228    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 777   score: 3.0   memory length: 141145   epsilon: 0.9185309200017686    steps: 226    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 778   score: 1.0   memory length: 141313   epsilon: 0.9181982800017758    steps: 168    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 779   score: 2.0   memory length: 141510   epsilon: 0.9178082200017843    steps: 197    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 780   score: 0.0   memory length: 141632   epsilon: 0.9175666600017895    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 781   score: 1.0   memory length: 141802   epsilon: 0.9172300600017969    steps: 170    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 782   score: 5.0   memory length: 142118   epsilon: 0.9166043800018104    steps: 316    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 783   score: 0.0   memory length: 142240   epsilon: 0.9163628200018157    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 784   score: 8.0   memory length: 142638   epsilon: 0.9155747800018328    steps: 398    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 785   score: 0.0   memory length: 142761   epsilon: 0.9153312400018381    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 786   score: 1.0   memory length: 142931   epsilon: 0.9149946400018454    steps: 170    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 787   score: 1.0   memory length: 143082   epsilon: 0.9146956600018519    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 788   score: 0.0   memory length: 143205   epsilon: 0.9144521200018572    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 789   score: 4.0   memory length: 143500   epsilon: 0.9138680200018698    steps: 295    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 790   score: 1.0   memory length: 143668   epsilon: 0.9135353800018771    steps: 168    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 791   score: 1.0   memory length: 143818   epsilon: 0.9132383800018835    steps: 150    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 792   score: 0.0   memory length: 143940   epsilon: 0.9129968200018888    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 793   score: 2.0   memory length: 144156   epsilon: 0.912569140001898    steps: 216    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 794   score: 2.0   memory length: 144373   epsilon: 0.9121394800019074    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 795   score: 0.0   memory length: 144496   epsilon: 0.9118959400019127    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 796   score: 0.0   memory length: 144619   epsilon: 0.9116524000019179    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 797   score: 2.0   memory length: 144816   epsilon: 0.9112623400019264    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 798   score: 1.0   memory length: 144985   epsilon: 0.9109277200019337    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 799   score: 2.0   memory length: 145183   epsilon: 0.9105356800019422    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 800   score: 0.0   memory length: 145306   epsilon: 0.9102921400019475    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 801   score: 2.0   memory length: 145486   epsilon: 0.9099357400019552    steps: 180    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 802   score: 4.0   memory length: 145779   epsilon: 0.9093556000019678    steps: 293    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 803   score: 2.0   memory length: 145999   epsilon: 0.9089200000019773    steps: 220    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 804   score: 2.0   memory length: 146197   epsilon: 0.9085279600019858    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 805   score: 2.0   memory length: 146395   epsilon: 0.9081359200019943    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 806   score: 4.0   memory length: 146670   epsilon: 0.9075914200020061    steps: 275    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 807   score: 0.0   memory length: 146793   epsilon: 0.9073478800020114    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 808   score: 0.0   memory length: 146916   epsilon: 0.9071043400020167    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 809   score: 0.0   memory length: 147039   epsilon: 0.906860800002022    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 810   score: 1.0   memory length: 147208   epsilon: 0.9065261800020292    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 811   score: 0.0   memory length: 147331   epsilon: 0.9062826400020345    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 812   score: 0.0   memory length: 147454   epsilon: 0.9060391000020398    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 813   score: 4.0   memory length: 147745   epsilon: 0.9054629200020523    steps: 291    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 814   score: 0.0   memory length: 147868   epsilon: 0.9052193800020576    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 815   score: 0.0   memory length: 147991   epsilon: 0.9049758400020629    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 816   score: 2.0   memory length: 148189   epsilon: 0.9045838000020714    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 817   score: 1.0   memory length: 148340   epsilon: 0.9042848200020779    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 818   score: 3.0   memory length: 148607   epsilon: 0.9037561600020894    steps: 267    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 819   score: 1.0   memory length: 148775   epsilon: 0.9034235200020966    steps: 168    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 820   score: 1.0   memory length: 148945   epsilon: 0.9030869200021039    steps: 170    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 821   score: 1.0   memory length: 149114   epsilon: 0.9027523000021112    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 822   score: 2.0   memory length: 149312   epsilon: 0.9023602600021197    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 823   score: 1.0   memory length: 149462   epsilon: 0.9020632600021261    steps: 150    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 824   score: 1.0   memory length: 149614   epsilon: 0.9017623000021326    steps: 152    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 825   score: 4.0   memory length: 149930   epsilon: 0.9011366200021462    steps: 316    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 826   score: 0.0   memory length: 150053   epsilon: 0.9008930800021515    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 827   score: 3.0   memory length: 150280   epsilon: 0.9004436200021613    steps: 227    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 828   score: 0.0   memory length: 150403   epsilon: 0.9002000800021666    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 829   score: 3.0   memory length: 150667   epsilon: 0.8996773600021779    steps: 264    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 830   score: 2.0   memory length: 150864   epsilon: 0.8992873000021864    steps: 197    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 831   score: 1.0   memory length: 151033   epsilon: 0.8989526800021936    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 832   score: 3.0   memory length: 151258   epsilon: 0.8985071800022033    steps: 225    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 833   score: 2.0   memory length: 151456   epsilon: 0.8981151400022118    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 834   score: 0.0   memory length: 151578   epsilon: 0.8978735800022171    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 835   score: 1.0   memory length: 151730   epsilon: 0.8975726200022236    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 836   score: 0.0   memory length: 151853   epsilon: 0.8973290800022289    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 837   score: 1.0   memory length: 152003   epsilon: 0.8970320800022353    steps: 150    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 838   score: 0.0   memory length: 152126   epsilon: 0.8967885400022406    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 839   score: 2.0   memory length: 152346   epsilon: 0.8963529400022501    steps: 220    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 840   score: 0.0   memory length: 152469   epsilon: 0.8961094000022554    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 841   score: 3.0   memory length: 152715   epsilon: 0.8956223200022659    steps: 246    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 842   score: 1.0   memory length: 152866   epsilon: 0.8953233400022724    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 843   score: 2.0   memory length: 153067   epsilon: 0.8949253600022811    steps: 201    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 844   score: 2.0   memory length: 153265   epsilon: 0.8945333200022896    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 845   score: 1.0   memory length: 153434   epsilon: 0.8941987000022968    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 846   score: 1.0   memory length: 153585   epsilon: 0.8938997200023033    steps: 151    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 847   score: 1.0   memory length: 153754   epsilon: 0.8935651000023106    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 848   score: 2.0   memory length: 153971   epsilon: 0.8931354400023199    steps: 217    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 849   score: 2.0   memory length: 154189   epsilon: 0.8927038000023293    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 850   score: 3.0   memory length: 154418   epsilon: 0.8922503800023391    steps: 229    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 851   score: 0.0   memory length: 154541   epsilon: 0.8920068400023444    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 852   score: 0.0   memory length: 154664   epsilon: 0.8917633000023497    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 853   score: 5.0   memory length: 154959   epsilon: 0.8911792000023624    steps: 295    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 854   score: 2.0   memory length: 155157   epsilon: 0.8907871600023709    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 855   score: 1.0   memory length: 155308   epsilon: 0.8904881800023774    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 856   score: 1.0   memory length: 155459   epsilon: 0.8901892000023839    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 857   score: 0.0   memory length: 155581   epsilon: 0.8899476400023891    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 858   score: 3.0   memory length: 155813   epsilon: 0.8894882800023991    steps: 232    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 859   score: 1.0   memory length: 155963   epsilon: 0.8891912800024055    steps: 150    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 860   score: 2.0   memory length: 156163   epsilon: 0.8887952800024141    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 861   score: 2.0   memory length: 156361   epsilon: 0.8884032400024227    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 862   score: 1.0   memory length: 156512   epsilon: 0.8881042600024291    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 863   score: 3.0   memory length: 156779   epsilon: 0.8875756000024406    steps: 267    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 864   score: 3.0   memory length: 157023   epsilon: 0.8870924800024511    steps: 244    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 865   score: 3.0   memory length: 157266   epsilon: 0.8866113400024616    steps: 243    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 866   score: 4.0   memory length: 157562   epsilon: 0.8860252600024743    steps: 296    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 867   score: 1.0   memory length: 157713   epsilon: 0.8857262800024808    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 868   score: 0.0   memory length: 157835   epsilon: 0.885484720002486    steps: 122    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 869   score: 3.0   memory length: 158064   epsilon: 0.8850313000024959    steps: 229    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 870   score: 2.0   memory length: 158262   epsilon: 0.8846392600025044    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 871   score: 2.0   memory length: 158481   epsilon: 0.8842056400025138    steps: 219    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 872   score: 3.0   memory length: 158727   epsilon: 0.8837185600025244    steps: 246    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 873   score: 0.0   memory length: 158850   epsilon: 0.8834750200025296    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 874   score: 0.0   memory length: 158972   epsilon: 0.8832334600025349    steps: 122    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 875   score: 2.0   memory length: 159190   epsilon: 0.8828018200025443    steps: 218    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 876   score: 1.0   memory length: 159359   epsilon: 0.8824672000025515    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 877   score: 1.0   memory length: 159530   epsilon: 0.8821286200025589    steps: 171    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 878   score: 2.0   memory length: 159732   epsilon: 0.8817286600025676    steps: 202    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 879   score: 1.0   memory length: 159883   epsilon: 0.881429680002574    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 880   score: 1.0   memory length: 160034   epsilon: 0.8811307000025805    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 881   score: 1.0   memory length: 160205   epsilon: 0.8807921200025879    steps: 171    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 882   score: 0.0   memory length: 160328   epsilon: 0.8805485800025932    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 883   score: 4.0   memory length: 160585   epsilon: 0.8800397200026042    steps: 257    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 884   score: 1.0   memory length: 160754   epsilon: 0.8797051000026115    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 885   score: 0.0   memory length: 160877   epsilon: 0.8794615600026168    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 886   score: 1.0   memory length: 161029   epsilon: 0.8791606000026233    steps: 152    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 887   score: 2.0   memory length: 161229   epsilon: 0.8787646000026319    steps: 200    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 888   score: 1.0   memory length: 161399   epsilon: 0.8784280000026392    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 889   score: 0.0   memory length: 161522   epsilon: 0.8781844600026445    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 890   score: 0.0   memory length: 161644   epsilon: 0.8779429000026497    steps: 122    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 891   score: 0.0   memory length: 161766   epsilon: 0.877701340002655    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 892   score: 2.0   memory length: 161963   epsilon: 0.8773112800026635    steps: 197    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 893   score: 0.0   memory length: 162086   epsilon: 0.8770677400026687    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 894   score: 1.0   memory length: 162257   epsilon: 0.8767291600026761    steps: 171    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 895   score: 2.0   memory length: 162439   epsilon: 0.8763688000026839    steps: 182    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 896   score: 2.0   memory length: 162637   epsilon: 0.8759767600026924    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 897   score: 1.0   memory length: 162806   epsilon: 0.8756421400026997    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 898   score: 2.0   memory length: 163004   epsilon: 0.8752501000027082    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 899   score: 1.0   memory length: 163155   epsilon: 0.8749511200027147    steps: 151    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 900   score: 0.0   memory length: 163277   epsilon: 0.8747095600027199    steps: 122    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 901   score: 1.0   memory length: 163446   epsilon: 0.8743749400027272    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 902   score: 2.0   memory length: 163664   epsilon: 0.8739433000027366    steps: 218    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 903   score: 0.0   memory length: 163786   epsilon: 0.8737017400027418    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 904   score: 2.0   memory length: 164007   epsilon: 0.8732641600027513    steps: 221    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 905   score: 2.0   memory length: 164205   epsilon: 0.8728721200027598    steps: 198    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 906   score: 0.0   memory length: 164328   epsilon: 0.8726285800027651    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 907   score: 5.0   memory length: 164632   epsilon: 0.8720266600027782    steps: 304    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 908   score: 3.0   memory length: 164900   epsilon: 0.8714960200027897    steps: 268    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 909   score: 0.0   memory length: 165023   epsilon: 0.871252480002795    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 910   score: 3.0   memory length: 165271   epsilon: 0.8707614400028056    steps: 248    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 911   score: 2.0   memory length: 165468   epsilon: 0.8703713800028141    steps: 197    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 912   score: 1.0   memory length: 165637   epsilon: 0.8700367600028214    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 913   score: 1.0   memory length: 165806   epsilon: 0.8697021400028286    steps: 169    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 914   score: 1.0   memory length: 165957   epsilon: 0.8694031600028351    steps: 151    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 915   score: 3.0   memory length: 166185   epsilon: 0.8689517200028449    steps: 228    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 916   score: 2.0   memory length: 166383   epsilon: 0.8685596800028534    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 917   score: 0.0   memory length: 166505   epsilon: 0.8683181200028587    steps: 122    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 918   score: 4.0   memory length: 166824   epsilon: 0.8676865000028724    steps: 319    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 919   score: 4.0   memory length: 167122   epsilon: 0.8670964600028852    steps: 298    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 920   score: 1.0   memory length: 167272   epsilon: 0.8667994600028917    steps: 150    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 921   score: 2.0   memory length: 167452   epsilon: 0.8664430600028994    steps: 180    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 922   score: 4.0   memory length: 167764   epsilon: 0.8658253000029128    steps: 312    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 923   score: 2.0   memory length: 167962   epsilon: 0.8654332600029213    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 924   score: 1.0   memory length: 168113   epsilon: 0.8651342800029278    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 925   score: 4.0   memory length: 168377   epsilon: 0.8646115600029392    steps: 264    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 926   score: 3.0   memory length: 168640   epsilon: 0.8640908200029505    steps: 263    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 927   score: 2.0   memory length: 168823   epsilon: 0.8637284800029583    steps: 183    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 928   score: 2.0   memory length: 169041   epsilon: 0.8632968400029677    steps: 218    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 929   score: 1.0   memory length: 169209   epsilon: 0.8629642000029749    steps: 168    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 930   score: 3.0   memory length: 169437   epsilon: 0.8625127600029847    steps: 228    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 931   score: 3.0   memory length: 169685   epsilon: 0.8620217200029954    steps: 248    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 932   score: 1.0   memory length: 169835   epsilon: 0.8617247200030018    steps: 150    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 933   score: 3.0   memory length: 170079   epsilon: 0.8612416000030123    steps: 244    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 934   score: 2.0   memory length: 170277   epsilon: 0.8608495600030208    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 935   score: 2.0   memory length: 170496   epsilon: 0.8604159400030302    steps: 219    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 936   score: 1.0   memory length: 170647   epsilon: 0.8601169600030367    steps: 151    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 937   score: 0.0   memory length: 170770   epsilon: 0.859873420003042    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 938   score: 4.0   memory length: 171065   epsilon: 0.8592893200030547    steps: 295    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 939   score: 1.0   memory length: 171233   epsilon: 0.8589566800030619    steps: 168    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 940   score: 2.0   memory length: 171451   epsilon: 0.8585250400030713    steps: 218    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 941   score: 2.0   memory length: 171631   epsilon: 0.858168640003079    steps: 180    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 942   score: 2.0   memory length: 171852   epsilon: 0.8577310600030885    steps: 221    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 943   score: 2.0   memory length: 172051   epsilon: 0.8573370400030971    steps: 199    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 944   score: 1.0   memory length: 172219   epsilon: 0.8570044000031043    steps: 168    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 945   score: 2.0   memory length: 172417   epsilon: 0.8566123600031128    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 946   score: 3.0   memory length: 172663   epsilon: 0.8561252800031234    steps: 246    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 947   score: 2.0   memory length: 172883   epsilon: 0.8556896800031328    steps: 220    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 948   score: 1.0   memory length: 173052   epsilon: 0.8553550600031401    steps: 169    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 949   score: 2.0   memory length: 173250   epsilon: 0.8549630200031486    steps: 198    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 950   score: 3.0   memory length: 173520   epsilon: 0.8544284200031602    steps: 270    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 951   score: 2.0   memory length: 173717   epsilon: 0.8540383600031687    steps: 197    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 952   score: 3.0   memory length: 173965   epsilon: 0.8535473200031793    steps: 248    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 953   score: 3.0   memory length: 174212   epsilon: 0.85305826000319    steps: 247    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 954   score: 4.0   memory length: 174527   epsilon: 0.8524345600032035    steps: 315    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 955   score: 2.0   memory length: 174725   epsilon: 0.852042520003212    steps: 198    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 956   score: 2.0   memory length: 174909   epsilon: 0.8516782000032199    steps: 184    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 957   score: 0.0   memory length: 175032   epsilon: 0.8514346600032252    steps: 123    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 958   score: 1.0   memory length: 175201   epsilon: 0.8511000400032325    steps: 169    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 959   score: 2.0   memory length: 175419   epsilon: 0.8506684000032418    steps: 218    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 960   score: 2.0   memory length: 175617   epsilon: 0.8502763600032504    steps: 198    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 961   score: 2.0   memory length: 175833   epsilon: 0.8498486800032596    steps: 216    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 962   score: 0.0   memory length: 175955   epsilon: 0.8496071200032649    steps: 122    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 963   score: 2.0   memory length: 176153   epsilon: 0.8492150800032734    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 964   score: 1.0   memory length: 176322   epsilon: 0.8488804600032807    steps: 169    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 965   score: 1.0   memory length: 176491   epsilon: 0.8485458400032879    steps: 169    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 966   score: 4.0   memory length: 176788   epsilon: 0.8479577800033007    steps: 297    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 967   score: 0.0   memory length: 176910   epsilon: 0.8477162200033059    steps: 122    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 968   score: 0.0   memory length: 177033   epsilon: 0.8474726800033112    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 969   score: 2.0   memory length: 177231   epsilon: 0.8470806400033197    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 970   score: 0.0   memory length: 177354   epsilon: 0.846837100003325    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 971   score: 2.0   memory length: 177554   epsilon: 0.8464411000033336    steps: 200    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 972   score: 0.0   memory length: 177676   epsilon: 0.8461995400033389    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 973   score: 2.0   memory length: 177898   epsilon: 0.8457599800033484    steps: 222    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 974   score: 2.0   memory length: 178095   epsilon: 0.8453699200033569    steps: 197    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 975   score: 1.0   memory length: 178247   epsilon: 0.8450689600033634    steps: 152    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 976   score: 5.0   memory length: 178555   epsilon: 0.8444591200033766    steps: 308    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 977   score: 0.0   memory length: 178678   epsilon: 0.8442155800033819    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 978   score: 3.0   memory length: 178925   epsilon: 0.8437265200033925    steps: 247    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 979   score: 2.0   memory length: 179107   epsilon: 0.8433661600034004    steps: 182    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 980   score: 0.0   memory length: 179230   epsilon: 0.8431226200034057    steps: 123    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 981   score: 0.0   memory length: 179353   epsilon: 0.8428790800034109    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 982   score: 3.0   memory length: 179599   epsilon: 0.8423920000034215    steps: 246    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 983   score: 0.0   memory length: 179722   epsilon: 0.8421484600034268    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 984   score: 1.0   memory length: 179891   epsilon: 0.8418138400034341    steps: 169    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 985   score: 0.0   memory length: 180014   epsilon: 0.8415703000034394    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 986   score: 0.0   memory length: 180137   epsilon: 0.8413267600034446    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 987   score: 2.0   memory length: 180337   epsilon: 0.8409307600034532    steps: 200    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 988   score: 1.0   memory length: 180488   epsilon: 0.8406317800034597    steps: 151    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 989   score: 1.0   memory length: 180638   epsilon: 0.8403347800034662    steps: 150    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 990   score: 0.0   memory length: 180760   epsilon: 0.8400932200034714    steps: 122    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 991   score: 5.0   memory length: 181105   epsilon: 0.8394101200034862    steps: 345    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 992   score: 0.0   memory length: 181228   epsilon: 0.8391665800034915    steps: 123    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 993   score: 2.0   memory length: 181426   epsilon: 0.8387745400035    steps: 198    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 994   score: 2.0   memory length: 181645   epsilon: 0.8383409200035095    steps: 219    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 995   score: 0.0   memory length: 181768   epsilon: 0.8380973800035147    steps: 123    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 996   score: 3.0   memory length: 182015   epsilon: 0.8376083200035254    steps: 247    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 997   score: 3.0   memory length: 182281   epsilon: 0.8370816400035368    steps: 266    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 998   score: 2.0   memory length: 182499   epsilon: 0.8366500000035462    steps: 218    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 999   score: 2.0   memory length: 182697   epsilon: 0.8362579600035547    steps: 198    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1000   score: 3.0   memory length: 182943   epsilon: 0.8357708800035653    steps: 246    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1001   score: 1.0   memory length: 183112   epsilon: 0.8354362600035725    steps: 169    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1002   score: 1.0   memory length: 183283   epsilon: 0.8350976800035799    steps: 171    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 1003   score: 1.0   memory length: 183453   epsilon: 0.8347610800035872    steps: 170    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1004   score: 1.0   memory length: 183603   epsilon: 0.8344640800035936    steps: 150    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 1005   score: 3.0   memory length: 183849   epsilon: 0.8339770000036042    steps: 246    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1006   score: 2.0   memory length: 184046   epsilon: 0.8335869400036127    steps: 197    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1007   score: 0.0   memory length: 184169   epsilon: 0.833343400003618    steps: 123    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1008   score: 0.0   memory length: 184292   epsilon: 0.8330998600036232    steps: 123    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 1009   score: 3.0   memory length: 184517   epsilon: 0.8326543600036329    steps: 225    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1010   score: 3.0   memory length: 184748   epsilon: 0.8321969800036428    steps: 231    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1011   score: 2.0   memory length: 184946   epsilon: 0.8318049400036513    steps: 198    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1012   score: 0.0   memory length: 185068   epsilon: 0.8315633800036566    steps: 122    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 1013   score: 0.0   memory length: 185191   epsilon: 0.8313198400036619    steps: 123    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1014   score: 1.0   memory length: 185341   epsilon: 0.8310228400036683    steps: 150    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1015   score: 0.0   memory length: 185464   epsilon: 0.8307793000036736    steps: 123    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 1016   score: 1.0   memory length: 185633   epsilon: 0.8304446800036809    steps: 169    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 1017   score: 1.0   memory length: 185805   epsilon: 0.8301041200036883    steps: 172    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 1018   score: 2.0   memory length: 186003   epsilon: 0.8297120800036968    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1019   score: 1.0   memory length: 186153   epsilon: 0.8294150800037032    steps: 150    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1020   score: 3.0   memory length: 186382   epsilon: 0.8289616600037131    steps: 229    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1021   score: 0.0   memory length: 186505   epsilon: 0.8287181200037184    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1022   score: 3.0   memory length: 186772   epsilon: 0.8281894600037298    steps: 267    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1023   score: 0.0   memory length: 186895   epsilon: 0.8279459200037351    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1024   score: 2.0   memory length: 187074   epsilon: 0.8275915000037428    steps: 179    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 1025   score: 0.0   memory length: 187197   epsilon: 0.8273479600037481    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1026   score: 0.0   memory length: 187320   epsilon: 0.8271044200037534    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1027   score: 3.0   memory length: 187586   epsilon: 0.8265777400037648    steps: 266    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1028   score: 3.0   memory length: 187831   epsilon: 0.8260926400037754    steps: 245    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1029   score: 1.0   memory length: 188000   epsilon: 0.8257580200037826    steps: 169    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1030   score: 4.0   memory length: 188279   epsilon: 0.8252056000037946    steps: 279    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1031   score: 1.0   memory length: 188430   epsilon: 0.8249066200038011    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1032   score: 4.0   memory length: 188727   epsilon: 0.8243185600038139    steps: 297    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1033   score: 1.0   memory length: 188896   epsilon: 0.8239839400038211    steps: 169    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1034   score: 4.0   memory length: 189195   epsilon: 0.823391920003834    steps: 299    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1035   score: 1.0   memory length: 189346   epsilon: 0.8230929400038405    steps: 151    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1036   score: 0.0   memory length: 189469   epsilon: 0.8228494000038458    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1037   score: 1.0   memory length: 189619   epsilon: 0.8225524000038522    steps: 150    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1038   score: 0.0   memory length: 189741   epsilon: 0.8223108400038575    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1039   score: 3.0   memory length: 189985   epsilon: 0.821827720003868    steps: 244    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1040   score: 0.0   memory length: 190107   epsilon: 0.8215861600038732    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1041   score: 3.0   memory length: 190335   epsilon: 0.821134720003883    steps: 228    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1042   score: 2.0   memory length: 190554   epsilon: 0.8207011000038924    steps: 219    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1043   score: 1.0   memory length: 190705   epsilon: 0.8204021200038989    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1044   score: 4.0   memory length: 190998   epsilon: 0.8198219800039115    steps: 293    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1045   score: 0.0   memory length: 191120   epsilon: 0.8195804200039167    steps: 122    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1046   score: 2.0   memory length: 191318   epsilon: 0.8191883800039252    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1047   score: 4.0   memory length: 191614   epsilon: 0.818602300003938    steps: 296    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1048   score: 3.0   memory length: 191879   epsilon: 0.8180776000039494    steps: 265    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1049   score: 0.0   memory length: 192002   epsilon: 0.8178340600039546    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1050   score: 1.0   memory length: 192153   epsilon: 0.8175350800039611    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1051   score: 2.0   memory length: 192350   epsilon: 0.8171450200039696    steps: 197    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1052   score: 3.0   memory length: 192597   epsilon: 0.8166559600039802    steps: 247    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1053   score: 2.0   memory length: 192795   epsilon: 0.8162639200039887    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1054   score: 5.0   memory length: 193131   epsilon: 0.8155986400040032    steps: 336    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1055   score: 1.0   memory length: 193300   epsilon: 0.8152640200040104    steps: 169    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1056   score: 2.0   memory length: 193497   epsilon: 0.8148739600040189    steps: 197    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1057   score: 2.0   memory length: 193696   epsilon: 0.8144799400040275    steps: 199    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1058   score: 0.0   memory length: 193819   epsilon: 0.8142364000040327    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1059   score: 0.0   memory length: 193942   epsilon: 0.813992860004038    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 1060   score: 2.0   memory length: 194139   epsilon: 0.8136028000040465    steps: 197    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 1061   score: 0.0   memory length: 194261   epsilon: 0.8133612400040517    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 1062   score: 1.0   memory length: 194430   epsilon: 0.813026620004059    steps: 169    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 1063   score: 5.0   memory length: 194754   epsilon: 0.8123851000040729    steps: 324    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1064   score: 1.0   memory length: 194924   epsilon: 0.8120485000040802    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1065   score: 2.0   memory length: 195141   epsilon: 0.8116188400040896    steps: 217    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1066   score: 5.0   memory length: 195486   epsilon: 0.8109357400041044    steps: 345    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1067   score: 3.0   memory length: 195735   epsilon: 0.8104427200041151    steps: 249    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1068   score: 3.0   memory length: 195983   epsilon: 0.8099516800041258    steps: 248    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 1069   score: 1.0   memory length: 196152   epsilon: 0.809617060004133    steps: 169    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1070   score: 2.0   memory length: 196370   epsilon: 0.8091854200041424    steps: 218    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1071   score: 3.0   memory length: 196637   epsilon: 0.8086567600041539    steps: 267    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1072   score: 1.0   memory length: 196788   epsilon: 0.8083577800041604    steps: 151    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 1073   score: 0.0   memory length: 196911   epsilon: 0.8081142400041657    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1074   score: 1.0   memory length: 197081   epsilon: 0.807777640004173    steps: 170    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 1075   score: 2.0   memory length: 197278   epsilon: 0.8073875800041814    steps: 197    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1076   score: 2.0   memory length: 197496   epsilon: 0.8069559400041908    steps: 218    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 1077   score: 3.0   memory length: 197740   epsilon: 0.8064728200042013    steps: 244    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1078   score: 2.0   memory length: 197939   epsilon: 0.8060788000042098    steps: 199    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 1079   score: 3.0   memory length: 198165   epsilon: 0.8056313200042196    steps: 226    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1080   score: 2.0   memory length: 198363   epsilon: 0.8052392800042281    steps: 198    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 1081   score: 2.0   memory length: 198561   epsilon: 0.8048472400042366    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1082   score: 0.0   memory length: 198684   epsilon: 0.8046037000042419    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1083   score: 0.0   memory length: 198807   epsilon: 0.8043601600042471    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1084   score: 1.0   memory length: 198975   epsilon: 0.8040275200042544    steps: 168    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1085   score: 3.0   memory length: 199201   epsilon: 0.8035800400042641    steps: 226    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1086   score: 0.0   memory length: 199324   epsilon: 0.8033365000042694    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1087   score: 2.0   memory length: 199522   epsilon: 0.8029444600042779    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1088   score: 4.0   memory length: 199802   epsilon: 0.8023900600042899    steps: 280    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 1089   score: 0.0   memory length: 199925   epsilon: 0.8021465200042952    steps: 123    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 1090   score: 0.0   memory length: 200048   epsilon: 0.8019029800043005    steps: 123    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1091   score: 3.0   memory length: 200311   epsilon: 0.8013822400043118    steps: 263    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1092   score: 2.0   memory length: 200527   epsilon: 0.8009545600043211    steps: 216    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1093   score: 2.0   memory length: 200724   epsilon: 0.8005645000043295    steps: 197    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1094   score: 0.0   memory length: 200846   epsilon: 0.8003229400043348    steps: 122    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1095   score: 1.0   memory length: 200996   epsilon: 0.8000259400043412    steps: 150    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1096   score: 2.0   memory length: 201175   epsilon: 0.7996715200043489    steps: 179    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1097   score: 3.0   memory length: 201404   epsilon: 0.7992181000043588    steps: 229    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1098   score: 4.0   memory length: 201679   epsilon: 0.7986736000043706    steps: 275    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1099   score: 3.0   memory length: 201928   epsilon: 0.7981805800043813    steps: 249    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 1100   score: 2.0   memory length: 202146   epsilon: 0.7977489400043907    steps: 218    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1101   score: 1.0   memory length: 202315   epsilon: 0.7974143200043979    steps: 169    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1102   score: 4.0   memory length: 202594   epsilon: 0.7968619000044099    steps: 279    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1103   score: 0.0   memory length: 202717   epsilon: 0.7966183600044152    steps: 123    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1104   score: 5.0   memory length: 203043   epsilon: 0.7959728800044292    steps: 326    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 1105   score: 0.0   memory length: 203166   epsilon: 0.7957293400044345    steps: 123    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1106   score: 1.0   memory length: 203317   epsilon: 0.795430360004441    steps: 151    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1107   score: 0.0   memory length: 203440   epsilon: 0.7951868200044463    steps: 123    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1108   score: 1.0   memory length: 203609   epsilon: 0.7948522000044536    steps: 169    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1109   score: 0.0   memory length: 203732   epsilon: 0.7946086600044588    steps: 123    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1110   score: 2.0   memory length: 203930   epsilon: 0.7942166200044674    steps: 198    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1111   score: 1.0   memory length: 204100   epsilon: 0.7938800200044747    steps: 170    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1112   score: 2.0   memory length: 204297   epsilon: 0.7934899600044831    steps: 197    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1113   score: 2.0   memory length: 204497   epsilon: 0.7930939600044917    steps: 200    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1114   score: 2.0   memory length: 204695   epsilon: 0.7927019200045002    steps: 198    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1115   score: 1.0   memory length: 204845   epsilon: 0.7924049200045067    steps: 150    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1116   score: 3.0   memory length: 205071   epsilon: 0.7919574400045164    steps: 226    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 1117   score: 2.0   memory length: 205252   epsilon: 0.7915990600045242    steps: 181    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1118   score: 3.0   memory length: 205479   epsilon: 0.7911496000045339    steps: 227    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1119   score: 3.0   memory length: 205708   epsilon: 0.7906961800045438    steps: 229    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1120   score: 1.0   memory length: 205878   epsilon: 0.7903595800045511    steps: 170    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1121   score: 1.0   memory length: 206048   epsilon: 0.7900229800045584    steps: 170    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1122   score: 2.0   memory length: 206265   epsilon: 0.7895933200045677    steps: 217    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1123   score: 4.0   memory length: 206526   epsilon: 0.7890765400045789    steps: 261    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1124   score: 4.0   memory length: 206839   epsilon: 0.7884568000045924    steps: 313    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1125   score: 2.0   memory length: 207057   epsilon: 0.7880251600046018    steps: 218    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1126   score: 1.0   memory length: 207227   epsilon: 0.7876885600046091    steps: 170    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1127   score: 2.0   memory length: 207424   epsilon: 0.7872985000046175    steps: 197    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1128   score: 4.0   memory length: 207683   epsilon: 0.7867856800046287    steps: 259    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1129   score: 0.0   memory length: 207806   epsilon: 0.786542140004634    steps: 123    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1130   score: 2.0   memory length: 208003   epsilon: 0.7861520800046424    steps: 197    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1131   score: 1.0   memory length: 208154   epsilon: 0.7858531000046489    steps: 151    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1132   score: 3.0   memory length: 208400   epsilon: 0.7853660200046595    steps: 246    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1133   score: 0.0   memory length: 208523   epsilon: 0.7851224800046648    steps: 123    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1134   score: 1.0   memory length: 208691   epsilon: 0.784789840004672    steps: 168    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1135   score: 1.0   memory length: 208860   epsilon: 0.7844552200046793    steps: 169    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1136   score: 1.0   memory length: 209029   epsilon: 0.7841206000046865    steps: 169    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1137   score: 3.0   memory length: 209296   epsilon: 0.783591940004698    steps: 267    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1138   score: 3.0   memory length: 209540   epsilon: 0.7831088200047085    steps: 244    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1139   score: 0.0   memory length: 209663   epsilon: 0.7828652800047138    steps: 123    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1140   score: 3.0   memory length: 209889   epsilon: 0.7824178000047235    steps: 226    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1141   score: 2.0   memory length: 210068   epsilon: 0.7820633800047312    steps: 179    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1142   score: 0.0   memory length: 210190   epsilon: 0.7818218200047364    steps: 122    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1143   score: 0.0   memory length: 210313   epsilon: 0.7815782800047417    steps: 123    lr: 4e-05     evaluation reward: 1.83\n",
      "episode: 1144   score: 0.0   memory length: 210436   epsilon: 0.781334740004747    steps: 123    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1145   score: 2.0   memory length: 210653   epsilon: 0.7809050800047563    steps: 217    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1146   score: 1.0   memory length: 210821   epsilon: 0.7805724400047636    steps: 168    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1147   score: 9.0   memory length: 211169   epsilon: 0.7798834000047785    steps: 348    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1148   score: 0.0   memory length: 211292   epsilon: 0.7796398600047838    steps: 123    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1149   score: 2.0   memory length: 211471   epsilon: 0.7792854400047915    steps: 179    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1150   score: 2.0   memory length: 211689   epsilon: 0.7788538000048009    steps: 218    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1151   score: 2.0   memory length: 211887   epsilon: 0.7784617600048094    steps: 198    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1152   score: 3.0   memory length: 212116   epsilon: 0.7780083400048192    steps: 229    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1153   score: 3.0   memory length: 212360   epsilon: 0.7775252200048297    steps: 244    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1154   score: 3.0   memory length: 212605   epsilon: 0.7770401200048402    steps: 245    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1155   score: 3.0   memory length: 212852   epsilon: 0.7765510600048509    steps: 247    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1156   score: 1.0   memory length: 213003   epsilon: 0.7762520800048573    steps: 151    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1157   score: 3.0   memory length: 213250   epsilon: 0.775763020004868    steps: 247    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1158   score: 1.0   memory length: 213421   epsilon: 0.7754244400048753    steps: 171    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1159   score: 7.0   memory length: 213827   epsilon: 0.7746205600048928    steps: 406    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1160   score: 5.0   memory length: 214136   epsilon: 0.774008740004906    steps: 309    lr: 4e-05     evaluation reward: 1.97\n",
      "episode: 1161   score: 2.0   memory length: 214317   epsilon: 0.7736503600049138    steps: 181    lr: 4e-05     evaluation reward: 1.99\n",
      "episode: 1162   score: 0.0   memory length: 214440   epsilon: 0.7734068200049191    steps: 123    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 1163   score: 2.0   memory length: 214640   epsilon: 0.7730108200049277    steps: 200    lr: 4e-05     evaluation reward: 1.95\n",
      "episode: 1164   score: 4.0   memory length: 214934   epsilon: 0.7724287000049403    steps: 294    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 1165   score: 1.0   memory length: 215103   epsilon: 0.7720940800049476    steps: 169    lr: 4e-05     evaluation reward: 1.97\n",
      "episode: 1166   score: 1.0   memory length: 215272   epsilon: 0.7717594600049549    steps: 169    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 1167   score: 2.0   memory length: 215491   epsilon: 0.7713258400049643    steps: 219    lr: 4e-05     evaluation reward: 1.92\n",
      "episode: 1168   score: 1.0   memory length: 215660   epsilon: 0.7709912200049716    steps: 169    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 1169   score: 1.0   memory length: 215829   epsilon: 0.7706566000049788    steps: 169    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 1170   score: 0.0   memory length: 215952   epsilon: 0.7704130600049841    steps: 123    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1171   score: 3.0   memory length: 216183   epsilon: 0.769955680004994    steps: 231    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1172   score: 2.0   memory length: 216365   epsilon: 0.7695953200050019    steps: 182    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1173   score: 4.0   memory length: 216663   epsilon: 0.7690052800050147    steps: 298    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 1174   score: 2.0   memory length: 216845   epsilon: 0.7686449200050225    steps: 182    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1175   score: 2.0   memory length: 217043   epsilon: 0.768252880005031    steps: 198    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1176   score: 0.0   memory length: 217166   epsilon: 0.7680093400050363    steps: 123    lr: 4e-05     evaluation reward: 1.92\n",
      "episode: 1177   score: 6.0   memory length: 217517   epsilon: 0.7673143600050514    steps: 351    lr: 4e-05     evaluation reward: 1.95\n",
      "episode: 1178   score: 1.0   memory length: 217686   epsilon: 0.7669797400050586    steps: 169    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1179   score: 1.0   memory length: 217836   epsilon: 0.7666827400050651    steps: 150    lr: 4e-05     evaluation reward: 1.92\n",
      "episode: 1180   score: 5.0   memory length: 218144   epsilon: 0.7660729000050783    steps: 308    lr: 4e-05     evaluation reward: 1.95\n",
      "episode: 1181   score: 0.0   memory length: 218267   epsilon: 0.7658293600050836    steps: 123    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 1182   score: 1.0   memory length: 218439   epsilon: 0.765488800005091    steps: 172    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1183   score: 5.0   memory length: 218744   epsilon: 0.7648849000051041    steps: 305    lr: 4e-05     evaluation reward: 1.99\n",
      "episode: 1184   score: 0.0   memory length: 218867   epsilon: 0.7646413600051094    steps: 123    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 1185   score: 3.0   memory length: 219097   epsilon: 0.7641859600051193    steps: 230    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 1186   score: 6.0   memory length: 219447   epsilon: 0.7634929600051343    steps: 350    lr: 4e-05     evaluation reward: 2.04\n",
      "episode: 1187   score: 1.0   memory length: 219616   epsilon: 0.7631583400051416    steps: 169    lr: 4e-05     evaluation reward: 2.03\n",
      "episode: 1188   score: 0.0   memory length: 219739   epsilon: 0.7629148000051469    steps: 123    lr: 4e-05     evaluation reward: 1.99\n",
      "episode: 1189   score: 3.0   memory length: 220007   epsilon: 0.7623841600051584    steps: 268    lr: 4e-05     evaluation reward: 2.02\n",
      "episode: 1190   score: 0.0   memory length: 220130   epsilon: 0.7621406200051637    steps: 123    lr: 4e-05     evaluation reward: 2.02\n",
      "episode: 1191   score: 6.0   memory length: 220501   epsilon: 0.7614060400051796    steps: 371    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 1192   score: 4.0   memory length: 220777   epsilon: 0.7608595600051915    steps: 276    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1193   score: 3.0   memory length: 220989   epsilon: 0.7604398000052006    steps: 212    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1194   score: 3.0   memory length: 221217   epsilon: 0.7599883600052104    steps: 228    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1195   score: 0.0   memory length: 221339   epsilon: 0.7597468000052157    steps: 122    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 1196   score: 6.0   memory length: 221669   epsilon: 0.7590934000052298    steps: 330    lr: 4e-05     evaluation reward: 2.14\n",
      "episode: 1197   score: 1.0   memory length: 221819   epsilon: 0.7587964000052363    steps: 150    lr: 4e-05     evaluation reward: 2.12\n",
      "episode: 1198   score: 3.0   memory length: 222047   epsilon: 0.7583449600052461    steps: 228    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1199   score: 3.0   memory length: 222273   epsilon: 0.7578974800052558    steps: 226    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1200   score: 2.0   memory length: 222454   epsilon: 0.7575391000052636    steps: 181    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1201   score: 2.0   memory length: 222672   epsilon: 0.757107460005273    steps: 218    lr: 4e-05     evaluation reward: 2.12\n",
      "episode: 1202   score: 4.0   memory length: 222965   epsilon: 0.7565273200052856    steps: 293    lr: 4e-05     evaluation reward: 2.12\n",
      "episode: 1203   score: 5.0   memory length: 223328   epsilon: 0.7558085800053012    steps: 363    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 1204   score: 1.0   memory length: 223479   epsilon: 0.7555096000053076    steps: 151    lr: 4e-05     evaluation reward: 2.13\n",
      "episode: 1205   score: 4.0   memory length: 223741   epsilon: 0.7549908400053189    steps: 262    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 1206   score: 2.0   memory length: 223939   epsilon: 0.7545988000053274    steps: 198    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1207   score: 1.0   memory length: 224109   epsilon: 0.7542622000053347    steps: 170    lr: 4e-05     evaluation reward: 2.19\n",
      "episode: 1208   score: 2.0   memory length: 224308   epsilon: 0.7538681800053433    steps: 199    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1209   score: 3.0   memory length: 224571   epsilon: 0.7533474400053546    steps: 263    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1210   score: 6.0   memory length: 224948   epsilon: 0.7526009800053708    steps: 377    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1211   score: 3.0   memory length: 225175   epsilon: 0.7521515200053805    steps: 227    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1212   score: 0.0   memory length: 225298   epsilon: 0.7519079800053858    steps: 123    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1213   score: 2.0   memory length: 225477   epsilon: 0.7515535600053935    steps: 179    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1214   score: 4.0   memory length: 225734   epsilon: 0.7510447000054046    steps: 257    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1215   score: 0.0   memory length: 225857   epsilon: 0.7508011600054099    steps: 123    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1216   score: 2.0   memory length: 226076   epsilon: 0.7503675400054193    steps: 219    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1217   score: 1.0   memory length: 226245   epsilon: 0.7500329200054265    steps: 169    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1218   score: 4.0   memory length: 226539   epsilon: 0.7494508000054392    steps: 294    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1219   score: 6.0   memory length: 226887   epsilon: 0.7487617600054541    steps: 348    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1220   score: 1.0   memory length: 227039   epsilon: 0.7484608000054607    steps: 152    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1221   score: 2.0   memory length: 227257   epsilon: 0.74802916000547    steps: 218    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1222   score: 3.0   memory length: 227468   epsilon: 0.7476113800054791    steps: 211    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1223   score: 5.0   memory length: 227760   epsilon: 0.7470332200054917    steps: 292    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1224   score: 1.0   memory length: 227911   epsilon: 0.7467342400054982    steps: 151    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1225   score: 3.0   memory length: 228139   epsilon: 0.746282800005508    steps: 228    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1226   score: 3.0   memory length: 228366   epsilon: 0.7458333400055177    steps: 227    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1227   score: 1.0   memory length: 228517   epsilon: 0.7455343600055242    steps: 151    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1228   score: 2.0   memory length: 228734   epsilon: 0.7451047000055335    steps: 217    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1229   score: 6.0   memory length: 229088   epsilon: 0.7444037800055487    steps: 354    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1230   score: 2.0   memory length: 229307   epsilon: 0.7439701600055582    steps: 219    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1231   score: 4.0   memory length: 229587   epsilon: 0.7434157600055702    steps: 280    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1232   score: 3.0   memory length: 229815   epsilon: 0.74296432000558    steps: 228    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1233   score: 0.0   memory length: 229937   epsilon: 0.7427227600055852    steps: 122    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1234   score: 4.0   memory length: 230232   epsilon: 0.7421386600055979    steps: 295    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1235   score: 1.0   memory length: 230383   epsilon: 0.7418396800056044    steps: 151    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1236   score: 5.0   memory length: 230727   epsilon: 0.7411585600056192    steps: 344    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1237   score: 2.0   memory length: 230927   epsilon: 0.7407625600056278    steps: 200    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1238   score: 4.0   memory length: 231204   epsilon: 0.7402141000056397    steps: 277    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1239   score: 4.0   memory length: 231503   epsilon: 0.7396220800056525    steps: 299    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1240   score: 3.0   memory length: 231750   epsilon: 0.7391330200056632    steps: 247    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1241   score: 4.0   memory length: 232045   epsilon: 0.7385489200056758    steps: 295    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1242   score: 2.0   memory length: 232264   epsilon: 0.7381153000056853    steps: 219    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1243   score: 0.0   memory length: 232387   epsilon: 0.7378717600056905    steps: 123    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1244   score: 1.0   memory length: 232556   epsilon: 0.7375371400056978    steps: 169    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1245   score: 0.0   memory length: 232678   epsilon: 0.737295580005703    steps: 122    lr: 4e-05     evaluation reward: 2.53\n",
      "episode: 1246   score: 2.0   memory length: 232879   epsilon: 0.7368976000057117    steps: 201    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1247   score: 3.0   memory length: 233124   epsilon: 0.7364125000057222    steps: 245    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1248   score: 1.0   memory length: 233293   epsilon: 0.7360778800057295    steps: 169    lr: 4e-05     evaluation reward: 2.49\n",
      "episode: 1249   score: 3.0   memory length: 233502   epsilon: 0.7356640600057385    steps: 209    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1250   score: 0.0   memory length: 233625   epsilon: 0.7354205200057438    steps: 123    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1251   score: 2.0   memory length: 233843   epsilon: 0.7349888800057531    steps: 218    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1252   score: 0.0   memory length: 233966   epsilon: 0.7347453400057584    steps: 123    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1253   score: 1.0   memory length: 234135   epsilon: 0.7344107200057657    steps: 169    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1254   score: 7.0   memory length: 234538   epsilon: 0.733612780005783    steps: 403    lr: 4e-05     evaluation reward: 2.47\n",
      "episode: 1255   score: 4.0   memory length: 234813   epsilon: 0.7330682800057948    steps: 275    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1256   score: 3.0   memory length: 235060   epsilon: 0.7325792200058054    steps: 247    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1257   score: 6.0   memory length: 235461   epsilon: 0.7317852400058227    steps: 401    lr: 4e-05     evaluation reward: 2.53\n",
      "episode: 1258   score: 1.0   memory length: 235612   epsilon: 0.7314862600058292    steps: 151    lr: 4e-05     evaluation reward: 2.53\n",
      "episode: 1259   score: 3.0   memory length: 235822   epsilon: 0.7310704600058382    steps: 210    lr: 4e-05     evaluation reward: 2.49\n",
      "episode: 1260   score: 5.0   memory length: 236137   epsilon: 0.7304467600058517    steps: 315    lr: 4e-05     evaluation reward: 2.49\n",
      "episode: 1261   score: 2.0   memory length: 236317   epsilon: 0.7300903600058595    steps: 180    lr: 4e-05     evaluation reward: 2.49\n",
      "episode: 1262   score: 2.0   memory length: 236517   epsilon: 0.7296943600058681    steps: 200    lr: 4e-05     evaluation reward: 2.51\n",
      "episode: 1263   score: 4.0   memory length: 236767   epsilon: 0.7291993600058788    steps: 250    lr: 4e-05     evaluation reward: 2.53\n",
      "episode: 1264   score: 3.0   memory length: 237028   epsilon: 0.72868258000589    steps: 261    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1265   score: 4.0   memory length: 237325   epsilon: 0.7280945200059028    steps: 297    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1266   score: 2.0   memory length: 237505   epsilon: 0.7277381200059105    steps: 180    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1267   score: 3.0   memory length: 237733   epsilon: 0.7272866800059203    steps: 228    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1268   score: 4.0   memory length: 238046   epsilon: 0.7266669400059338    steps: 313    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1269   score: 1.0   memory length: 238197   epsilon: 0.7263679600059403    steps: 151    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1270   score: 1.0   memory length: 238367   epsilon: 0.7260313600059476    steps: 170    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1271   score: 1.0   memory length: 238537   epsilon: 0.7256947600059549    steps: 170    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1272   score: 2.0   memory length: 238735   epsilon: 0.7253027200059634    steps: 198    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1273   score: 0.0   memory length: 238858   epsilon: 0.7250591800059687    steps: 123    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1274   score: 5.0   memory length: 239167   epsilon: 0.724447360005982    steps: 309    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1275   score: 3.0   memory length: 239412   epsilon: 0.7239622600059925    steps: 245    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1276   score: 1.0   memory length: 239564   epsilon: 0.723661300005999    steps: 152    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1277   score: 3.0   memory length: 239791   epsilon: 0.7232118400060088    steps: 227    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1278   score: 0.0   memory length: 239914   epsilon: 0.7229683000060141    steps: 123    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1279   score: 3.0   memory length: 240158   epsilon: 0.7224851800060246    steps: 244    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1280   score: 2.0   memory length: 240356   epsilon: 0.7220931400060331    steps: 198    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1281   score: 3.0   memory length: 240600   epsilon: 0.7216100200060436    steps: 244    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1282   score: 5.0   memory length: 240910   epsilon: 0.7209962200060569    steps: 310    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1283   score: 1.0   memory length: 241081   epsilon: 0.7206576400060642    steps: 171    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1284   score: 4.0   memory length: 241376   epsilon: 0.7200735400060769    steps: 295    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1285   score: 2.0   memory length: 241574   epsilon: 0.7196815000060854    steps: 198    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1286   score: 3.0   memory length: 241785   epsilon: 0.7192637200060945    steps: 211    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1287   score: 3.0   memory length: 242011   epsilon: 0.7188162400061042    steps: 226    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1288   score: 5.0   memory length: 242335   epsilon: 0.7181747200061182    steps: 324    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1289   score: 3.0   memory length: 242548   epsilon: 0.7177529800061273    steps: 213    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1290   score: 6.0   memory length: 242867   epsilon: 0.717121360006141    steps: 319    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1291   score: 0.0   memory length: 242989   epsilon: 0.7168798000061463    steps: 122    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1292   score: 3.0   memory length: 243216   epsilon: 0.716430340006156    steps: 227    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1293   score: 4.0   memory length: 243489   epsilon: 0.7158898000061678    steps: 273    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1294   score: 1.0   memory length: 243640   epsilon: 0.7155908200061742    steps: 151    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1295   score: 4.0   memory length: 243935   epsilon: 0.7150067200061869    steps: 295    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1296   score: 8.0   memory length: 244277   epsilon: 0.7143295600062016    steps: 342    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1297   score: 3.0   memory length: 244543   epsilon: 0.7138028800062131    steps: 266    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1298   score: 2.0   memory length: 244725   epsilon: 0.7134425200062209    steps: 182    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1299   score: 3.0   memory length: 244951   epsilon: 0.7129950400062306    steps: 226    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1300   score: 5.0   memory length: 245240   epsilon: 0.712422820006243    steps: 289    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1301   score: 3.0   memory length: 245485   epsilon: 0.7119377200062535    steps: 245    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1302   score: 1.0   memory length: 245636   epsilon: 0.71163874000626    steps: 151    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1303   score: 1.0   memory length: 245787   epsilon: 0.7113397600062665    steps: 151    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1304   score: 0.0   memory length: 245910   epsilon: 0.7110962200062718    steps: 123    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1305   score: 5.0   memory length: 246225   epsilon: 0.7104725200062854    steps: 315    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1306   score: 1.0   memory length: 246396   epsilon: 0.7101339400062927    steps: 171    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1307   score: 1.0   memory length: 246547   epsilon: 0.7098349600062992    steps: 151    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1308   score: 5.0   memory length: 246892   epsilon: 0.709151860006314    steps: 345    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1309   score: 2.0   memory length: 247072   epsilon: 0.7087954600063218    steps: 180    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1310   score: 3.0   memory length: 247319   epsilon: 0.7083064000063324    steps: 247    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1311   score: 5.0   memory length: 247629   epsilon: 0.7076926000063457    steps: 310    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1312   score: 3.0   memory length: 247898   epsilon: 0.7071599800063573    steps: 269    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1313   score: 5.0   memory length: 248222   epsilon: 0.7065184600063712    steps: 324    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1314   score: 4.0   memory length: 248497   epsilon: 0.705973960006383    steps: 275    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1315   score: 2.0   memory length: 248695   epsilon: 0.7055819200063915    steps: 198    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1316   score: 2.0   memory length: 248892   epsilon: 0.7051918600064    steps: 197    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1317   score: 4.0   memory length: 249165   epsilon: 0.7046513200064117    steps: 273    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1318   score: 4.0   memory length: 249429   epsilon: 0.7041286000064231    steps: 264    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1319   score: 4.0   memory length: 249704   epsilon: 0.7035841000064349    steps: 275    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1320   score: 3.0   memory length: 249949   epsilon: 0.7030990000064454    steps: 245    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1321   score: 1.0   memory length: 250100   epsilon: 0.7028000200064519    steps: 151    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1322   score: 3.0   memory length: 250348   epsilon: 0.7023089800064626    steps: 248    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1323   score: 2.0   memory length: 250566   epsilon: 0.701877340006472    steps: 218    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1324   score: 5.0   memory length: 250846   epsilon: 0.701322940006484    steps: 280    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1325   score: 2.0   memory length: 251045   epsilon: 0.7009289200064925    steps: 199    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1326   score: 0.0   memory length: 251168   epsilon: 0.7006853800064978    steps: 123    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1327   score: 6.0   memory length: 251534   epsilon: 0.6999607000065136    steps: 366    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1328   score: 8.0   memory length: 251992   epsilon: 0.6990538600065332    steps: 458    lr: 4e-05     evaluation reward: 2.85\n",
      "episode: 1329   score: 3.0   memory length: 252266   epsilon: 0.698511340006545    steps: 274    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1330   score: 4.0   memory length: 252508   epsilon: 0.6980321800065554    steps: 242    lr: 4e-05     evaluation reward: 2.84\n",
      "episode: 1331   score: 1.0   memory length: 252660   epsilon: 0.697731220006562    steps: 152    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1332   score: 1.0   memory length: 252811   epsilon: 0.6974322400065684    steps: 151    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1333   score: 5.0   memory length: 253161   epsilon: 0.6967392400065835    steps: 350    lr: 4e-05     evaluation reward: 2.84\n",
      "episode: 1334   score: 7.0   memory length: 253577   epsilon: 0.6959155600066014    steps: 416    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1335   score: 4.0   memory length: 253856   epsilon: 0.6953631400066134    steps: 279    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1336   score: 4.0   memory length: 254121   epsilon: 0.6948384400066248    steps: 265    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1337   score: 2.0   memory length: 254320   epsilon: 0.6944444200066333    steps: 199    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1338   score: 3.0   memory length: 254584   epsilon: 0.6939217000066447    steps: 264    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1339   score: 2.0   memory length: 254785   epsilon: 0.6935237200066533    steps: 201    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1340   score: 2.0   memory length: 254983   epsilon: 0.6931316800066618    steps: 198    lr: 4e-05     evaluation reward: 2.85\n",
      "episode: 1341   score: 7.0   memory length: 255368   epsilon: 0.6923693800066784    steps: 385    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1342   score: 4.0   memory length: 255643   epsilon: 0.6918248800066902    steps: 275    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1343   score: 2.0   memory length: 255825   epsilon: 0.691464520006698    steps: 182    lr: 4e-05     evaluation reward: 2.92\n",
      "episode: 1344   score: 0.0   memory length: 255947   epsilon: 0.6912229600067032    steps: 122    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1345   score: 3.0   memory length: 256180   epsilon: 0.6907616200067133    steps: 233    lr: 4e-05     evaluation reward: 2.94\n",
      "episode: 1346   score: 3.0   memory length: 256426   epsilon: 0.6902745400067238    steps: 246    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1347   score: 4.0   memory length: 256683   epsilon: 0.6897656800067349    steps: 257    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1348   score: 4.0   memory length: 256996   epsilon: 0.6891459400067483    steps: 313    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1349   score: 4.0   memory length: 257255   epsilon: 0.6886331200067595    steps: 259    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1350   score: 6.0   memory length: 257574   epsilon: 0.6880015000067732    steps: 319    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1351   score: 0.0   memory length: 257696   epsilon: 0.6877599400067784    steps: 122    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1352   score: 5.0   memory length: 258019   epsilon: 0.6871204000067923    steps: 323    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1353   score: 0.0   memory length: 258142   epsilon: 0.6868768600067976    steps: 123    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1354   score: 7.0   memory length: 258444   epsilon: 0.6862789000068106    steps: 302    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1355   score: 3.0   memory length: 258674   epsilon: 0.6858235000068205    steps: 230    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1356   score: 5.0   memory length: 258999   epsilon: 0.6851800000068344    steps: 325    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1357   score: 2.0   memory length: 259198   epsilon: 0.684785980006843    steps: 199    lr: 4e-05     evaluation reward: 3.05\n",
      "episode: 1358   score: 3.0   memory length: 259445   epsilon: 0.6842969200068536    steps: 247    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1359   score: 9.0   memory length: 259785   epsilon: 0.6836237200068682    steps: 340    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1360   score: 4.0   memory length: 260081   epsilon: 0.6830376400068809    steps: 296    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1361   score: 1.0   memory length: 260232   epsilon: 0.6827386600068874    steps: 151    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1362   score: 4.0   memory length: 260471   epsilon: 0.6822654400068977    steps: 239    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1363   score: 6.0   memory length: 260843   epsilon: 0.6815288800069137    steps: 372    lr: 4e-05     evaluation reward: 3.15\n",
      "episode: 1364   score: 5.0   memory length: 261145   epsilon: 0.6809309200069267    steps: 302    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1365   score: 5.0   memory length: 261448   epsilon: 0.6803309800069397    steps: 303    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1366   score: 7.0   memory length: 261885   epsilon: 0.6794657200069585    steps: 437    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1367   score: 6.0   memory length: 262299   epsilon: 0.6786460000069763    steps: 414    lr: 4e-05     evaluation reward: 3.26\n",
      "episode: 1368   score: 3.0   memory length: 262530   epsilon: 0.6781886200069862    steps: 231    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1369   score: 1.0   memory length: 262680   epsilon: 0.6778916200069927    steps: 150    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1370   score: 3.0   memory length: 262926   epsilon: 0.6774045400070032    steps: 246    lr: 4e-05     evaluation reward: 3.27\n",
      "episode: 1371   score: 2.0   memory length: 263123   epsilon: 0.6770144800070117    steps: 197    lr: 4e-05     evaluation reward: 3.28\n",
      "episode: 1372   score: 5.0   memory length: 263419   epsilon: 0.6764284000070244    steps: 296    lr: 4e-05     evaluation reward: 3.31\n",
      "episode: 1373   score: 2.0   memory length: 263636   epsilon: 0.6759987400070337    steps: 217    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1374   score: 1.0   memory length: 263807   epsilon: 0.6756601600070411    steps: 171    lr: 4e-05     evaluation reward: 3.29\n",
      "episode: 1375   score: 5.0   memory length: 264153   epsilon: 0.674975080007056    steps: 346    lr: 4e-05     evaluation reward: 3.31\n",
      "episode: 1376   score: 7.0   memory length: 264590   epsilon: 0.6741098200070748    steps: 437    lr: 4e-05     evaluation reward: 3.37\n",
      "episode: 1377   score: 4.0   memory length: 264866   epsilon: 0.6735633400070866    steps: 276    lr: 4e-05     evaluation reward: 3.38\n",
      "episode: 1378   score: 4.0   memory length: 265142   epsilon: 0.6730168600070985    steps: 276    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1379   score: 1.0   memory length: 265293   epsilon: 0.672717880007105    steps: 151    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1380   score: 3.0   memory length: 265519   epsilon: 0.6722704000071147    steps: 226    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1381   score: 3.0   memory length: 265784   epsilon: 0.6717457000071261    steps: 265    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1382   score: 5.0   memory length: 266107   epsilon: 0.67110616000714    steps: 323    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1383   score: 1.0   memory length: 266257   epsilon: 0.6708091600071464    steps: 150    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1384   score: 3.0   memory length: 266509   epsilon: 0.6703102000071572    steps: 252    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1385   score: 2.0   memory length: 266691   epsilon: 0.6699498400071651    steps: 182    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1386   score: 6.0   memory length: 267071   epsilon: 0.6691974400071814    steps: 380    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1387   score: 3.0   memory length: 267300   epsilon: 0.6687440200071912    steps: 229    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1388   score: 2.0   memory length: 267481   epsilon: 0.668385640007199    steps: 181    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1389   score: 4.0   memory length: 267721   epsilon: 0.6679104400072093    steps: 240    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1390   score: 6.0   memory length: 268073   epsilon: 0.6672134800072245    steps: 352    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1391   score: 3.0   memory length: 268299   epsilon: 0.6667660000072342    steps: 226    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1392   score: 2.0   memory length: 268517   epsilon: 0.6663343600072436    steps: 218    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1393   score: 4.0   memory length: 268811   epsilon: 0.6657522400072562    steps: 294    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1394   score: 3.0   memory length: 269060   epsilon: 0.6652592200072669    steps: 249    lr: 4e-05     evaluation reward: 3.45\n",
      "episode: 1395   score: 5.0   memory length: 269404   epsilon: 0.6645781000072817    steps: 344    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1396   score: 4.0   memory length: 269647   epsilon: 0.6640969600072921    steps: 243    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1397   score: 3.0   memory length: 269896   epsilon: 0.6636039400073028    steps: 249    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1398   score: 5.0   memory length: 270197   epsilon: 0.6630079600073158    steps: 301    lr: 4e-05     evaluation reward: 3.45\n",
      "episode: 1399   score: 1.0   memory length: 270367   epsilon: 0.6626713600073231    steps: 170    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1400   score: 2.0   memory length: 270585   epsilon: 0.6622397200073324    steps: 218    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1401   score: 5.0   memory length: 270931   epsilon: 0.6615546400073473    steps: 346    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1402   score: 3.0   memory length: 271160   epsilon: 0.6611012200073572    steps: 229    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1403   score: 3.0   memory length: 271407   epsilon: 0.6606121600073678    steps: 247    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1404   score: 4.0   memory length: 271727   epsilon: 0.6599785600073815    steps: 320    lr: 4e-05     evaluation reward: 3.5\n",
      "episode: 1405   score: 3.0   memory length: 271937   epsilon: 0.6595627600073906    steps: 210    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1406   score: 2.0   memory length: 272134   epsilon: 0.659172700007399    steps: 197    lr: 4e-05     evaluation reward: 3.49\n",
      "episode: 1407   score: 4.0   memory length: 272427   epsilon: 0.6585925600074116    steps: 293    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1408   score: 0.0   memory length: 272550   epsilon: 0.6583490200074169    steps: 123    lr: 4e-05     evaluation reward: 3.47\n",
      "episode: 1409   score: 2.0   memory length: 272748   epsilon: 0.6579569800074254    steps: 198    lr: 4e-05     evaluation reward: 3.47\n",
      "episode: 1410   score: 2.0   memory length: 272965   epsilon: 0.6575273200074347    steps: 217    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1411   score: 3.0   memory length: 273212   epsilon: 0.6570382600074454    steps: 247    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1412   score: 1.0   memory length: 273363   epsilon: 0.6567392800074519    steps: 151    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1413   score: 6.0   memory length: 273757   epsilon: 0.6559591600074688    steps: 394    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1414   score: 4.0   memory length: 274034   epsilon: 0.6554107000074807    steps: 277    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1415   score: 5.0   memory length: 274380   epsilon: 0.6547256200074956    steps: 346    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1416   score: 4.0   memory length: 274622   epsilon: 0.654246460007506    steps: 242    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1417   score: 3.0   memory length: 274851   epsilon: 0.6537930400075158    steps: 229    lr: 4e-05     evaluation reward: 3.47\n",
      "episode: 1418   score: 4.0   memory length: 275144   epsilon: 0.6532129000075284    steps: 293    lr: 4e-05     evaluation reward: 3.47\n",
      "episode: 1419   score: 2.0   memory length: 275344   epsilon: 0.652816900007537    steps: 200    lr: 4e-05     evaluation reward: 3.45\n",
      "episode: 1420   score: 9.0   memory length: 275716   epsilon: 0.652080340007553    steps: 372    lr: 4e-05     evaluation reward: 3.51\n",
      "episode: 1421   score: 3.0   memory length: 275944   epsilon: 0.6516289000075628    steps: 228    lr: 4e-05     evaluation reward: 3.53\n",
      "episode: 1422   score: 4.0   memory length: 276239   epsilon: 0.6510448000075755    steps: 295    lr: 4e-05     evaluation reward: 3.54\n",
      "episode: 1423   score: 2.0   memory length: 276437   epsilon: 0.650652760007584    steps: 198    lr: 4e-05     evaluation reward: 3.54\n",
      "episode: 1424   score: 3.0   memory length: 276667   epsilon: 0.6501973600075939    steps: 230    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1425   score: 6.0   memory length: 276997   epsilon: 0.6495439600076081    steps: 330    lr: 4e-05     evaluation reward: 3.56\n",
      "episode: 1426   score: 5.0   memory length: 277296   epsilon: 0.6489519400076209    steps: 299    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1427   score: 6.0   memory length: 277686   epsilon: 0.6481797400076377    steps: 390    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1428   score: 3.0   memory length: 277899   epsilon: 0.6477580000076468    steps: 213    lr: 4e-05     evaluation reward: 3.56\n",
      "episode: 1429   score: 4.0   memory length: 278157   epsilon: 0.6472471600076579    steps: 258    lr: 4e-05     evaluation reward: 3.57\n",
      "episode: 1430   score: 4.0   memory length: 278434   epsilon: 0.6466987000076698    steps: 277    lr: 4e-05     evaluation reward: 3.57\n",
      "episode: 1431   score: 2.0   memory length: 278634   epsilon: 0.6463027000076784    steps: 200    lr: 4e-05     evaluation reward: 3.58\n",
      "episode: 1432   score: 4.0   memory length: 278891   epsilon: 0.6457938400076895    steps: 257    lr: 4e-05     evaluation reward: 3.61\n",
      "episode: 1433   score: 6.0   memory length: 279264   epsilon: 0.6450553000077055    steps: 373    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1434   score: 9.0   memory length: 279774   epsilon: 0.6440455000077274    steps: 510    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1435   score: 6.0   memory length: 280139   epsilon: 0.6433228000077431    steps: 365    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1436   score: 1.0   memory length: 280308   epsilon: 0.6429881800077504    steps: 169    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1437   score: 4.0   memory length: 280601   epsilon: 0.642408040007763    steps: 293    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1438   score: 1.0   memory length: 280752   epsilon: 0.6421090600077695    steps: 151    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1439   score: 4.0   memory length: 281012   epsilon: 0.6415942600077806    steps: 260    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1440   score: 1.0   memory length: 281162   epsilon: 0.6412972600077871    steps: 150    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1441   score: 2.0   memory length: 281382   epsilon: 0.6408616600077965    steps: 220    lr: 4e-05     evaluation reward: 3.59\n",
      "episode: 1442   score: 3.0   memory length: 281629   epsilon: 0.6403726000078072    steps: 247    lr: 4e-05     evaluation reward: 3.58\n",
      "episode: 1443   score: 4.0   memory length: 281889   epsilon: 0.6398578000078183    steps: 260    lr: 4e-05     evaluation reward: 3.6\n",
      "episode: 1444   score: 2.0   memory length: 282089   epsilon: 0.6394618000078269    steps: 200    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1445   score: 4.0   memory length: 282327   epsilon: 0.6389905600078372    steps: 238    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1446   score: 3.0   memory length: 282572   epsilon: 0.6385054600078477    steps: 245    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1447   score: 3.0   memory length: 282802   epsilon: 0.6380500600078576    steps: 230    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1448   score: 8.0   memory length: 283268   epsilon: 0.6371273800078776    steps: 466    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1449   score: 3.0   memory length: 283493   epsilon: 0.6366818800078873    steps: 225    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1450   score: 4.0   memory length: 283769   epsilon: 0.6361354000078991    steps: 276    lr: 4e-05     evaluation reward: 3.63\n",
      "episode: 1451   score: 1.0   memory length: 283920   epsilon: 0.6358364200079056    steps: 151    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1452   score: 5.0   memory length: 284199   epsilon: 0.6352840000079176    steps: 279    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1453   score: 5.0   memory length: 284488   epsilon: 0.63471178000793    steps: 289    lr: 4e-05     evaluation reward: 3.69\n",
      "episode: 1454   score: 4.0   memory length: 284748   epsilon: 0.6341969800079412    steps: 260    lr: 4e-05     evaluation reward: 3.66\n",
      "episode: 1455   score: 5.0   memory length: 285055   epsilon: 0.6335891200079544    steps: 307    lr: 4e-05     evaluation reward: 3.68\n",
      "episode: 1456   score: 2.0   memory length: 285253   epsilon: 0.6331970800079629    steps: 198    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1457   score: 4.0   memory length: 285527   epsilon: 0.6326545600079747    steps: 274    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1458   score: 5.0   memory length: 285841   epsilon: 0.6320328400079882    steps: 314    lr: 4e-05     evaluation reward: 3.69\n",
      "episode: 1459   score: 5.0   memory length: 286150   epsilon: 0.6314210200080015    steps: 309    lr: 4e-05     evaluation reward: 3.65\n",
      "episode: 1460   score: 6.0   memory length: 286478   epsilon: 0.6307715800080156    steps: 328    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1461   score: 3.0   memory length: 286726   epsilon: 0.6302805400080262    steps: 248    lr: 4e-05     evaluation reward: 3.69\n",
      "episode: 1462   score: 2.0   memory length: 286942   epsilon: 0.6298528600080355    steps: 216    lr: 4e-05     evaluation reward: 3.67\n",
      "episode: 1463   score: 3.0   memory length: 287189   epsilon: 0.6293638000080461    steps: 247    lr: 4e-05     evaluation reward: 3.64\n",
      "episode: 1464   score: 3.0   memory length: 287419   epsilon: 0.628908400008056    steps: 230    lr: 4e-05     evaluation reward: 3.62\n",
      "episode: 1465   score: 1.0   memory length: 287570   epsilon: 0.6286094200080625    steps: 151    lr: 4e-05     evaluation reward: 3.58\n",
      "episode: 1466   score: 2.0   memory length: 287751   epsilon: 0.6282510400080703    steps: 181    lr: 4e-05     evaluation reward: 3.53\n",
      "episode: 1467   score: 4.0   memory length: 288044   epsilon: 0.6276709000080829    steps: 293    lr: 4e-05     evaluation reward: 3.51\n",
      "episode: 1468   score: 4.0   memory length: 288324   epsilon: 0.6271165000080949    steps: 280    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1469   score: 2.0   memory length: 288521   epsilon: 0.6267264400081034    steps: 197    lr: 4e-05     evaluation reward: 3.53\n",
      "episode: 1470   score: 0.0   memory length: 288644   epsilon: 0.6264829000081087    steps: 123    lr: 4e-05     evaluation reward: 3.5\n",
      "episode: 1471   score: 4.0   memory length: 288918   epsilon: 0.6259403800081205    steps: 274    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1472   score: 5.0   memory length: 289240   epsilon: 0.6253028200081343    steps: 322    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1473   score: 6.0   memory length: 289582   epsilon: 0.624625660008149    steps: 342    lr: 4e-05     evaluation reward: 3.56\n",
      "episode: 1474   score: 2.0   memory length: 289780   epsilon: 0.6242336200081575    steps: 198    lr: 4e-05     evaluation reward: 3.57\n",
      "episode: 1475   score: 2.0   memory length: 289998   epsilon: 0.6238019800081669    steps: 218    lr: 4e-05     evaluation reward: 3.54\n",
      "episode: 1476   score: 1.0   memory length: 290167   epsilon: 0.6234673600081742    steps: 169    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1477   score: 2.0   memory length: 290351   epsilon: 0.6231030400081821    steps: 184    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1478   score: 4.0   memory length: 290644   epsilon: 0.6225229000081947    steps: 293    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1479   score: 2.0   memory length: 290846   epsilon: 0.6221229400082033    steps: 202    lr: 4e-05     evaluation reward: 3.47\n",
      "episode: 1480   score: 4.0   memory length: 291105   epsilon: 0.6216101200082145    steps: 259    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1481   score: 5.0   memory length: 291427   epsilon: 0.6209725600082283    steps: 322    lr: 4e-05     evaluation reward: 3.5\n",
      "episode: 1482   score: 4.0   memory length: 291705   epsilon: 0.6204221200082403    steps: 278    lr: 4e-05     evaluation reward: 3.49\n",
      "episode: 1483   score: 3.0   memory length: 291933   epsilon: 0.6199706800082501    steps: 228    lr: 4e-05     evaluation reward: 3.51\n",
      "episode: 1484   score: 2.0   memory length: 292131   epsilon: 0.6195786400082586    steps: 198    lr: 4e-05     evaluation reward: 3.5\n",
      "episode: 1485   score: 5.0   memory length: 292474   epsilon: 0.6188995000082733    steps: 343    lr: 4e-05     evaluation reward: 3.53\n",
      "episode: 1486   score: 1.0   memory length: 292644   epsilon: 0.6185629000082806    steps: 170    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1487   score: 1.0   memory length: 292795   epsilon: 0.6182639200082871    steps: 151    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1488   score: 1.0   memory length: 292947   epsilon: 0.6179629600082936    steps: 152    lr: 4e-05     evaluation reward: 3.45\n",
      "episode: 1489   score: 4.0   memory length: 293204   epsilon: 0.6174541000083047    steps: 257    lr: 4e-05     evaluation reward: 3.45\n",
      "episode: 1490   score: 3.0   memory length: 293433   epsilon: 0.6170006800083145    steps: 229    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1491   score: 2.0   memory length: 293631   epsilon: 0.616608640008323    steps: 198    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1492   score: 2.0   memory length: 293811   epsilon: 0.6162522400083308    steps: 180    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1493   score: 3.0   memory length: 294041   epsilon: 0.6157968400083407    steps: 230    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1494   score: 3.0   memory length: 294269   epsilon: 0.6153454000083505    steps: 228    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1495   score: 1.0   memory length: 294420   epsilon: 0.615046420008357    steps: 151    lr: 4e-05     evaluation reward: 3.36\n",
      "episode: 1496   score: 5.0   memory length: 294727   epsilon: 0.6144385600083702    steps: 307    lr: 4e-05     evaluation reward: 3.37\n",
      "episode: 1497   score: 6.0   memory length: 295066   epsilon: 0.6137673400083847    steps: 339    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1498   score: 6.0   memory length: 295406   epsilon: 0.6130941400083993    steps: 340    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1499   score: 3.0   memory length: 295633   epsilon: 0.6126446800084091    steps: 227    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1500   score: 4.0   memory length: 295911   epsilon: 0.612094240008421    steps: 278    lr: 4e-05     evaluation reward: 3.45\n",
      "episode: 1501   score: 3.0   memory length: 296121   epsilon: 0.6116784400084301    steps: 210    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1502   score: 2.0   memory length: 296303   epsilon: 0.6113180800084379    steps: 182    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1503   score: 3.0   memory length: 296532   epsilon: 0.6108646600084477    steps: 229    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1504   score: 4.0   memory length: 296776   epsilon: 0.6103815400084582    steps: 244    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1505   score: 3.0   memory length: 297026   epsilon: 0.609886540008469    steps: 250    lr: 4e-05     evaluation reward: 3.42\n",
      "episode: 1506   score: 3.0   memory length: 297237   epsilon: 0.609468760008478    steps: 211    lr: 4e-05     evaluation reward: 3.43\n",
      "episode: 1507   score: 7.0   memory length: 297592   epsilon: 0.6087658600084933    steps: 355    lr: 4e-05     evaluation reward: 3.46\n",
      "episode: 1508   score: 2.0   memory length: 297810   epsilon: 0.6083342200085027    steps: 218    lr: 4e-05     evaluation reward: 3.48\n",
      "episode: 1509   score: 3.0   memory length: 298055   epsilon: 0.6078491200085132    steps: 245    lr: 4e-05     evaluation reward: 3.49\n",
      "episode: 1510   score: 3.0   memory length: 298303   epsilon: 0.6073580800085239    steps: 248    lr: 4e-05     evaluation reward: 3.5\n",
      "episode: 1511   score: 4.0   memory length: 298561   epsilon: 0.606847240008535    steps: 258    lr: 4e-05     evaluation reward: 3.51\n",
      "episode: 1512   score: 5.0   memory length: 298870   epsilon: 0.6062354200085482    steps: 309    lr: 4e-05     evaluation reward: 3.55\n",
      "episode: 1513   score: 3.0   memory length: 299098   epsilon: 0.605783980008558    steps: 228    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1514   score: 7.0   memory length: 299453   epsilon: 0.6050810800085733    steps: 355    lr: 4e-05     evaluation reward: 3.55\n",
      "episode: 1515   score: 2.0   memory length: 299671   epsilon: 0.6046494400085827    steps: 218    lr: 4e-05     evaluation reward: 3.52\n",
      "episode: 1516   score: 3.0   memory length: 299899   epsilon: 0.6041980000085925    steps: 228    lr: 4e-05     evaluation reward: 3.51\n",
      "episode: 1517   score: 5.0   memory length: 300225   epsilon: 0.6035525200086065    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1518   score: 5.0   memory length: 300522   epsilon: 0.6029644600086193    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1519   score: 4.0   memory length: 300779   epsilon: 0.6024556000086303    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1520   score: 4.0   memory length: 301018   epsilon: 0.6019823800086406    steps: 239    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n",
      "episode: 1521   score: 19.0   memory length: 301650   epsilon: 0.6007310200086677    steps: 632    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1522   score: 5.0   memory length: 301938   epsilon: 0.6001607800086801    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1523   score: 5.0   memory length: 302259   epsilon: 0.5995252000086939    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1524   score: 7.0   memory length: 302662   epsilon: 0.5987272600087112    steps: 403    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n",
      "episode: 1525   score: 5.0   memory length: 303010   epsilon: 0.5980382200087262    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1526   score: 5.0   memory length: 303318   epsilon: 0.5974283800087394    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1527   score: 3.0   memory length: 303528   epsilon: 0.5970125800087485    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1528   score: 6.0   memory length: 303885   epsilon: 0.5963057200087638    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1529   score: 1.0   memory length: 304054   epsilon: 0.5959711000087711    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1530   score: 5.0   memory length: 304398   epsilon: 0.5952899800087859    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1531   score: 7.0   memory length: 304770   epsilon: 0.5945534200088018    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1532   score: 6.0   memory length: 305080   epsilon: 0.5939396200088152    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1533   score: 4.0   memory length: 305354   epsilon: 0.593397100008827    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1534   score: 5.0   memory length: 305680   epsilon: 0.592751620008841    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1535   score: 5.0   memory length: 305988   epsilon: 0.5921417800088542    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1536   score: 7.0   memory length: 306397   epsilon: 0.5913319600088718    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1537   score: 2.0   memory length: 306595   epsilon: 0.5909399200088803    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n",
      "episode: 1538   score: 9.0   memory length: 307105   epsilon: 0.5899301200089022    steps: 510    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n",
      "episode: 1539   score: 5.0   memory length: 307428   epsilon: 0.5892905800089161    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n",
      "episode: 1540   score: 3.0   memory length: 307639   epsilon: 0.5888728000089252    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1541   score: 4.0   memory length: 307913   epsilon: 0.588330280008937    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1542   score: 2.0   memory length: 308131   epsilon: 0.5878986400089463    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1543   score: 9.0   memory length: 308631   epsilon: 0.5869086400089678    steps: 500    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n",
      "episode: 1544   score: 3.0   memory length: 308843   epsilon: 0.5864888800089769    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n",
      "episode: 1545   score: 2.0   memory length: 309043   epsilon: 0.5860928800089855    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n",
      "episode: 1546   score: 2.0   memory length: 309263   epsilon: 0.585657280008995    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n",
      "episode: 1547   score: 3.0   memory length: 309509   epsilon: 0.5851702000090055    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n",
      "episode: 1548   score: 4.0   memory length: 309802   epsilon: 0.5845900600090181    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1549   score: 6.0   memory length: 310159   epsilon: 0.5838832000090335    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1550   score: 1.0   memory length: 310309   epsilon: 0.5835862000090399    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1551   score: 4.0   memory length: 310584   epsilon: 0.5830417000090518    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1552   score: 3.0   memory length: 310812   epsilon: 0.5825902600090616    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1553   score: 5.0   memory length: 311162   epsilon: 0.5818972600090766    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1554   score: 2.0   memory length: 311343   epsilon: 0.5815388800090844    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n",
      "episode: 1555   score: 3.0   memory length: 311570   epsilon: 0.5810894200090941    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n",
      "episode: 1556   score: 3.0   memory length: 311798   epsilon: 0.5806379800091039    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n",
      "episode: 1557   score: 2.0   memory length: 311979   epsilon: 0.5802796000091117    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1558   score: 5.0   memory length: 312270   epsilon: 0.5797034200091242    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1559   score: 1.0   memory length: 312420   epsilon: 0.5794064200091307    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1560   score: 4.0   memory length: 312663   epsilon: 0.5789252800091411    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1561   score: 4.0   memory length: 312922   epsilon: 0.5784124600091523    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1562   score: 5.0   memory length: 313232   epsilon: 0.5777986600091656    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1563   score: 1.0   memory length: 313383   epsilon: 0.5774996800091721    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1564   score: 3.0   memory length: 313595   epsilon: 0.5770799200091812    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1565   score: 5.0   memory length: 313927   epsilon: 0.5764225600091955    steps: 332    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1566   score: 7.0   memory length: 314353   epsilon: 0.5755790800092138    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1567   score: 6.0   memory length: 314691   epsilon: 0.5749098400092283    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1568   score: 4.0   memory length: 314950   epsilon: 0.5743970200092394    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1569   score: 2.0   memory length: 315152   epsilon: 0.5739970600092481    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1570   score: 9.0   memory length: 315665   epsilon: 0.5729813200092702    steps: 513    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1571   score: 3.0   memory length: 315878   epsilon: 0.5725595800092793    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1572   score: 4.0   memory length: 316136   epsilon: 0.5720487400092904    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1573   score: 8.0   memory length: 316575   epsilon: 0.5711795200093093    steps: 439    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1574   score: 5.0   memory length: 316887   epsilon: 0.5705617600093227    steps: 312    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1575   score: 2.0   memory length: 317085   epsilon: 0.5701697200093312    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1576   score: 4.0   memory length: 317381   epsilon: 0.5695836400093439    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1577   score: 6.0   memory length: 317757   epsilon: 0.5688391600093601    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1578   score: 2.0   memory length: 317939   epsilon: 0.5684788000093679    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1579   score: 4.0   memory length: 318194   epsilon: 0.5679739000093789    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1580   score: 5.0   memory length: 318540   epsilon: 0.5672888200093937    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1581   score: 3.0   memory length: 318752   epsilon: 0.5668690600094028    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1582   score: 3.0   memory length: 318996   epsilon: 0.5663859400094133    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1583   score: 4.0   memory length: 319273   epsilon: 0.5658374800094252    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1584   score: 4.0   memory length: 319567   epsilon: 0.5652553600094379    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1585   score: 3.0   memory length: 319777   epsilon: 0.5648395600094469    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1586   score: 4.0   memory length: 320052   epsilon: 0.5642950600094587    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1587   score: 4.0   memory length: 320322   epsilon: 0.5637604600094703    steps: 270    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1588   score: 2.0   memory length: 320520   epsilon: 0.5633684200094788    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1589   score: 5.0   memory length: 320809   epsilon: 0.5627962000094913    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1590   score: 5.0   memory length: 321116   epsilon: 0.5621883400095045    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1591   score: 3.0   memory length: 321344   epsilon: 0.5617369000095143    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1592   score: 3.0   memory length: 321555   epsilon: 0.5613191200095233    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1593   score: 10.0   memory length: 322097   epsilon: 0.5602459600095466    steps: 542    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1594   score: 4.0   memory length: 322374   epsilon: 0.5596975000095585    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1595   score: 1.0   memory length: 322524   epsilon: 0.559400500009565    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1596   score: 4.0   memory length: 322802   epsilon: 0.5588500600095769    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1597   score: 2.0   memory length: 323000   epsilon: 0.5584580200095854    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1598   score: 5.0   memory length: 323349   epsilon: 0.5577670000096004    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1599   score: 4.0   memory length: 323607   epsilon: 0.5572561600096115    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1600   score: 5.0   memory length: 323900   epsilon: 0.5566760200096241    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1601   score: 0.0   memory length: 324023   epsilon: 0.5564324800096294    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1602   score: 2.0   memory length: 324220   epsilon: 0.5560424200096379    steps: 197    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1603   score: 6.0   memory length: 324596   epsilon: 0.555297940009654    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1604   score: 5.0   memory length: 324926   epsilon: 0.5546445400096682    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1605   score: 3.0   memory length: 325172   epsilon: 0.5541574600096788    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1606   score: 4.0   memory length: 325432   epsilon: 0.55364266000969    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1607   score: 3.0   memory length: 325677   epsilon: 0.5531575600097005    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1608   score: 3.0   memory length: 325906   epsilon: 0.5527041400097104    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1609   score: 1.0   memory length: 326057   epsilon: 0.5524051600097168    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1610   score: 4.0   memory length: 326334   epsilon: 0.5518567000097288    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1611   score: 7.0   memory length: 326761   epsilon: 0.5510112400097471    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1612   score: 2.0   memory length: 326942   epsilon: 0.5506528600097549    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1613   score: 3.0   memory length: 327171   epsilon: 0.5501994400097647    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1614   score: 2.0   memory length: 327351   epsilon: 0.5498430400097725    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1615   score: 4.0   memory length: 327630   epsilon: 0.5492906200097845    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1616   score: 5.0   memory length: 327956   epsilon: 0.5486451400097985    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1617   score: 2.0   memory length: 328156   epsilon: 0.5482491400098071    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1618   score: 2.0   memory length: 328337   epsilon: 0.5478907600098148    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1619   score: 4.0   memory length: 328599   epsilon: 0.5473720000098261    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1620   score: 5.0   memory length: 328926   epsilon: 0.5467245400098402    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1621   score: 4.0   memory length: 329220   epsilon: 0.5461424200098528    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1622   score: 5.0   memory length: 329533   epsilon: 0.5455226800098663    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1623   score: 3.0   memory length: 329761   epsilon: 0.5450712400098761    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1624   score: 5.0   memory length: 330052   epsilon: 0.5444950600098886    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1625   score: 6.0   memory length: 330427   epsilon: 0.5437525600099047    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1626   score: 3.0   memory length: 330674   epsilon: 0.5432635000099153    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1627   score: 2.0   memory length: 330889   epsilon: 0.5428378000099245    steps: 215    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1628   score: 4.0   memory length: 331149   epsilon: 0.5423230000099357    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n",
      "episode: 1629   score: 4.0   memory length: 331449   epsilon: 0.5417290000099486    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1630   score: 4.0   memory length: 331705   epsilon: 0.5412221200099596    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1631   score: 2.0   memory length: 331922   epsilon: 0.540792460009969    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1632   score: 10.0   memory length: 332317   epsilon: 0.5400103600099859    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n",
      "episode: 1633   score: 11.0   memory length: 332832   epsilon: 0.5389906600100081    steps: 515    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1634   score: 8.0   memory length: 333290   epsilon: 0.5380838200100277    steps: 458    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1635   score: 3.0   memory length: 333518   epsilon: 0.5376323800100375    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1636   score: 5.0   memory length: 333845   epsilon: 0.5369849200100516    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1637   score: 5.0   memory length: 334186   epsilon: 0.5363097400100663    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1638   score: 3.0   memory length: 334399   epsilon: 0.5358880000100754    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1639   score: 4.0   memory length: 334682   epsilon: 0.5353276600100876    steps: 283    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1640   score: 4.0   memory length: 334982   epsilon: 0.5347336600101005    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1641   score: 7.0   memory length: 335341   epsilon: 0.5340228400101159    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1642   score: 6.0   memory length: 335697   epsilon: 0.5333179600101312    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1643   score: 1.0   memory length: 335847   epsilon: 0.5330209600101377    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1644   score: 7.0   memory length: 336235   epsilon: 0.5322527200101543    steps: 388    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1645   score: 3.0   memory length: 336463   epsilon: 0.5318012800101641    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1646   score: 6.0   memory length: 336819   epsilon: 0.5310964000101794    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1647   score: 5.0   memory length: 337133   epsilon: 0.5304746800101929    steps: 314    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1648   score: 4.0   memory length: 337374   epsilon: 0.5299975000102033    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1649   score: 6.0   memory length: 337744   epsilon: 0.5292649000102192    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1650   score: 4.0   memory length: 338006   epsilon: 0.5287461400102305    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1651   score: 4.0   memory length: 338250   epsilon: 0.528263020010241    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1652   score: 6.0   memory length: 338616   epsilon: 0.5275383400102567    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1653   score: 4.0   memory length: 338896   epsilon: 0.5269839400102687    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1654   score: 8.0   memory length: 339332   epsilon: 0.5261206600102875    steps: 436    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1655   score: 9.0   memory length: 339776   epsilon: 0.5252415400103065    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1656   score: 6.0   memory length: 340135   epsilon: 0.524530720010322    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1657   score: 3.0   memory length: 340348   epsilon: 0.5241089800103311    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1658   score: 5.0   memory length: 340678   epsilon: 0.5234555800103453    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1659   score: 7.0   memory length: 341077   epsilon: 0.5226655600103625    steps: 399    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1660   score: 1.0   memory length: 341228   epsilon: 0.522366580010369    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1661   score: 5.0   memory length: 341541   epsilon: 0.5217468400103824    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1662   score: 8.0   memory length: 341975   epsilon: 0.5208875200104011    steps: 434    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1663   score: 1.0   memory length: 342125   epsilon: 0.5205905200104075    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1664   score: 8.0   memory length: 342438   epsilon: 0.519970780010421    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 4.4\n",
      "episode: 1665   score: 10.0   memory length: 342928   epsilon: 0.519000580010442    steps: 490    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1666   score: 5.0   memory length: 343255   epsilon: 0.5183531200104561    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1667   score: 9.0   memory length: 343696   epsilon: 0.517479940010475    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 4.46\n",
      "episode: 1668   score: 1.0   memory length: 343847   epsilon: 0.5171809600104815    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1669   score: 4.0   memory length: 344124   epsilon: 0.5166325000104934    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1670   score: 3.0   memory length: 344337   epsilon: 0.5162107600105026    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1671   score: 5.0   memory length: 344626   epsilon: 0.515638540010515    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n",
      "episode: 1672   score: 5.0   memory length: 344935   epsilon: 0.5150267200105283    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1673   score: 3.0   memory length: 345165   epsilon: 0.5145713200105382    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1674   score: 2.0   memory length: 345345   epsilon: 0.5142149200105459    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1675   score: 1.0   memory length: 345496   epsilon: 0.5139159400105524    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n",
      "episode: 1676   score: 3.0   memory length: 345708   epsilon: 0.5134961800105615    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1677   score: 6.0   memory length: 346028   epsilon: 0.5128625800105753    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1678   score: 7.0   memory length: 346398   epsilon: 0.5121299800105912    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1679   score: 6.0   memory length: 346753   epsilon: 0.5114270800106064    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1680   score: 4.0   memory length: 346997   epsilon: 0.5109439600106169    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1681   score: 2.0   memory length: 347195   epsilon: 0.5105519200106254    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1682   score: 5.0   memory length: 347519   epsilon: 0.5099104000106394    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1683   score: 5.0   memory length: 347825   epsilon: 0.5093045200106525    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.4\n",
      "episode: 1684   score: 8.0   memory length: 348135   epsilon: 0.5086907200106658    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1685   score: 5.0   memory length: 348423   epsilon: 0.5081204800106782    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.46\n",
      "episode: 1686   score: 2.0   memory length: 348642   epsilon: 0.5076868600106876    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1687   score: 7.0   memory length: 349083   epsilon: 0.5068136800107066    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1688   score: 3.0   memory length: 349294   epsilon: 0.5063959000107157    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1689   score: 3.0   memory length: 349507   epsilon: 0.5059741600107248    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.46\n",
      "episode: 1690   score: 2.0   memory length: 349707   epsilon: 0.5055781600107334    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1691   score: 5.0   memory length: 349998   epsilon: 0.5050019800107459    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1692   score: 3.0   memory length: 350225   epsilon: 0.5045525200107557    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1693   score: 3.0   memory length: 350453   epsilon: 0.5041010800107655    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1694   score: 5.0   memory length: 350801   epsilon: 0.5034120400107804    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1695   score: 6.0   memory length: 351171   epsilon: 0.5026794400107963    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1696   score: 4.0   memory length: 351413   epsilon: 0.5022002800108067    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1697   score: 5.0   memory length: 351757   epsilon: 0.5015191600108215    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1698   score: 5.0   memory length: 352066   epsilon: 0.5009073400108348    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1699   score: 4.0   memory length: 352344   epsilon: 0.5003569000108468    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1700   score: 7.0   memory length: 352732   epsilon: 0.4995886600108519    steps: 388    lr: 1.6000000000000003e-05     evaluation reward: 4.49\n",
      "episode: 1701   score: 5.0   memory length: 353038   epsilon: 0.49898278001084806    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.54\n",
      "episode: 1702   score: 7.0   memory length: 353442   epsilon: 0.498182860010843    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 4.59\n",
      "episode: 1703   score: 9.0   memory length: 353808   epsilon: 0.4974581800108384    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 4.62\n",
      "episode: 1704   score: 6.0   memory length: 354143   epsilon: 0.4967948800108342    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 4.63\n",
      "episode: 1705   score: 6.0   memory length: 354481   epsilon: 0.49612564001083    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.66\n",
      "episode: 1706   score: 5.0   memory length: 354787   epsilon: 0.49551976001082615    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n",
      "episode: 1707   score: 6.0   memory length: 355165   epsilon: 0.4947713200108214    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 4.7\n",
      "episode: 1708   score: 9.0   memory length: 355550   epsilon: 0.4940090200108166    steps: 385    lr: 1.6000000000000003e-05     evaluation reward: 4.76\n",
      "episode: 1709   score: 4.0   memory length: 355847   epsilon: 0.49342096001081287    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.79\n",
      "episode: 1710   score: 7.0   memory length: 356217   epsilon: 0.49268836001080824    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n",
      "episode: 1711   score: 5.0   memory length: 356512   epsilon: 0.49210426001080454    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.8\n",
      "episode: 1712   score: 4.0   memory length: 356771   epsilon: 0.4915914400108013    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n",
      "episode: 1713   score: 6.0   memory length: 357089   epsilon: 0.4909618000107973    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n",
      "episode: 1714   score: 1.0   memory length: 357240   epsilon: 0.4906628200107954    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n",
      "episode: 1715   score: 4.0   memory length: 357481   epsilon: 0.4901856400107924    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n",
      "episode: 1716   score: 4.0   memory length: 357735   epsilon: 0.4896827200107892    steps: 254    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n",
      "episode: 1717   score: 5.0   memory length: 358078   epsilon: 0.4890035800107849    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n",
      "episode: 1718   score: 7.0   memory length: 358471   epsilon: 0.48822544001078    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 4.91\n",
      "episode: 1719   score: 7.0   memory length: 358860   epsilon: 0.4874552200107751    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 4.94\n",
      "episode: 1720   score: 3.0   memory length: 359089   epsilon: 0.48700180001077226    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n",
      "episode: 1721   score: 6.0   memory length: 359460   epsilon: 0.4862672200107676    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 4.94\n",
      "episode: 1722   score: 4.0   memory length: 359719   epsilon: 0.48575440001076436    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n",
      "episode: 1723   score: 3.0   memory length: 359947   epsilon: 0.4853029600107615    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n",
      "episode: 1724   score: 6.0   memory length: 360341   epsilon: 0.4845228400107566    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.94\n",
      "episode: 1725   score: 9.0   memory length: 360813   epsilon: 0.48358828001075066    steps: 472    lr: 1.6000000000000003e-05     evaluation reward: 4.97\n",
      "episode: 1726   score: 6.0   memory length: 361169   epsilon: 0.4828834000107462    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n",
      "episode: 1727   score: 4.0   memory length: 361448   epsilon: 0.4823309800107427    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n",
      "episode: 1728   score: 4.0   memory length: 361744   epsilon: 0.481744900010739    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n",
      "episode: 1729   score: 10.0   memory length: 362137   epsilon: 0.4809667600107341    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n",
      "episode: 1730   score: 3.0   memory length: 362348   epsilon: 0.48054898001073143    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n",
      "episode: 1731   score: 7.0   memory length: 362774   epsilon: 0.4797055000107261    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n",
      "episode: 1732   score: 11.0   memory length: 363282   epsilon: 0.47869966001071973    steps: 508    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n",
      "episode: 1733   score: 7.0   memory length: 363690   epsilon: 0.4778918200107146    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n",
      "episode: 1734   score: 6.0   memory length: 364087   epsilon: 0.47710576001070965    steps: 397    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n",
      "episode: 1735   score: 5.0   memory length: 364394   epsilon: 0.4764979000107058    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n",
      "episode: 1736   score: 3.0   memory length: 364642   epsilon: 0.4760068600107027    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n",
      "episode: 1737   score: 6.0   memory length: 364999   epsilon: 0.4753000000106982    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 5.08\n",
      "episode: 1738   score: 4.0   memory length: 365281   epsilon: 0.4747416400106947    steps: 282    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n",
      "episode: 1739   score: 1.0   memory length: 365432   epsilon: 0.4744426600106928    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 5.06\n",
      "episode: 1740   score: 3.0   memory length: 365658   epsilon: 0.47399518001068996    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n",
      "episode: 1741   score: 4.0   memory length: 365917   epsilon: 0.4734823600106867    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n",
      "episode: 1742   score: 4.0   memory length: 366157   epsilon: 0.4730071600106837    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n",
      "episode: 1743   score: 6.0   memory length: 366512   epsilon: 0.47230426001067927    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n",
      "episode: 1744   score: 1.0   memory length: 366663   epsilon: 0.4720052800106774    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.99\n",
      "episode: 1745   score: 2.0   memory length: 366843   epsilon: 0.4716488800106751    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.98\n",
      "episode: 1746   score: 3.0   memory length: 367054   epsilon: 0.4712311000106725    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.95\n",
      "episode: 1747   score: 3.0   memory length: 367301   epsilon: 0.4707420400106694    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n",
      "episode: 1748   score: 5.0   memory length: 367649   epsilon: 0.470053000010665    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 4.94\n",
      "episode: 1749   score: 3.0   memory length: 367875   epsilon: 0.4696055200106622    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.91\n",
      "episode: 1750   score: 3.0   memory length: 368127   epsilon: 0.46910656001065903    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n",
      "episode: 1751   score: 4.0   memory length: 368391   epsilon: 0.46858384001065573    steps: 264    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n",
      "episode: 1752   score: 4.0   memory length: 368665   epsilon: 0.4680413200106523    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.88\n",
      "episode: 1753   score: 8.0   memory length: 369088   epsilon: 0.467203780010647    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n",
      "episode: 1754   score: 6.0   memory length: 369447   epsilon: 0.4664929600106425    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n",
      "episode: 1755   score: 6.0   memory length: 369821   epsilon: 0.4657524400106378    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.87\n",
      "episode: 1756   score: 4.0   memory length: 370118   epsilon: 0.4651643800106341    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n",
      "episode: 1757   score: 3.0   memory length: 370330   epsilon: 0.46474462001063144    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n",
      "episode: 1758   score: 5.0   memory length: 370618   epsilon: 0.46417438001062783    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n",
      "episode: 1759   score: 10.0   memory length: 371067   epsilon: 0.4632853600106222    steps: 449    lr: 1.6000000000000003e-05     evaluation reward: 4.88\n",
      "episode: 1760   score: 8.0   memory length: 371511   epsilon: 0.46240624001061664    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 4.95\n",
      "episode: 1761   score: 6.0   memory length: 371847   epsilon: 0.46174096001061243    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 4.96\n",
      "episode: 1762   score: 6.0   memory length: 372191   epsilon: 0.4610598400106081    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.94\n",
      "episode: 1763   score: 4.0   memory length: 372432   epsilon: 0.4605826600106051    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 4.97\n",
      "episode: 1764   score: 4.0   memory length: 372710   epsilon: 0.4600322200106016    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n",
      "episode: 1765   score: 8.0   memory length: 373147   epsilon: 0.45916696001059615    steps: 437    lr: 1.6000000000000003e-05     evaluation reward: 4.91\n",
      "episode: 1766   score: 4.0   memory length: 373462   epsilon: 0.4585432600105922    steps: 315    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n",
      "episode: 1767   score: 5.0   memory length: 373790   epsilon: 0.4578938200105881    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n",
      "episode: 1768   score: 9.0   memory length: 374225   epsilon: 0.45703252001058264    steps: 435    lr: 1.6000000000000003e-05     evaluation reward: 4.94\n",
      "episode: 1769   score: 7.0   memory length: 374618   epsilon: 0.4562543800105777    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 4.97\n",
      "episode: 1770   score: 9.0   memory length: 375040   epsilon: 0.45541882001057243    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 5.03\n",
      "episode: 1771   score: 7.0   memory length: 375429   epsilon: 0.45464860001056756    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n",
      "episode: 1772   score: 7.0   memory length: 375833   epsilon: 0.4538486800105625    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n",
      "episode: 1773   score: 6.0   memory length: 376174   epsilon: 0.45317350001055823    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n",
      "episode: 1774   score: 3.0   memory length: 376400   epsilon: 0.4527260200105554    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 5.11\n",
      "episode: 1775   score: 8.0   memory length: 376827   epsilon: 0.45188056001055005    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n",
      "episode: 1776   score: 6.0   memory length: 377177   epsilon: 0.45118756001054566    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 5.21\n",
      "episode: 1777   score: 7.0   memory length: 377554   epsilon: 0.45044110001054094    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 5.22\n",
      "episode: 1778   score: 5.0   memory length: 377881   epsilon: 0.44979364001053684    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 5.2\n",
      "episode: 1779   score: 4.0   memory length: 378160   epsilon: 0.44924122001053335    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n",
      "episode: 1780   score: 4.0   memory length: 378402   epsilon: 0.4487620600105303    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n",
      "episode: 1781   score: 7.0   memory length: 378798   epsilon: 0.44797798001052536    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 5.23\n",
      "episode: 1782   score: 6.0   memory length: 379152   epsilon: 0.4472770600105209    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n",
      "episode: 1783   score: 5.0   memory length: 379480   epsilon: 0.4466276200105168    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n",
      "episode: 1784   score: 11.0   memory length: 379901   epsilon: 0.44579404001051154    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n",
      "episode: 1785   score: 2.0   memory length: 380099   epsilon: 0.44540200001050906    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n",
      "episode: 1786   score: 5.0   memory length: 380422   epsilon: 0.444762460010505    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n",
      "episode: 1787   score: 5.0   memory length: 380767   epsilon: 0.4440793600105007    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 5.25\n",
      "episode: 1788   score: 6.0   memory length: 381121   epsilon: 0.44337844001049626    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 5.28\n",
      "episode: 1789   score: 8.0   memory length: 381575   epsilon: 0.44247952001049057    steps: 454    lr: 1.6000000000000003e-05     evaluation reward: 5.33\n",
      "episode: 1790   score: 7.0   memory length: 381988   epsilon: 0.4416617800104854    steps: 413    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n",
      "episode: 1791   score: 5.0   memory length: 382276   epsilon: 0.4410915400104818    steps: 288    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n",
      "episode: 1792   score: 7.0   memory length: 382671   epsilon: 0.44030944001047684    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1793   score: 3.0   memory length: 382896   epsilon: 0.439863940010474    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1794   score: 5.0   memory length: 383204   epsilon: 0.43925410001047016    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1795   score: 5.0   memory length: 383531   epsilon: 0.43860664001046606    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n",
      "episode: 1796   score: 5.0   memory length: 383858   epsilon: 0.43795918001046197    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1797   score: 6.0   memory length: 384174   epsilon: 0.437333500010458    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1798   score: 5.0   memory length: 384502   epsilon: 0.4366840600104539    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1799   score: 5.0   memory length: 384828   epsilon: 0.4360385800104498    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.44\n",
      "episode: 1800   score: 13.0   memory length: 385339   epsilon: 0.4350268000104434    steps: 511    lr: 1.6000000000000003e-05     evaluation reward: 5.5\n",
      "episode: 1801   score: 1.0   memory length: 385489   epsilon: 0.43472980001044154    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 5.46\n",
      "episode: 1802   score: 6.0   memory length: 385864   epsilon: 0.43398730001043684    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.45\n",
      "episode: 1803   score: 6.0   memory length: 386209   epsilon: 0.4333042000104325    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1804   score: 7.0   memory length: 386633   epsilon: 0.4324646800104272    steps: 424    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1805   score: 5.0   memory length: 386957   epsilon: 0.43182316001042315    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 5.42\n",
      "episode: 1806   score: 6.0   memory length: 387279   epsilon: 0.4311856000104191    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 5.43\n",
      "episode: 1807   score: 12.0   memory length: 387763   epsilon: 0.43022728001041305    steps: 484    lr: 1.6000000000000003e-05     evaluation reward: 5.49\n",
      "episode: 1808   score: 7.0   memory length: 388138   epsilon: 0.42948478001040835    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.47\n",
      "episode: 1809   score: 7.0   memory length: 388530   epsilon: 0.42870862001040344    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 5.5\n",
      "episode: 1810   score: 6.0   memory length: 388880   epsilon: 0.42801562001039906    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 5.49\n",
      "episode: 1811   score: 7.0   memory length: 389287   epsilon: 0.42720976001039396    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 5.51\n",
      "episode: 1812   score: 9.0   memory length: 389765   epsilon: 0.42626332001038797    steps: 478    lr: 1.6000000000000003e-05     evaluation reward: 5.56\n",
      "episode: 1813   score: 3.0   memory length: 390011   epsilon: 0.4257762400103849    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 5.53\n",
      "episode: 1814   score: 4.0   memory length: 390305   epsilon: 0.4251941200103812    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 5.56\n",
      "episode: 1815   score: 5.0   memory length: 390648   epsilon: 0.4245149800103769    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 5.57\n",
      "episode: 1816   score: 8.0   memory length: 391065   epsilon: 0.4236893200103717    steps: 417    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n",
      "episode: 1817   score: 5.0   memory length: 391390   epsilon: 0.4230458200103676    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n",
      "episode: 1818   score: 5.0   memory length: 391735   epsilon: 0.4223627200103633    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 5.59\n",
      "episode: 1819   score: 2.0   memory length: 391915   epsilon: 0.42200632001036104    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 5.54\n",
      "episode: 1820   score: 2.0   memory length: 392097   epsilon: 0.42164596001035876    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 5.53\n",
      "episode: 1821   score: 6.0   memory length: 392452   epsilon: 0.4209430600103543    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.53\n",
      "episode: 1822   score: 7.0   memory length: 392858   epsilon: 0.4201391800103492    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 5.56\n",
      "episode: 1823   score: 11.0   memory length: 393397   epsilon: 0.41907196001034247    steps: 539    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n",
      "episode: 1824   score: 6.0   memory length: 393742   epsilon: 0.41838886001033815    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n",
      "episode: 1825   score: 6.0   memory length: 394061   epsilon: 0.41775724001033415    steps: 319    lr: 1.6000000000000003e-05     evaluation reward: 5.61\n",
      "episode: 1826   score: 5.0   memory length: 394344   epsilon: 0.4171969000103306    steps: 283    lr: 1.6000000000000003e-05     evaluation reward: 5.6\n",
      "episode: 1827   score: 7.0   memory length: 394734   epsilon: 0.4164247000103257    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 5.63\n",
      "episode: 1828   score: 6.0   memory length: 395075   epsilon: 0.41574952001032145    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n",
      "episode: 1829   score: 7.0   memory length: 395498   epsilon: 0.41491198001031615    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 5.62\n",
      "episode: 1830   score: 4.0   memory length: 395777   epsilon: 0.41435956001031266    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.63\n",
      "episode: 1831   score: 8.0   memory length: 396249   epsilon: 0.41342500001030674    steps: 472    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n",
      "episode: 1832   score: 1.0   memory length: 396402   epsilon: 0.4131220600103048    steps: 153    lr: 1.6000000000000003e-05     evaluation reward: 5.54\n",
      "episode: 1833   score: 5.0   memory length: 396693   epsilon: 0.4125458800103012    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 5.52\n",
      "episode: 1834   score: 10.0   memory length: 397209   epsilon: 0.4115242000102947    steps: 516    lr: 1.6000000000000003e-05     evaluation reward: 5.56\n",
      "episode: 1835   score: 9.0   memory length: 397713   epsilon: 0.4105262800102884    steps: 504    lr: 1.6000000000000003e-05     evaluation reward: 5.6\n",
      "episode: 1836   score: 7.0   memory length: 398119   epsilon: 0.4097224000102833    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 5.64\n",
      "episode: 1837   score: 10.0   memory length: 398541   epsilon: 0.40888684001027803    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 5.68\n",
      "episode: 1838   score: 4.0   memory length: 398796   epsilon: 0.40838194001027484    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 5.68\n",
      "episode: 1839   score: 6.0   memory length: 399151   epsilon: 0.4076790400102704    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.73\n",
      "episode: 1840   score: 3.0   memory length: 399414   epsilon: 0.4071583000102671    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 5.73\n",
      "episode: 1841   score: 6.0   memory length: 399775   epsilon: 0.40644352001026257    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n",
      "episode: 1842   score: 9.0   memory length: 400241   epsilon: 0.40552084001025673    steps: 466    lr: 6.400000000000001e-06     evaluation reward: 5.8\n",
      "episode: 1843   score: 6.0   memory length: 400616   epsilon: 0.40477834001025204    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.8\n",
      "episode: 1844   score: 5.0   memory length: 400905   epsilon: 0.4042061200102484    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 5.84\n",
      "episode: 1845   score: 7.0   memory length: 401276   epsilon: 0.40347154001024377    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 5.89\n",
      "episode: 1846   score: 5.0   memory length: 401621   epsilon: 0.40278844001023945    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 5.91\n",
      "episode: 1847   score: 4.0   memory length: 401863   epsilon: 0.4023092800102364    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.92\n",
      "episode: 1848   score: 7.0   memory length: 402211   epsilon: 0.40162024001023205    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 5.94\n",
      "episode: 1849   score: 3.0   memory length: 402424   epsilon: 0.4011985000102294    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 5.94\n",
      "episode: 1850   score: 11.0   memory length: 403009   epsilon: 0.40004020001022206    steps: 585    lr: 6.400000000000001e-06     evaluation reward: 6.02\n",
      "episode: 1851   score: 11.0   memory length: 403466   epsilon: 0.39913534001021633    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 6.09\n",
      "episode: 1852   score: 9.0   memory length: 403977   epsilon: 0.39812356001020993    steps: 511    lr: 6.400000000000001e-06     evaluation reward: 6.14\n",
      "episode: 1853   score: 5.0   memory length: 404302   epsilon: 0.39748006001020586    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 6.11\n",
      "episode: 1854   score: 2.0   memory length: 404501   epsilon: 0.39708604001020337    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 6.07\n",
      "episode: 1855   score: 3.0   memory length: 404714   epsilon: 0.3966643000102007    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 6.04\n",
      "episode: 1856   score: 5.0   memory length: 405024   epsilon: 0.3960505000101968    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 6.05\n",
      "episode: 1857   score: 6.0   memory length: 405369   epsilon: 0.3953674000101925    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 6.08\n",
      "episode: 1858   score: 6.0   memory length: 405738   epsilon: 0.39463678001018787    steps: 369    lr: 6.400000000000001e-06     evaluation reward: 6.09\n",
      "episode: 1859   score: 12.0   memory length: 406223   epsilon: 0.3936764800101818    steps: 485    lr: 6.400000000000001e-06     evaluation reward: 6.11\n",
      "episode: 1860   score: 4.0   memory length: 406517   epsilon: 0.3930943600101781    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 6.07\n",
      "episode: 1861   score: 12.0   memory length: 407002   epsilon: 0.39213406001017204    steps: 485    lr: 6.400000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1862   score: 5.0   memory length: 407287   epsilon: 0.39156976001016847    steps: 285    lr: 6.400000000000001e-06     evaluation reward: 6.12\n",
      "episode: 1863   score: 5.0   memory length: 407593   epsilon: 0.39096388001016463    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1864   score: 6.0   memory length: 407940   epsilon: 0.3902768200101603    steps: 347    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1865   score: 12.0   memory length: 408480   epsilon: 0.3892076200101535    steps: 540    lr: 6.400000000000001e-06     evaluation reward: 6.19\n",
      "episode: 1866   score: 11.0   memory length: 409043   epsilon: 0.38809288001014647    steps: 563    lr: 6.400000000000001e-06     evaluation reward: 6.26\n",
      "episode: 1867   score: 5.0   memory length: 409352   epsilon: 0.3874810600101426    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 6.26\n",
      "episode: 1868   score: 6.0   memory length: 409724   epsilon: 0.38674450001013794    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 6.23\n",
      "episode: 1869   score: 4.0   memory length: 409985   epsilon: 0.38622772001013467    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 6.2\n",
      "episode: 1870   score: 6.0   memory length: 410288   epsilon: 0.38562778001013087    steps: 303    lr: 6.400000000000001e-06     evaluation reward: 6.17\n",
      "episode: 1871   score: 4.0   memory length: 410565   epsilon: 0.3850793200101274    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 6.14\n",
      "episode: 1872   score: 4.0   memory length: 410841   epsilon: 0.38453284001012394    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 6.11\n",
      "episode: 1873   score: 8.0   memory length: 411288   epsilon: 0.38364778001011834    steps: 447    lr: 6.400000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1874   score: 3.0   memory length: 411498   epsilon: 0.3832319800101157    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 6.13\n",
      "episode: 1875   score: 6.0   memory length: 411855   epsilon: 0.38252512001011124    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 6.11\n",
      "episode: 1876   score: 5.0   memory length: 412166   epsilon: 0.38190934001010735    steps: 311    lr: 6.400000000000001e-06     evaluation reward: 6.1\n",
      "episode: 1877   score: 6.0   memory length: 412519   epsilon: 0.3812104000101029    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 6.09\n",
      "episode: 1878   score: 4.0   memory length: 412817   epsilon: 0.3806203600100992    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 6.08\n",
      "episode: 1879   score: 11.0   memory length: 413354   epsilon: 0.37955710001009246    steps: 537    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1880   score: 14.0   memory length: 414010   epsilon: 0.37825822001008425    steps: 656    lr: 6.400000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1881   score: 7.0   memory length: 414417   epsilon: 0.37745236001007915    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 6.25\n",
      "episode: 1882   score: 5.0   memory length: 414762   epsilon: 0.3767692600100748    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 6.24\n",
      "episode: 1883   score: 11.0   memory length: 415175   epsilon: 0.37595152001006965    steps: 413    lr: 6.400000000000001e-06     evaluation reward: 6.3\n",
      "episode: 1884   score: 10.0   memory length: 415719   epsilon: 0.37487440001006284    steps: 544    lr: 6.400000000000001e-06     evaluation reward: 6.29\n",
      "episode: 1885   score: 6.0   memory length: 416110   epsilon: 0.37410022001005794    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 6.33\n",
      "episode: 1886   score: 5.0   memory length: 416403   epsilon: 0.37352008001005427    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 6.33\n",
      "episode: 1887   score: 5.0   memory length: 416726   epsilon: 0.3728805400100502    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 6.33\n",
      "episode: 1888   score: 4.0   memory length: 417004   epsilon: 0.37233010001004674    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.31\n",
      "episode: 1889   score: 14.0   memory length: 417543   epsilon: 0.37126288001004    steps: 539    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 1890   score: 6.0   memory length: 417856   epsilon: 0.37064314001003607    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 6.36\n",
      "episode: 1891   score: 7.0   memory length: 418236   epsilon: 0.3698907400100313    steps: 380    lr: 6.400000000000001e-06     evaluation reward: 6.38\n",
      "episode: 1892   score: 4.0   memory length: 418514   epsilon: 0.3693403000100278    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1893   score: 8.0   memory length: 418965   epsilon: 0.3684473200100222    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 6.4\n",
      "episode: 1894   score: 8.0   memory length: 419395   epsilon: 0.3675959200100168    steps: 430    lr: 6.400000000000001e-06     evaluation reward: 6.43\n",
      "episode: 1895   score: 7.0   memory length: 419796   epsilon: 0.36680194001001176    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 6.45\n",
      "episode: 1896   score: 6.0   memory length: 420168   epsilon: 0.3660653800100071    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 1897   score: 4.0   memory length: 420410   epsilon: 0.36558622001000407    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 6.44\n",
      "episode: 1898   score: 9.0   memory length: 420900   epsilon: 0.36461602000999793    steps: 490    lr: 6.400000000000001e-06     evaluation reward: 6.48\n",
      "episode: 1899   score: 8.0   memory length: 421307   epsilon: 0.36381016000999283    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 6.51\n",
      "episode: 1900   score: 13.0   memory length: 421948   epsilon: 0.3625409800099848    steps: 641    lr: 6.400000000000001e-06     evaluation reward: 6.51\n",
      "episode: 1901   score: 6.0   memory length: 422310   epsilon: 0.36182422000998027    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 1902   score: 16.0   memory length: 422837   epsilon: 0.36078076000997367    steps: 527    lr: 6.400000000000001e-06     evaluation reward: 6.66\n",
      "episode: 1903   score: 6.0   memory length: 423177   epsilon: 0.3601075600099694    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 6.66\n",
      "episode: 1904   score: 3.0   memory length: 423390   epsilon: 0.35968582000996674    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 6.62\n",
      "episode: 1905   score: 4.0   memory length: 423650   epsilon: 0.3591710200099635    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 6.61\n",
      "episode: 1906   score: 7.0   memory length: 424053   epsilon: 0.35837308000995843    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 6.62\n",
      "episode: 1907   score: 6.0   memory length: 424449   epsilon: 0.3575890000099535    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 1908   score: 7.0   memory length: 424876   epsilon: 0.3567435400099481    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 1909   score: 6.0   memory length: 425253   epsilon: 0.3559970800099434    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 6.55\n",
      "episode: 1910   score: 5.0   memory length: 425604   epsilon: 0.355302100009939    steps: 351    lr: 6.400000000000001e-06     evaluation reward: 6.54\n",
      "episode: 1911   score: 6.0   memory length: 425930   epsilon: 0.3546566200099349    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 6.53\n",
      "episode: 1912   score: 7.0   memory length: 426320   epsilon: 0.35388442000993003    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 6.51\n",
      "episode: 1913   score: 6.0   memory length: 426640   epsilon: 0.353250820009926    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 6.54\n",
      "episode: 1914   score: 6.0   memory length: 426979   epsilon: 0.3525796000099218    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 1915   score: 6.0   memory length: 427343   epsilon: 0.3518588800099172    steps: 364    lr: 6.400000000000001e-06     evaluation reward: 6.57\n",
      "episode: 1916   score: 7.0   memory length: 427728   epsilon: 0.3510965800099124    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 1917   score: 6.0   memory length: 428102   epsilon: 0.3503560600099077    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 6.57\n",
      "episode: 1918   score: 4.0   memory length: 428379   epsilon: 0.34980760000990424    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 1919   score: 6.0   memory length: 428710   epsilon: 0.3491522200099001    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 6.6\n",
      "episode: 1920   score: 8.0   memory length: 429125   epsilon: 0.3483305200098949    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 6.66\n",
      "episode: 1921   score: 6.0   memory length: 429501   epsilon: 0.3475860400098902    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 6.66\n",
      "episode: 1922   score: 8.0   memory length: 429917   epsilon: 0.346762360009885    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 6.67\n",
      "episode: 1923   score: 9.0   memory length: 430335   epsilon: 0.34593472000987974    steps: 418    lr: 6.400000000000001e-06     evaluation reward: 6.65\n",
      "episode: 1924   score: 14.0   memory length: 430870   epsilon: 0.34487542000987303    steps: 535    lr: 6.400000000000001e-06     evaluation reward: 6.73\n",
      "episode: 1925   score: 7.0   memory length: 431240   epsilon: 0.3441428200098684    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 1926   score: 12.0   memory length: 431769   epsilon: 0.3430954000098618    steps: 529    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1927   score: 6.0   memory length: 432124   epsilon: 0.3423925000098573    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.8\n",
      "episode: 1928   score: 7.0   memory length: 432509   epsilon: 0.3416302000098525    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1929   score: 8.0   memory length: 432949   epsilon: 0.340759000009847    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 6.82\n",
      "episode: 1930   score: 7.0   memory length: 433337   epsilon: 0.33999076000984213    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 1931   score: 4.0   memory length: 433635   epsilon: 0.3394007200098384    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1932   score: 4.0   memory length: 433915   epsilon: 0.3388463200098349    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 6.84\n",
      "episode: 1933   score: 5.0   memory length: 434221   epsilon: 0.33824044000983106    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.84\n",
      "episode: 1934   score: 5.0   memory length: 434527   epsilon: 0.3376345600098272    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.79\n",
      "episode: 1935   score: 7.0   memory length: 434884   epsilon: 0.33692770000982275    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 6.77\n",
      "episode: 1936   score: 8.0   memory length: 435273   epsilon: 0.3361574800098179    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1937   score: 5.0   memory length: 435598   epsilon: 0.3355139800098138    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 6.73\n",
      "episode: 1938   score: 9.0   memory length: 435963   epsilon: 0.33479128000980923    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1939   score: 5.0   memory length: 436251   epsilon: 0.3342210400098056    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 6.77\n",
      "episode: 1940   score: 4.0   memory length: 436509   epsilon: 0.3337102000098024    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1941   score: 6.0   memory length: 436867   epsilon: 0.3330013600097979    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1942   score: 8.0   memory length: 437322   epsilon: 0.3321004600097922    steps: 455    lr: 6.400000000000001e-06     evaluation reward: 6.77\n",
      "episode: 1943   score: 8.0   memory length: 437727   epsilon: 0.33129856000978714    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 6.79\n",
      "episode: 1944   score: 7.0   memory length: 438124   epsilon: 0.33051250000978216    steps: 397    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1945   score: 7.0   memory length: 438492   epsilon: 0.32978386000977755    steps: 368    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1946   score: 9.0   memory length: 438939   epsilon: 0.32889880000977195    steps: 447    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 1947   score: 3.0   memory length: 439167   epsilon: 0.3284473600097691    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 6.84\n",
      "episode: 1948   score: 4.0   memory length: 439428   epsilon: 0.3279305800097658    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1949   score: 5.0   memory length: 439755   epsilon: 0.32728312000976173    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 6.83\n",
      "episode: 1950   score: 7.0   memory length: 440159   epsilon: 0.32648320000975667    steps: 404    lr: 6.400000000000001e-06     evaluation reward: 6.79\n",
      "episode: 1951   score: 5.0   memory length: 440450   epsilon: 0.325907020009753    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 6.73\n",
      "episode: 1952   score: 6.0   memory length: 440803   epsilon: 0.3252080800097486    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 6.7\n",
      "episode: 1953   score: 3.0   memory length: 441016   epsilon: 0.32478634000974593    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 6.68\n",
      "episode: 1954   score: 5.0   memory length: 441342   epsilon: 0.32414086000974185    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 6.71\n",
      "episode: 1955   score: 7.0   memory length: 441702   epsilon: 0.32342806000973734    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 1956   score: 6.0   memory length: 442051   epsilon: 0.32273704000973297    steps: 349    lr: 6.400000000000001e-06     evaluation reward: 6.76\n",
      "episode: 1957   score: 6.0   memory length: 442373   epsilon: 0.32209948000972893    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 6.76\n",
      "episode: 1958   score: 11.0   memory length: 442848   epsilon: 0.321158980009723    steps: 475    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1959   score: 9.0   memory length: 443312   epsilon: 0.32024026000971717    steps: 464    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1960   score: 4.0   memory length: 443569   epsilon: 0.31973140000971395    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1961   score: 5.0   memory length: 443912   epsilon: 0.31905226000970965    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 6.71\n",
      "episode: 1962   score: 5.0   memory length: 444203   epsilon: 0.318476080009706    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 6.71\n",
      "episode: 1963   score: 6.0   memory length: 444557   epsilon: 0.3177751600097016    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 6.72\n",
      "episode: 1964   score: 9.0   memory length: 445033   epsilon: 0.3168326800096956    steps: 476    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 1965   score: 6.0   memory length: 445371   epsilon: 0.3161634400096914    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 6.69\n",
      "episode: 1966   score: 9.0   memory length: 445854   epsilon: 0.3152071000096853    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 6.67\n",
      "episode: 1967   score: 4.0   memory length: 446131   epsilon: 0.31465864000968186    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 6.66\n",
      "episode: 1968   score: 8.0   memory length: 446513   epsilon: 0.31390228000967707    steps: 382    lr: 6.400000000000001e-06     evaluation reward: 6.68\n",
      "episode: 1969   score: 6.0   memory length: 446865   epsilon: 0.31320532000967266    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 6.7\n",
      "episode: 1970   score: 7.0   memory length: 447265   epsilon: 0.31241332000966765    steps: 400    lr: 6.400000000000001e-06     evaluation reward: 6.71\n",
      "episode: 1971   score: 8.0   memory length: 447727   epsilon: 0.31149856000966186    steps: 462    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 1972   score: 5.0   memory length: 448069   epsilon: 0.3108214000096576    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 6.76\n",
      "episode: 1973   score: 9.0   memory length: 448517   epsilon: 0.30993436000965197    steps: 448    lr: 6.400000000000001e-06     evaluation reward: 6.77\n",
      "episode: 1974   score: 7.0   memory length: 448908   epsilon: 0.30916018000964707    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1975   score: 8.0   memory length: 449321   epsilon: 0.3083424400096419    steps: 413    lr: 6.400000000000001e-06     evaluation reward: 6.83\n",
      "episode: 1976   score: 9.0   memory length: 449801   epsilon: 0.3073920400096359    steps: 480    lr: 6.400000000000001e-06     evaluation reward: 6.87\n",
      "episode: 1977   score: 4.0   memory length: 450061   epsilon: 0.3068772400096326    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 1978   score: 13.0   memory length: 450544   epsilon: 0.3059209000096266    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 6.94\n",
      "episode: 1979   score: 6.0   memory length: 450861   epsilon: 0.3052932400096226    steps: 317    lr: 6.400000000000001e-06     evaluation reward: 6.89\n",
      "episode: 1980   score: 11.0   memory length: 451414   epsilon: 0.3041983000096157    steps: 553    lr: 6.400000000000001e-06     evaluation reward: 6.86\n",
      "episode: 1981   score: 4.0   memory length: 451689   epsilon: 0.30365380000961223    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 6.83\n",
      "episode: 1982   score: 4.0   memory length: 451931   epsilon: 0.3031746400096092    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 6.82\n",
      "episode: 1983   score: 8.0   memory length: 452359   epsilon: 0.30232720000960384    steps: 428    lr: 6.400000000000001e-06     evaluation reward: 6.79\n",
      "episode: 1984   score: 6.0   memory length: 452736   epsilon: 0.3015807400095991    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 1985   score: 9.0   memory length: 453217   epsilon: 0.3006283600095931    steps: 481    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1986   score: 9.0   memory length: 453667   epsilon: 0.29973736000958745    steps: 450    lr: 6.400000000000001e-06     evaluation reward: 6.82\n",
      "episode: 1987   score: 4.0   memory length: 453909   epsilon: 0.2992582000095844    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 1988   score: 6.0   memory length: 454238   epsilon: 0.2986067800095803    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 6.83\n",
      "episode: 1989   score: 5.0   memory length: 454565   epsilon: 0.2979593200095762    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 1990   score: 6.0   memory length: 454921   epsilon: 0.29725444000957174    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 1991   score: 7.0   memory length: 455322   epsilon: 0.2964604600095667    steps: 401    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 1992   score: 4.0   memory length: 455617   epsilon: 0.295876360009563    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 1993   score: 7.0   memory length: 455991   epsilon: 0.29513584000955834    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 6.73\n",
      "episode: 1994   score: 6.0   memory length: 456368   epsilon: 0.2943893800095536    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 6.71\n",
      "episode: 1995   score: 11.0   memory length: 456919   epsilon: 0.2932984000095467    steps: 551    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 1996   score: 6.0   memory length: 457274   epsilon: 0.29259550000954226    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 1997   score: 7.0   memory length: 457677   epsilon: 0.2917975600095372    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 1998   score: 8.0   memory length: 458138   epsilon: 0.29088478000953144    steps: 461    lr: 6.400000000000001e-06     evaluation reward: 6.77\n",
      "episode: 1999   score: 9.0   memory length: 458547   epsilon: 0.2900749600095263    steps: 409    lr: 6.400000000000001e-06     evaluation reward: 6.78\n",
      "episode: 2000   score: 9.0   memory length: 458890   epsilon: 0.289395820009522    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 2001   score: 7.0   memory length: 459264   epsilon: 0.28865530000951733    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 2002   score: 10.0   memory length: 459759   epsilon: 0.28767520000951113    steps: 495    lr: 6.400000000000001e-06     evaluation reward: 6.69\n",
      "episode: 2003   score: 6.0   memory length: 460107   epsilon: 0.2869861600095068    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 6.69\n",
      "episode: 2004   score: 4.0   memory length: 460384   epsilon: 0.2864377000095033    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 6.7\n",
      "episode: 2005   score: 6.0   memory length: 460774   epsilon: 0.2856655000094984    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 6.72\n",
      "episode: 2006   score: 9.0   memory length: 461139   epsilon: 0.28494280000949385    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 6.74\n",
      "episode: 2007   score: 7.0   memory length: 461474   epsilon: 0.28427950000948965    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 2008   score: 13.0   memory length: 461993   epsilon: 0.28325188000948315    steps: 519    lr: 6.400000000000001e-06     evaluation reward: 6.81\n",
      "episode: 2009   score: 9.0   memory length: 462399   epsilon: 0.28244800000947806    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 6.84\n",
      "episode: 2010   score: 5.0   memory length: 462707   epsilon: 0.2818381600094742    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 6.84\n",
      "episode: 2011   score: 5.0   memory length: 462995   epsilon: 0.2812679200094706    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 6.83\n",
      "episode: 2012   score: 10.0   memory length: 463400   epsilon: 0.2804660200094655    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 6.86\n",
      "episode: 2013   score: 6.0   memory length: 463740   epsilon: 0.27979282000946126    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 6.86\n",
      "episode: 2014   score: 5.0   memory length: 464064   epsilon: 0.2791513000094572    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 2015   score: 9.0   memory length: 464553   epsilon: 0.2781830800094511    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 6.88\n",
      "episode: 2016   score: 6.0   memory length: 464923   epsilon: 0.27745048000944644    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 6.87\n",
      "episode: 2017   score: 10.0   memory length: 465453   epsilon: 0.2764010800094398    steps: 530    lr: 6.400000000000001e-06     evaluation reward: 6.91\n",
      "episode: 2018   score: 10.0   memory length: 465981   epsilon: 0.2753556400094332    steps: 528    lr: 6.400000000000001e-06     evaluation reward: 6.97\n",
      "episode: 2019   score: 9.0   memory length: 466444   epsilon: 0.2744389000094274    steps: 463    lr: 6.400000000000001e-06     evaluation reward: 7.0\n",
      "episode: 2020   score: 6.0   memory length: 466764   epsilon: 0.2738053000094234    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 6.98\n",
      "episode: 2021   score: 7.0   memory length: 467150   epsilon: 0.27304102000941854    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 6.99\n",
      "episode: 2022   score: 5.0   memory length: 467473   epsilon: 0.2724014800094145    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 6.96\n",
      "episode: 2023   score: 6.0   memory length: 467810   epsilon: 0.2717342200094103    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 6.93\n",
      "episode: 2024   score: 7.0   memory length: 468236   epsilon: 0.27089074000940494    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 6.86\n",
      "episode: 2025   score: 6.0   memory length: 468583   epsilon: 0.2702036800094006    steps: 347    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 2026   score: 7.0   memory length: 468975   epsilon: 0.2694275200093957    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 6.8\n",
      "episode: 2027   score: 8.0   memory length: 469412   epsilon: 0.2685622600093902    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 6.82\n",
      "episode: 2028   score: 4.0   memory length: 469690   epsilon: 0.2680118200093867    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.79\n",
      "episode: 2029   score: 5.0   memory length: 469980   epsilon: 0.2674376200093831    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 6.76\n",
      "episode: 2030   score: 10.0   memory length: 470484   epsilon: 0.2664397000093768    steps: 504    lr: 6.400000000000001e-06     evaluation reward: 6.79\n",
      "episode: 2031   score: 7.0   memory length: 470872   epsilon: 0.2656714600093719    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 6.82\n",
      "episode: 2032   score: 7.0   memory length: 471234   epsilon: 0.2649547000093674    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 2033   score: 4.0   memory length: 471476   epsilon: 0.26447554000936435    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 6.84\n",
      "episode: 2034   score: 4.0   memory length: 471751   epsilon: 0.2639310400093609    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 6.83\n",
      "episode: 2035   score: 14.0   memory length: 472296   epsilon: 0.2628519400093541    steps: 545    lr: 6.400000000000001e-06     evaluation reward: 6.9\n",
      "episode: 2036   score: 12.0   memory length: 472734   epsilon: 0.2619847000093486    steps: 438    lr: 6.400000000000001e-06     evaluation reward: 6.94\n",
      "episode: 2037   score: 12.0   memory length: 473242   epsilon: 0.26097886000934223    steps: 508    lr: 6.400000000000001e-06     evaluation reward: 7.01\n",
      "episode: 2038   score: 6.0   memory length: 473581   epsilon: 0.260307640009338    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 6.98\n",
      "episode: 2039   score: 10.0   memory length: 473938   epsilon: 0.2596007800093335    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 7.03\n",
      "episode: 2040   score: 5.0   memory length: 474225   epsilon: 0.2590325200093299    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 7.04\n",
      "episode: 2041   score: 6.0   memory length: 474581   epsilon: 0.25832764000932545    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 7.04\n",
      "episode: 2042   score: 8.0   memory length: 475049   epsilon: 0.2574010000093196    steps: 468    lr: 6.400000000000001e-06     evaluation reward: 7.04\n",
      "episode: 2043   score: 4.0   memory length: 475311   epsilon: 0.2568822400093163    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 7.0\n",
      "episode: 2044   score: 8.0   memory length: 475762   epsilon: 0.25598926000931066    steps: 451    lr: 6.400000000000001e-06     evaluation reward: 7.01\n",
      "episode: 2045   score: 11.0   memory length: 476156   epsilon: 0.2552091400093057    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 7.05\n",
      "episode: 2046   score: 7.0   memory length: 476514   epsilon: 0.25450030000930124    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 7.03\n",
      "episode: 2047   score: 9.0   memory length: 476922   epsilon: 0.25369246000929613    steps: 408    lr: 6.400000000000001e-06     evaluation reward: 7.09\n",
      "episode: 2048   score: 4.0   memory length: 477164   epsilon: 0.2532133000092931    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 7.09\n",
      "episode: 2049   score: 8.0   memory length: 477600   epsilon: 0.25235002000928763    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 7.12\n",
      "episode: 2050   score: 5.0   memory length: 477928   epsilon: 0.2517005800092835    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 7.1\n",
      "episode: 2051   score: 8.0   memory length: 478307   epsilon: 0.2509501600092788    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 7.13\n",
      "episode: 2052   score: 15.0   memory length: 478857   epsilon: 0.2498611600092719    steps: 550    lr: 6.400000000000001e-06     evaluation reward: 7.22\n",
      "episode: 2053   score: 6.0   memory length: 479176   epsilon: 0.2492295400092679    steps: 319    lr: 6.400000000000001e-06     evaluation reward: 7.25\n",
      "episode: 2054   score: 3.0   memory length: 479404   epsilon: 0.24877810000926504    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 7.23\n",
      "episode: 2055   score: 9.0   memory length: 479889   epsilon: 0.24781780000925896    steps: 485    lr: 6.400000000000001e-06     evaluation reward: 7.25\n",
      "episode: 2056   score: 7.0   memory length: 480281   epsilon: 0.24704164000925405    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2057   score: 6.0   memory length: 480605   epsilon: 0.24640012000925    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2058   score: 8.0   memory length: 481003   epsilon: 0.245612080009245    steps: 398    lr: 6.400000000000001e-06     evaluation reward: 7.23\n",
      "episode: 2059   score: 12.0   memory length: 481645   epsilon: 0.24434092000923696    steps: 642    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2060   score: 6.0   memory length: 481967   epsilon: 0.24370336000923293    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 7.28\n",
      "episode: 2061   score: 8.0   memory length: 482415   epsilon: 0.24281632000922732    steps: 448    lr: 6.400000000000001e-06     evaluation reward: 7.31\n",
      "episode: 2062   score: 6.0   memory length: 482790   epsilon: 0.24207382000922262    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2063   score: 5.0   memory length: 483117   epsilon: 0.24142636000921852    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 7.31\n",
      "episode: 2064   score: 11.0   memory length: 483574   epsilon: 0.2405215000092128    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2065   score: 7.0   memory length: 483994   epsilon: 0.23968990000920753    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2066   score: 5.0   memory length: 484265   epsilon: 0.23915332000920414    steps: 271    lr: 6.400000000000001e-06     evaluation reward: 7.3\n",
      "episode: 2067   score: 8.0   memory length: 484696   epsilon: 0.23829994000919874    steps: 431    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2068   score: 8.0   memory length: 485096   epsilon: 0.23750794000919373    steps: 400    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2069   score: 5.0   memory length: 485424   epsilon: 0.23685850000918962    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2070   score: 9.0   memory length: 485860   epsilon: 0.23599522000918416    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2071   score: 6.0   memory length: 486219   epsilon: 0.23528440000917966    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2072   score: 9.0   memory length: 486669   epsilon: 0.23439340000917402    steps: 450    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2073   score: 9.0   memory length: 487095   epsilon: 0.2335499200091687    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2074   score: 6.0   memory length: 487452   epsilon: 0.23284306000916422    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 7.36\n",
      "episode: 2075   score: 10.0   memory length: 487844   epsilon: 0.2320669000091593    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2076   score: 8.0   memory length: 488279   epsilon: 0.23120560000915386    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2077   score: 9.0   memory length: 488827   epsilon: 0.230120560009147    steps: 548    lr: 6.400000000000001e-06     evaluation reward: 7.42\n",
      "episode: 2078   score: 9.0   memory length: 489295   epsilon: 0.22919392000914113    steps: 468    lr: 6.400000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2079   score: 7.0   memory length: 489666   epsilon: 0.22845934000913648    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 7.39\n",
      "episode: 2080   score: 7.0   memory length: 490053   epsilon: 0.22769308000913163    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2081   score: 4.0   memory length: 490313   epsilon: 0.22717828000912837    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2082   score: 4.0   memory length: 490576   epsilon: 0.22665754000912508    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2083   score: 4.0   memory length: 490853   epsilon: 0.2261090800091216    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 7.31\n",
      "episode: 2084   score: 4.0   memory length: 491116   epsilon: 0.22558834000911832    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2085   score: 13.0   memory length: 491761   epsilon: 0.22431124000911024    steps: 645    lr: 6.400000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2086   score: 6.0   memory length: 492119   epsilon: 0.22360240000910575    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 7.3\n",
      "episode: 2087   score: 6.0   memory length: 492460   epsilon: 0.22292722000910148    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2088   score: 3.0   memory length: 492689   epsilon: 0.2224738000090986    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2089   score: 5.0   memory length: 493015   epsilon: 0.22182832000909453    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2090   score: 6.0   memory length: 493335   epsilon: 0.22119472000909052    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2091   score: 5.0   memory length: 493681   epsilon: 0.22050964000908618    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 7.27\n",
      "episode: 2092   score: 4.0   memory length: 493923   epsilon: 0.22003048000908315    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 7.27\n",
      "episode: 2093   score: 5.0   memory length: 494232   epsilon: 0.21941866000907928    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 7.25\n",
      "episode: 2094   score: 13.0   memory length: 494770   epsilon: 0.21835342000907254    steps: 538    lr: 6.400000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2095   score: 7.0   memory length: 495138   epsilon: 0.21762478000906793    steps: 368    lr: 6.400000000000001e-06     evaluation reward: 7.28\n",
      "episode: 2096   score: 15.0   memory length: 495700   epsilon: 0.2165120200090609    steps: 562    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2097   score: 9.0   memory length: 496154   epsilon: 0.2156131000090552    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 7.39\n",
      "episode: 2098   score: 6.0   memory length: 496509   epsilon: 0.21491020000905076    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2099   score: 9.0   memory length: 496973   epsilon: 0.21399148000904494    steps: 464    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2100   score: 7.0   memory length: 497365   epsilon: 0.21321532000904003    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2101   score: 7.0   memory length: 497758   epsilon: 0.2124371800090351    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2102   score: 7.0   memory length: 498155   epsilon: 0.21165112000903014    steps: 397    lr: 6.400000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2103   score: 9.0   memory length: 498604   epsilon: 0.2107621000090245    steps: 449    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2104   score: 7.0   memory length: 498994   epsilon: 0.20998990000901963    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2105   score: 8.0   memory length: 499487   epsilon: 0.20901376000901345    steps: 493    lr: 6.400000000000001e-06     evaluation reward: 7.4\n",
      "episode: 2106   score: 4.0   memory length: 499764   epsilon: 0.20846530000900998    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2107   score: 9.0   memory length: 500169   epsilon: 0.2076634000090049    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2108   score: 5.0   memory length: 500458   epsilon: 0.20709118000900129    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2109   score: 7.0   memory length: 500847   epsilon: 0.2063209600089964    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 7.27\n",
      "episode: 2110   score: 10.0   memory length: 501332   epsilon: 0.20536066000899034    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2111   score: 11.0   memory length: 501731   epsilon: 0.20457064000898534    steps: 399    lr: 2.560000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2112   score: 4.0   memory length: 502006   epsilon: 0.2040261400089819    steps: 275    lr: 2.560000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2113   score: 6.0   memory length: 502378   epsilon: 0.20328958000897723    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2114   score: 14.0   memory length: 502930   epsilon: 0.20219662000897032    steps: 552    lr: 2.560000000000001e-06     evaluation reward: 7.41\n",
      "episode: 2115   score: 6.0   memory length: 503249   epsilon: 0.20156500000896632    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2116   score: 6.0   memory length: 503570   epsilon: 0.2009294200089623    steps: 321    lr: 2.560000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2117   score: 9.0   memory length: 504049   epsilon: 0.1999810000089563    steps: 479    lr: 2.560000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2118   score: 7.0   memory length: 504417   epsilon: 0.1992523600089517    steps: 368    lr: 2.560000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2119   score: 9.0   memory length: 504906   epsilon: 0.19828414000894556    steps: 489    lr: 2.560000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2120   score: 13.0   memory length: 505376   epsilon: 0.19735354000893968    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 7.41\n",
      "episode: 2121   score: 8.0   memory length: 505794   epsilon: 0.19652590000893444    steps: 418    lr: 2.560000000000001e-06     evaluation reward: 7.42\n",
      "episode: 2122   score: 12.0   memory length: 506352   epsilon: 0.19542106000892745    steps: 558    lr: 2.560000000000001e-06     evaluation reward: 7.49\n",
      "episode: 2123   score: 7.0   memory length: 506718   epsilon: 0.19469638000892286    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 7.5\n",
      "episode: 2124   score: 9.0   memory length: 507215   epsilon: 0.19371232000891664    steps: 497    lr: 2.560000000000001e-06     evaluation reward: 7.52\n",
      "episode: 2125   score: 8.0   memory length: 507682   epsilon: 0.1927876600089108    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 7.54\n",
      "episode: 2126   score: 7.0   memory length: 508108   epsilon: 0.19194418000890545    steps: 426    lr: 2.560000000000001e-06     evaluation reward: 7.54\n",
      "episode: 2127   score: 6.0   memory length: 508501   epsilon: 0.19116604000890053    steps: 393    lr: 2.560000000000001e-06     evaluation reward: 7.52\n",
      "episode: 2128   score: 25.0   memory length: 509221   epsilon: 0.1897404400088915    steps: 720    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2129   score: 5.0   memory length: 509508   epsilon: 0.1891721800088879    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2130   score: 8.0   memory length: 509903   epsilon: 0.18839008000888297    steps: 395    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2131   score: 6.0   memory length: 510247   epsilon: 0.18770896000887866    steps: 344    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2132   score: 11.0   memory length: 510819   epsilon: 0.1865764000088715    steps: 572    lr: 2.560000000000001e-06     evaluation reward: 7.74\n",
      "episode: 2133   score: 7.0   memory length: 511211   epsilon: 0.18580024000886658    steps: 392    lr: 2.560000000000001e-06     evaluation reward: 7.77\n",
      "episode: 2134   score: 7.0   memory length: 511614   epsilon: 0.18500230000886153    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 7.8\n",
      "episode: 2135   score: 15.0   memory length: 512194   epsilon: 0.18385390000885427    steps: 580    lr: 2.560000000000001e-06     evaluation reward: 7.81\n",
      "episode: 2136   score: 10.0   memory length: 512660   epsilon: 0.18293122000884843    steps: 466    lr: 2.560000000000001e-06     evaluation reward: 7.79\n",
      "episode: 2137   score: 6.0   memory length: 512979   epsilon: 0.18229960000884443    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2138   score: 8.0   memory length: 513397   epsilon: 0.1814719600088392    steps: 418    lr: 2.560000000000001e-06     evaluation reward: 7.75\n",
      "episode: 2139   score: 7.0   memory length: 513765   epsilon: 0.18074332000883458    steps: 368    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2140   score: 5.0   memory length: 514076   epsilon: 0.1801275400088307    steps: 311    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2141   score: 9.0   memory length: 514557   epsilon: 0.17917516000882466    steps: 481    lr: 2.560000000000001e-06     evaluation reward: 7.75\n",
      "episode: 2142   score: 9.0   memory length: 515040   epsilon: 0.1782188200088186    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 7.76\n",
      "episode: 2143   score: 8.0   memory length: 515435   epsilon: 0.17743672000881366    steps: 395    lr: 2.560000000000001e-06     evaluation reward: 7.8\n",
      "episode: 2144   score: 6.0   memory length: 515789   epsilon: 0.17673580000880923    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 7.78\n",
      "episode: 2145   score: 10.0   memory length: 516275   epsilon: 0.17577352000880314    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 7.77\n",
      "episode: 2146   score: 6.0   memory length: 516629   epsilon: 0.1750726000087987    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 7.76\n",
      "episode: 2147   score: 8.0   memory length: 517000   epsilon: 0.17433802000879406    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 7.75\n",
      "episode: 2148   score: 9.0   memory length: 517458   epsilon: 0.17343118000878832    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 7.8\n",
      "episode: 2149   score: 13.0   memory length: 518092   epsilon: 0.17217586000878038    steps: 634    lr: 2.560000000000001e-06     evaluation reward: 7.85\n",
      "episode: 2150   score: 6.0   memory length: 518452   epsilon: 0.17146306000877587    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 7.86\n",
      "episode: 2151   score: 9.0   memory length: 518883   epsilon: 0.17060968000877047    steps: 431    lr: 2.560000000000001e-06     evaluation reward: 7.87\n",
      "episode: 2152   score: 7.0   memory length: 519270   epsilon: 0.16984342000876562    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 7.79\n",
      "episode: 2153   score: 9.0   memory length: 519724   epsilon: 0.16894450000875993    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 7.82\n",
      "episode: 2154   score: 8.0   memory length: 520178   epsilon: 0.16804558000875425    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 7.87\n",
      "episode: 2155   score: 11.0   memory length: 520727   epsilon: 0.16695856000874737    steps: 549    lr: 2.560000000000001e-06     evaluation reward: 7.89\n",
      "episode: 2156   score: 5.0   memory length: 521015   epsilon: 0.16638832000874376    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 7.87\n",
      "episode: 2157   score: 14.0   memory length: 521548   epsilon: 0.16533298000873708    steps: 533    lr: 2.560000000000001e-06     evaluation reward: 7.95\n",
      "episode: 2158   score: 7.0   memory length: 521934   epsilon: 0.16456870000873225    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 7.94\n",
      "episode: 2159   score: 10.0   memory length: 522419   epsilon: 0.16360840000872617    steps: 485    lr: 2.560000000000001e-06     evaluation reward: 7.92\n",
      "episode: 2160   score: 11.0   memory length: 522929   epsilon: 0.16259860000871978    steps: 510    lr: 2.560000000000001e-06     evaluation reward: 7.97\n",
      "episode: 2161   score: 11.0   memory length: 523479   epsilon: 0.1615096000087129    steps: 550    lr: 2.560000000000001e-06     evaluation reward: 8.0\n",
      "episode: 2162   score: 6.0   memory length: 523800   epsilon: 0.16087402000870887    steps: 321    lr: 2.560000000000001e-06     evaluation reward: 8.0\n",
      "episode: 2163   score: 6.0   memory length: 524137   epsilon: 0.16020676000870465    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 8.01\n",
      "episode: 2164   score: 7.0   memory length: 524560   epsilon: 0.15936922000869935    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 7.97\n",
      "episode: 2165   score: 16.0   memory length: 525089   epsilon: 0.15832180000869273    steps: 529    lr: 2.560000000000001e-06     evaluation reward: 8.06\n",
      "episode: 2166   score: 7.0   memory length: 525513   epsilon: 0.15748228000868741    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 8.08\n",
      "episode: 2167   score: 12.0   memory length: 526065   epsilon: 0.1563893200086805    steps: 552    lr: 2.560000000000001e-06     evaluation reward: 8.12\n",
      "episode: 2168   score: 4.0   memory length: 526323   epsilon: 0.15587848000867727    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 8.08\n",
      "episode: 2169   score: 8.0   memory length: 526816   epsilon: 0.1549023400086711    steps: 493    lr: 2.560000000000001e-06     evaluation reward: 8.11\n",
      "episode: 2170   score: 4.0   memory length: 527058   epsilon: 0.15442318000866806    steps: 242    lr: 2.560000000000001e-06     evaluation reward: 8.06\n",
      "episode: 2171   score: 7.0   memory length: 527431   epsilon: 0.1536846400086634    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 8.07\n",
      "episode: 2172   score: 9.0   memory length: 527906   epsilon: 0.15274414000865744    steps: 475    lr: 2.560000000000001e-06     evaluation reward: 8.07\n",
      "episode: 2173   score: 9.0   memory length: 528398   epsilon: 0.15176998000865127    steps: 492    lr: 2.560000000000001e-06     evaluation reward: 8.07\n",
      "episode: 2174   score: 9.0   memory length: 528828   epsilon: 0.1509185800086459    steps: 430    lr: 2.560000000000001e-06     evaluation reward: 8.1\n",
      "episode: 2175   score: 10.0   memory length: 529330   epsilon: 0.1499246200086396    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 8.1\n",
      "episode: 2176   score: 13.0   memory length: 529870   epsilon: 0.14885542000863283    steps: 540    lr: 2.560000000000001e-06     evaluation reward: 8.15\n",
      "episode: 2177   score: 7.0   memory length: 530316   epsilon: 0.14797234000862725    steps: 446    lr: 2.560000000000001e-06     evaluation reward: 8.13\n",
      "episode: 2178   score: 6.0   memory length: 530676   epsilon: 0.14725954000862274    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 8.1\n",
      "episode: 2179   score: 6.0   memory length: 531046   epsilon: 0.1465269400086181    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 8.09\n",
      "episode: 2180   score: 7.0   memory length: 531434   epsilon: 0.14575870000861324    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 8.09\n",
      "episode: 2181   score: 11.0   memory length: 531897   epsilon: 0.14484196000860744    steps: 463    lr: 2.560000000000001e-06     evaluation reward: 8.16\n",
      "episode: 2182   score: 7.0   memory length: 532303   epsilon: 0.14403808000860235    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 8.19\n",
      "episode: 2183   score: 10.0   memory length: 532765   epsilon: 0.14312332000859657    steps: 462    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2184   score: 4.0   memory length: 533008   epsilon: 0.14264218000859352    steps: 243    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2185   score: 9.0   memory length: 533491   epsilon: 0.14168584000858747    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 8.21\n",
      "episode: 2186   score: 6.0   memory length: 533810   epsilon: 0.14105422000858348    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 8.21\n",
      "episode: 2187   score: 9.0   memory length: 534287   epsilon: 0.1401097600085775    steps: 477    lr: 2.560000000000001e-06     evaluation reward: 8.24\n",
      "episode: 2188   score: 9.0   memory length: 534714   epsilon: 0.13926430000857215    steps: 427    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2189   score: 5.0   memory length: 535039   epsilon: 0.13862080000856808    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2190   score: 6.0   memory length: 535358   epsilon: 0.13798918000856408    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2191   score: 9.0   memory length: 535839   epsilon: 0.13703680000855806    steps: 481    lr: 2.560000000000001e-06     evaluation reward: 8.34\n",
      "episode: 2192   score: 10.0   memory length: 536330   epsilon: 0.1360646200085519    steps: 491    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2193   score: 7.0   memory length: 536734   epsilon: 0.13526470000854685    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 8.42\n",
      "episode: 2194   score: 5.0   memory length: 537039   epsilon: 0.13466080000854302    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 8.34\n",
      "episode: 2195   score: 5.0   memory length: 537345   epsilon: 0.1340549200085392    steps: 306    lr: 2.560000000000001e-06     evaluation reward: 8.32\n",
      "episode: 2196   score: 10.0   memory length: 537850   epsilon: 0.13305502000853286    steps: 505    lr: 2.560000000000001e-06     evaluation reward: 8.27\n",
      "episode: 2197   score: 5.0   memory length: 538138   epsilon: 0.13248478000852926    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 8.23\n",
      "episode: 2198   score: 14.0   memory length: 538721   epsilon: 0.13133044000852195    steps: 583    lr: 2.560000000000001e-06     evaluation reward: 8.31\n",
      "episode: 2199   score: 7.0   memory length: 539111   epsilon: 0.13055824000851707    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 8.29\n",
      "episode: 2200   score: 7.0   memory length: 539515   epsilon: 0.129758320008512    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 8.29\n",
      "episode: 2201   score: 10.0   memory length: 540025   epsilon: 0.12874852000850562    steps: 510    lr: 2.560000000000001e-06     evaluation reward: 8.32\n",
      "episode: 2202   score: 10.0   memory length: 540474   epsilon: 0.1278595000085    steps: 449    lr: 2.560000000000001e-06     evaluation reward: 8.35\n",
      "episode: 2203   score: 8.0   memory length: 540910   epsilon: 0.12699622000849453    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 8.34\n",
      "episode: 2204   score: 11.0   memory length: 541479   epsilon: 0.1258696000084874    steps: 569    lr: 2.560000000000001e-06     evaluation reward: 8.38\n",
      "episode: 2205   score: 9.0   memory length: 541952   epsilon: 0.12493306000848195    steps: 473    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2206   score: 14.0   memory length: 542520   epsilon: 0.12380842000848272    steps: 568    lr: 2.560000000000001e-06     evaluation reward: 8.49\n",
      "episode: 2207   score: 10.0   memory length: 543003   epsilon: 0.12285208000848337    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 8.5\n",
      "episode: 2208   score: 7.0   memory length: 543393   epsilon: 0.1220798800084839    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 8.52\n",
      "episode: 2209   score: 5.0   memory length: 543697   epsilon: 0.1214779600084843    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 8.5\n",
      "episode: 2210   score: 7.0   memory length: 544081   epsilon: 0.12071764000848483    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 8.47\n",
      "episode: 2211   score: 6.0   memory length: 544420   epsilon: 0.12004642000848528    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 8.42\n",
      "episode: 2212   score: 7.0   memory length: 544808   epsilon: 0.1192781800084858    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 8.45\n",
      "episode: 2213   score: 8.0   memory length: 545254   epsilon: 0.11839510000848641    steps: 446    lr: 2.560000000000001e-06     evaluation reward: 8.47\n",
      "episode: 2214   score: 6.0   memory length: 545607   epsilon: 0.11769616000848689    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2215   score: 5.0   memory length: 545929   epsilon: 0.11705860000848732    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 8.38\n",
      "episode: 2216   score: 8.0   memory length: 546363   epsilon: 0.1161992800084879    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2217   score: 8.0   memory length: 546770   epsilon: 0.11539342000848846    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2218   score: 9.0   memory length: 547241   epsilon: 0.11446084000848909    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 8.41\n",
      "episode: 2219   score: 11.0   memory length: 547824   epsilon: 0.11330650000848988    steps: 583    lr: 2.560000000000001e-06     evaluation reward: 8.43\n",
      "episode: 2220   score: 11.0   memory length: 548254   epsilon: 0.11245510000849046    steps: 430    lr: 2.560000000000001e-06     evaluation reward: 8.41\n",
      "episode: 2221   score: 12.0   memory length: 548825   epsilon: 0.11132452000849123    steps: 571    lr: 2.560000000000001e-06     evaluation reward: 8.45\n",
      "episode: 2222   score: 7.0   memory length: 549185   epsilon: 0.11061172000849172    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2223   score: 6.0   memory length: 549542   epsilon: 0.1099048600084922    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2224   score: 7.0   memory length: 549971   epsilon: 0.10905544000849278    steps: 429    lr: 2.560000000000001e-06     evaluation reward: 8.37\n",
      "episode: 2225   score: 11.0   memory length: 550487   epsilon: 0.10803376000849348    steps: 516    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2226   score: 5.0   memory length: 550796   epsilon: 0.1074219400084939    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 8.38\n",
      "episode: 2227   score: 10.0   memory length: 551299   epsilon: 0.10642600000849457    steps: 503    lr: 2.560000000000001e-06     evaluation reward: 8.42\n",
      "episode: 2228   score: 8.0   memory length: 551780   epsilon: 0.10547362000849522    steps: 481    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2229   score: 7.0   memory length: 552145   epsilon: 0.10475092000849572    steps: 365    lr: 2.560000000000001e-06     evaluation reward: 8.27\n",
      "episode: 2230   score: 9.0   memory length: 552592   epsilon: 0.10386586000849632    steps: 447    lr: 2.560000000000001e-06     evaluation reward: 8.28\n",
      "episode: 2231   score: 9.0   memory length: 553090   epsilon: 0.10287982000849699    steps: 498    lr: 2.560000000000001e-06     evaluation reward: 8.31\n",
      "episode: 2232   score: 4.0   memory length: 553388   epsilon: 0.1022897800084974    steps: 298    lr: 2.560000000000001e-06     evaluation reward: 8.24\n",
      "episode: 2233   score: 8.0   memory length: 553879   epsilon: 0.10131760000849806    steps: 491    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2234   score: 7.0   memory length: 554231   epsilon: 0.10062064000849853    steps: 352    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2235   score: 7.0   memory length: 554621   epsilon: 0.09984844000849906    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 8.17\n",
      "episode: 2236   score: 8.0   memory length: 555087   epsilon: 0.09892576000849969    steps: 466    lr: 2.560000000000001e-06     evaluation reward: 8.15\n",
      "episode: 2237   score: 8.0   memory length: 555554   epsilon: 0.09800110000850032    steps: 467    lr: 2.560000000000001e-06     evaluation reward: 8.17\n",
      "episode: 2238   score: 8.0   memory length: 555956   epsilon: 0.09720514000850086    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 8.17\n",
      "episode: 2239   score: 6.0   memory length: 556293   epsilon: 0.09653788000850132    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 8.16\n",
      "episode: 2240   score: 13.0   memory length: 556791   epsilon: 0.09555184000850199    steps: 498    lr: 2.560000000000001e-06     evaluation reward: 8.24\n",
      "episode: 2241   score: 6.0   memory length: 557155   epsilon: 0.09483112000850248    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 8.21\n",
      "episode: 2242   score: 5.0   memory length: 557479   epsilon: 0.09418960000850292    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 8.17\n",
      "episode: 2243   score: 7.0   memory length: 557864   epsilon: 0.09342730000850344    steps: 385    lr: 2.560000000000001e-06     evaluation reward: 8.16\n",
      "episode: 2244   score: 9.0   memory length: 558341   epsilon: 0.09248284000850408    steps: 477    lr: 2.560000000000001e-06     evaluation reward: 8.19\n",
      "episode: 2245   score: 10.0   memory length: 558845   epsilon: 0.09148492000850476    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 8.19\n",
      "episode: 2246   score: 8.0   memory length: 559280   epsilon: 0.09062362000850535    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 8.21\n",
      "episode: 2247   score: 10.0   memory length: 559651   epsilon: 0.08988904000850585    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 8.23\n",
      "episode: 2248   score: 7.0   memory length: 559986   epsilon: 0.0892257400085063    steps: 335    lr: 2.560000000000001e-06     evaluation reward: 8.21\n",
      "episode: 2249   score: 11.0   memory length: 560520   epsilon: 0.08816842000850703    steps: 534    lr: 2.560000000000001e-06     evaluation reward: 8.19\n",
      "episode: 2250   score: 12.0   memory length: 561069   epsilon: 0.08708140000850777    steps: 549    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2251   score: 9.0   memory length: 561571   epsilon: 0.08608744000850845    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 8.25\n",
      "episode: 2252   score: 17.0   memory length: 562251   epsilon: 0.08474104000850936    steps: 680    lr: 2.560000000000001e-06     evaluation reward: 8.35\n",
      "episode: 2253   score: 6.0   memory length: 562554   epsilon: 0.08414110000850977    steps: 303    lr: 2.560000000000001e-06     evaluation reward: 8.32\n",
      "episode: 2254   score: 15.0   memory length: 562975   epsilon: 0.08330752000851034    steps: 421    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2255   score: 16.0   memory length: 563497   epsilon: 0.08227396000851105    steps: 522    lr: 2.560000000000001e-06     evaluation reward: 8.44\n",
      "episode: 2256   score: 7.0   memory length: 563918   epsilon: 0.08144038000851161    steps: 421    lr: 2.560000000000001e-06     evaluation reward: 8.46\n",
      "episode: 2257   score: 8.0   memory length: 564353   epsilon: 0.0805790800085122    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2258   score: 6.0   memory length: 564710   epsilon: 0.07987222000851268    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2259   score: 7.0   memory length: 565096   epsilon: 0.0791079400085132    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 8.36\n",
      "episode: 2260   score: 10.0   memory length: 565507   epsilon: 0.07829416000851376    steps: 411    lr: 2.560000000000001e-06     evaluation reward: 8.35\n",
      "episode: 2261   score: 9.0   memory length: 565989   epsilon: 0.07733980000851441    steps: 482    lr: 2.560000000000001e-06     evaluation reward: 8.33\n",
      "episode: 2262   score: 7.0   memory length: 566398   epsilon: 0.07652998000851496    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 8.34\n",
      "episode: 2263   score: 9.0   memory length: 566875   epsilon: 0.07558552000851561    steps: 477    lr: 2.560000000000001e-06     evaluation reward: 8.37\n",
      "episode: 2264   score: 10.0   memory length: 567246   epsilon: 0.07485094000851611    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2265   score: 6.0   memory length: 567566   epsilon: 0.07421734000851654    steps: 320    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2266   score: 7.0   memory length: 567957   epsilon: 0.07344316000851707    steps: 391    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2267   score: 9.0   memory length: 568422   epsilon: 0.0725224600085177    steps: 465    lr: 2.560000000000001e-06     evaluation reward: 8.27\n",
      "episode: 2268   score: 7.0   memory length: 568827   epsilon: 0.07172056000851824    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2269   score: 13.0   memory length: 569375   epsilon: 0.07063552000851898    steps: 548    lr: 2.560000000000001e-06     evaluation reward: 8.35\n",
      "episode: 2270   score: 11.0   memory length: 569872   epsilon: 0.06965146000851966    steps: 497    lr: 2.560000000000001e-06     evaluation reward: 8.42\n",
      "episode: 2271   score: 10.0   memory length: 570356   epsilon: 0.06869314000852031    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 8.45\n",
      "episode: 2272   score: 4.0   memory length: 570619   epsilon: 0.06817240000852066    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 8.4\n",
      "episode: 2273   score: 4.0   memory length: 570896   epsilon: 0.06762394000852104    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 8.35\n",
      "episode: 2274   score: 6.0   memory length: 571257   epsilon: 0.06690916000852153    steps: 361    lr: 2.560000000000001e-06     evaluation reward: 8.32\n",
      "episode: 2275   score: 9.0   memory length: 571725   epsilon: 0.06598252000852216    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 8.31\n",
      "episode: 2276   score: 12.0   memory length: 572221   epsilon: 0.06500044000852283    steps: 496    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2277   score: 10.0   memory length: 572691   epsilon: 0.06406984000852346    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 8.33\n",
      "episode: 2278   score: 10.0   memory length: 573187   epsilon: 0.06308776000852413    steps: 496    lr: 2.560000000000001e-06     evaluation reward: 8.37\n",
      "episode: 2279   score: 7.0   memory length: 573573   epsilon: 0.062323480008524654    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 8.38\n",
      "episode: 2280   score: 12.0   memory length: 574024   epsilon: 0.06143050000852526    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 8.43\n",
      "episode: 2281   score: 16.0   memory length: 574627   epsilon: 0.06023656000852608    steps: 603    lr: 2.560000000000001e-06     evaluation reward: 8.48\n",
      "episode: 2282   score: 8.0   memory length: 575034   epsilon: 0.05943070000852663    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 8.49\n",
      "episode: 2283   score: 6.0   memory length: 575408   epsilon: 0.05869018000852713    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 8.45\n",
      "episode: 2284   score: 7.0   memory length: 575774   epsilon: 0.057965500008527626    steps: 366    lr: 2.560000000000001e-06     evaluation reward: 8.48\n",
      "episode: 2285   score: 7.0   memory length: 576182   epsilon: 0.05715766000852818    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 8.46\n",
      "episode: 2286   score: 14.0   memory length: 576824   epsilon: 0.055886500008529044    steps: 642    lr: 2.560000000000001e-06     evaluation reward: 8.54\n",
      "episode: 2287   score: 10.0   memory length: 577295   epsilon: 0.05495392000852968    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 8.55\n",
      "episode: 2288   score: 5.0   memory length: 577604   epsilon: 0.0543421000085301    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 8.51\n",
      "episode: 2289   score: 11.0   memory length: 578043   epsilon: 0.05347288000853069    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 8.57\n",
      "episode: 2290   score: 7.0   memory length: 578451   epsilon: 0.05266504000853124    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 8.58\n",
      "episode: 2291   score: 10.0   memory length: 578953   epsilon: 0.05167108000853192    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 8.59\n",
      "episode: 2292   score: 6.0   memory length: 579298   epsilon: 0.050987980008532385    steps: 345    lr: 2.560000000000001e-06     evaluation reward: 8.55\n",
      "episode: 2293   score: 8.0   memory length: 579701   epsilon: 0.05019004000853293    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 8.56\n",
      "episode: 2294   score: 8.0   memory length: 580162   epsilon: 0.04927726000853355    steps: 461    lr: 2.560000000000001e-06     evaluation reward: 8.59\n",
      "episode: 2295   score: 6.0   memory length: 580516   epsilon: 0.04857634000853403    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 8.6\n",
      "episode: 2296   score: 9.0   memory length: 580999   epsilon: 0.04762000000853468    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 8.59\n",
      "episode: 2297   score: 6.0   memory length: 581361   epsilon: 0.04690324000853517    steps: 362    lr: 2.560000000000001e-06     evaluation reward: 8.6\n",
      "episode: 2298   score: 5.0   memory length: 581685   epsilon: 0.04626172000853561    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 8.51\n",
      "episode: 2299   score: 9.0   memory length: 582115   epsilon: 0.04541032000853619    steps: 430    lr: 2.560000000000001e-06     evaluation reward: 8.53\n",
      "episode: 2300   score: 11.0   memory length: 582524   epsilon: 0.04460050000853674    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 8.57\n",
      "episode: 2301   score: 10.0   memory length: 583005   epsilon: 0.04364812000853739    steps: 481    lr: 2.560000000000001e-06     evaluation reward: 8.57\n",
      "episode: 2302   score: 8.0   memory length: 583462   epsilon: 0.04274326000853801    steps: 457    lr: 2.560000000000001e-06     evaluation reward: 8.55\n",
      "episode: 2303   score: 10.0   memory length: 584005   epsilon: 0.04166812000853874    steps: 543    lr: 2.560000000000001e-06     evaluation reward: 8.57\n",
      "episode: 2304   score: 7.0   memory length: 584413   epsilon: 0.04086028000853929    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 8.53\n",
      "episode: 2305   score: 10.0   memory length: 584785   epsilon: 0.040123720008539795    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 8.54\n",
      "episode: 2306   score: 11.0   memory length: 585327   epsilon: 0.03905056000854053    steps: 542    lr: 2.560000000000001e-06     evaluation reward: 8.51\n",
      "episode: 2307   score: 8.0   memory length: 585709   epsilon: 0.03829420000854104    steps: 382    lr: 2.560000000000001e-06     evaluation reward: 8.49\n",
      "episode: 2308   score: 15.0   memory length: 586161   epsilon: 0.037399240008541654    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 8.57\n",
      "episode: 2309   score: 7.0   memory length: 586513   epsilon: 0.03670228000854213    steps: 352    lr: 2.560000000000001e-06     evaluation reward: 8.59\n",
      "episode: 2310   score: 11.0   memory length: 586955   epsilon: 0.035827120008542726    steps: 442    lr: 2.560000000000001e-06     evaluation reward: 8.63\n",
      "episode: 2311   score: 9.0   memory length: 587348   epsilon: 0.03504898000854326    steps: 393    lr: 2.560000000000001e-06     evaluation reward: 8.66\n",
      "episode: 2312   score: 11.0   memory length: 587902   epsilon: 0.033952060008544005    steps: 554    lr: 2.560000000000001e-06     evaluation reward: 8.7\n",
      "episode: 2313   score: 13.0   memory length: 588392   epsilon: 0.03298186000854467    steps: 490    lr: 2.560000000000001e-06     evaluation reward: 8.75\n",
      "episode: 2314   score: 9.0   memory length: 588864   epsilon: 0.032047300008545304    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 8.78\n",
      "episode: 2315   score: 12.0   memory length: 589308   epsilon: 0.031168180008545904    steps: 444    lr: 2.560000000000001e-06     evaluation reward: 8.85\n",
      "episode: 2316   score: 14.0   memory length: 589939   epsilon: 0.029918800008546756    steps: 631    lr: 2.560000000000001e-06     evaluation reward: 8.91\n",
      "episode: 2317   score: 10.0   memory length: 590423   epsilon: 0.02896048000854741    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 8.93\n",
      "episode: 2318   score: 12.0   memory length: 590841   epsilon: 0.028132840008547974    steps: 418    lr: 2.560000000000001e-06     evaluation reward: 8.96\n",
      "episode: 2319   score: 10.0   memory length: 591374   epsilon: 0.027077500008548694    steps: 533    lr: 2.560000000000001e-06     evaluation reward: 8.95\n",
      "episode: 2320   score: 10.0   memory length: 591829   epsilon: 0.02617660000854931    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2321   score: 9.0   memory length: 592305   epsilon: 0.02523412000854995    steps: 476    lr: 2.560000000000001e-06     evaluation reward: 8.91\n",
      "episode: 2322   score: 10.0   memory length: 592696   epsilon: 0.02445994000855048    steps: 391    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2323   score: 10.0   memory length: 593201   epsilon: 0.02346004000855116    steps: 505    lr: 2.560000000000001e-06     evaluation reward: 8.98\n",
      "episode: 2324   score: 12.0   memory length: 593761   epsilon: 0.022351240008551918    steps: 560    lr: 2.560000000000001e-06     evaluation reward: 9.03\n",
      "episode: 2325   score: 12.0   memory length: 594219   epsilon: 0.021444400008552536    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 9.04\n",
      "episode: 2326   score: 7.0   memory length: 594588   epsilon: 0.020713780008553034    steps: 369    lr: 2.560000000000001e-06     evaluation reward: 9.06\n",
      "episode: 2327   score: 10.0   memory length: 594960   epsilon: 0.019977220008553537    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 9.06\n",
      "episode: 2328   score: 7.0   memory length: 595348   epsilon: 0.01920898000855406    steps: 388    lr: 2.560000000000001e-06     evaluation reward: 9.05\n",
      "episode: 2329   score: 10.0   memory length: 595816   epsilon: 0.018282340008554693    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 9.08\n",
      "episode: 2330   score: 9.0   memory length: 596335   epsilon: 0.017254720008555394    steps: 519    lr: 2.560000000000001e-06     evaluation reward: 9.08\n",
      "episode: 2331   score: 10.0   memory length: 596707   epsilon: 0.016518160008555896    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 9.09\n",
      "episode: 2332   score: 11.0   memory length: 597109   epsilon: 0.01572220000855644    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 9.16\n",
      "episode: 2333   score: 14.0   memory length: 597733   epsilon: 0.014486680008556284    steps: 624    lr: 2.560000000000001e-06     evaluation reward: 9.22\n",
      "episode: 2334   score: 12.0   memory length: 598284   epsilon: 0.013395700008556072    steps: 551    lr: 2.560000000000001e-06     evaluation reward: 9.27\n",
      "episode: 2335   score: 10.0   memory length: 598768   epsilon: 0.012437380008555887    steps: 484    lr: 2.560000000000001e-06     evaluation reward: 9.3\n",
      "episode: 2336   score: 5.0   memory length: 599097   epsilon: 0.01178596000855576    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 9.27\n",
      "episode: 2337   score: 10.0   memory length: 599619   epsilon: 0.01075240000855556    steps: 522    lr: 2.560000000000001e-06     evaluation reward: 9.29\n",
      "episode: 2338   score: 10.0   memory length: 599991   epsilon: 0.010015840008555417    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 9.31\n",
      "episode: 2339   score: 11.0   memory length: 600393   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2340   score: 7.0   memory length: 600746   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2341   score: 14.0   memory length: 601295   epsilon: 0.009998020008555413    steps: 549    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2342   score: 12.0   memory length: 601865   epsilon: 0.009998020008555413    steps: 570    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2343   score: 8.0   memory length: 602293   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 9.46\n",
      "episode: 2344   score: 17.0   memory length: 602911   epsilon: 0.009998020008555413    steps: 618    lr: 1.0240000000000005e-06     evaluation reward: 9.54\n",
      "episode: 2345   score: 8.0   memory length: 603342   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 9.52\n",
      "episode: 2346   score: 13.0   memory length: 603844   epsilon: 0.009998020008555413    steps: 502    lr: 1.0240000000000005e-06     evaluation reward: 9.57\n",
      "episode: 2347   score: 9.0   memory length: 604360   epsilon: 0.009998020008555413    steps: 516    lr: 1.0240000000000005e-06     evaluation reward: 9.56\n",
      "episode: 2348   score: 9.0   memory length: 604809   epsilon: 0.009998020008555413    steps: 449    lr: 1.0240000000000005e-06     evaluation reward: 9.58\n",
      "episode: 2349   score: 10.0   memory length: 605386   epsilon: 0.009998020008555413    steps: 577    lr: 1.0240000000000005e-06     evaluation reward: 9.57\n",
      "episode: 2350   score: 9.0   memory length: 605848   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 9.54\n",
      "episode: 2351   score: 7.0   memory length: 606224   epsilon: 0.009998020008555413    steps: 376    lr: 1.0240000000000005e-06     evaluation reward: 9.52\n",
      "episode: 2352   score: 9.0   memory length: 606724   epsilon: 0.009998020008555413    steps: 500    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2353   score: 8.0   memory length: 607178   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 9.46\n",
      "episode: 2354   score: 9.0   memory length: 607623   epsilon: 0.009998020008555413    steps: 445    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2355   score: 9.0   memory length: 608091   epsilon: 0.009998020008555413    steps: 468    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2356   score: 10.0   memory length: 608639   epsilon: 0.009998020008555413    steps: 548    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2357   score: 9.0   memory length: 609101   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 9.37\n",
      "episode: 2358   score: 8.0   memory length: 609484   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2359   score: 9.0   memory length: 609955   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 9.41\n",
      "episode: 2360   score: 6.0   memory length: 610311   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 9.37\n",
      "episode: 2361   score: 6.0   memory length: 610650   epsilon: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2362   score: 12.0   memory length: 611295   epsilon: 0.009998020008555413    steps: 645    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2363   score: 9.0   memory length: 611743   epsilon: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2364   score: 11.0   memory length: 612335   epsilon: 0.009998020008555413    steps: 592    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2365   score: 9.0   memory length: 612851   epsilon: 0.009998020008555413    steps: 516    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2366   score: 6.0   memory length: 613158   epsilon: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     evaluation reward: 9.42\n",
      "episode: 2367   score: 7.0   memory length: 613552   epsilon: 0.009998020008555413    steps: 394    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2368   score: 5.0   memory length: 613861   epsilon: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2369   score: 7.0   memory length: 614283   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2370   score: 4.0   memory length: 614560   epsilon: 0.009998020008555413    steps: 277    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2371   score: 10.0   memory length: 615027   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2372   score: 7.0   memory length: 615398   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2373   score: 9.0   memory length: 615879   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2374   score: 7.0   memory length: 616248   epsilon: 0.009998020008555413    steps: 369    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2375   score: 11.0   memory length: 616798   epsilon: 0.009998020008555413    steps: 550    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2376   score: 10.0   memory length: 617330   epsilon: 0.009998020008555413    steps: 532    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2377   score: 6.0   memory length: 617679   epsilon: 0.009998020008555413    steps: 349    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2378   score: 9.0   memory length: 618141   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 9.29\n",
      "episode: 2379   score: 9.0   memory length: 618617   epsilon: 0.009998020008555413    steps: 476    lr: 1.0240000000000005e-06     evaluation reward: 9.31\n",
      "episode: 2380   score: 11.0   memory length: 619142   epsilon: 0.009998020008555413    steps: 525    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2381   score: 10.0   memory length: 619649   epsilon: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     evaluation reward: 9.24\n",
      "episode: 2382   score: 9.0   memory length: 620136   epsilon: 0.009998020008555413    steps: 487    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2383   score: 9.0   memory length: 620639   epsilon: 0.009998020008555413    steps: 503    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2384   score: 12.0   memory length: 621169   epsilon: 0.009998020008555413    steps: 530    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2385   score: 11.0   memory length: 621621   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.37\n",
      "episode: 2386   score: 11.0   memory length: 622181   epsilon: 0.009998020008555413    steps: 560    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2387   score: 8.0   memory length: 622567   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2388   score: 7.0   memory length: 622971   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2389   score: 6.0   memory length: 623276   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 9.29\n",
      "episode: 2390   score: 11.0   memory length: 623827   epsilon: 0.009998020008555413    steps: 551    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2391   score: 9.0   memory length: 624307   epsilon: 0.009998020008555413    steps: 480    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2392   score: 9.0   memory length: 624797   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2393   score: 10.0   memory length: 625291   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 9.37\n",
      "episode: 2394   score: 9.0   memory length: 625730   epsilon: 0.009998020008555413    steps: 439    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2395   score: 7.0   memory length: 626118   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2396   score: 11.0   memory length: 626570   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.41\n",
      "episode: 2397   score: 9.0   memory length: 627022   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2398   score: 9.0   memory length: 627364   epsilon: 0.009998020008555413    steps: 342    lr: 1.0240000000000005e-06     evaluation reward: 9.48\n",
      "episode: 2399   score: 10.0   memory length: 627846   epsilon: 0.009998020008555413    steps: 482    lr: 1.0240000000000005e-06     evaluation reward: 9.49\n",
      "episode: 2400   score: 5.0   memory length: 628135   epsilon: 0.009998020008555413    steps: 289    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2401   score: 7.0   memory length: 628557   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2402   score: 16.0   memory length: 629149   epsilon: 0.009998020008555413    steps: 592    lr: 1.0240000000000005e-06     evaluation reward: 9.48\n",
      "episode: 2403   score: 8.0   memory length: 629550   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 9.46\n",
      "episode: 2404   score: 9.0   memory length: 630041   epsilon: 0.009998020008555413    steps: 491    lr: 1.0240000000000005e-06     evaluation reward: 9.48\n",
      "episode: 2405   score: 11.0   memory length: 630556   epsilon: 0.009998020008555413    steps: 515    lr: 1.0240000000000005e-06     evaluation reward: 9.49\n",
      "episode: 2406   score: 10.0   memory length: 631089   epsilon: 0.009998020008555413    steps: 533    lr: 1.0240000000000005e-06     evaluation reward: 9.48\n",
      "episode: 2407   score: 9.0   memory length: 631568   epsilon: 0.009998020008555413    steps: 479    lr: 1.0240000000000005e-06     evaluation reward: 9.49\n",
      "episode: 2408   score: 10.0   memory length: 631939   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2409   score: 7.0   memory length: 632349   epsilon: 0.009998020008555413    steps: 410    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2410   score: 8.0   memory length: 632768   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 9.41\n",
      "episode: 2411   score: 8.0   memory length: 633237   epsilon: 0.009998020008555413    steps: 469    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2412   score: 14.0   memory length: 633830   epsilon: 0.009998020008555413    steps: 593    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2413   score: 10.0   memory length: 634344   epsilon: 0.009998020008555413    steps: 514    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2414   score: 8.0   memory length: 634732   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2415   score: 9.0   memory length: 635203   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2416   score: 8.0   memory length: 635585   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2417   score: 12.0   memory length: 636204   epsilon: 0.009998020008555413    steps: 619    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2418   score: 10.0   memory length: 636656   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2419   score: 7.0   memory length: 637037   epsilon: 0.009998020008555413    steps: 381    lr: 1.0240000000000005e-06     evaluation reward: 9.27\n",
      "episode: 2420   score: 5.0   memory length: 637310   epsilon: 0.009998020008555413    steps: 273    lr: 1.0240000000000005e-06     evaluation reward: 9.22\n",
      "episode: 2421   score: 10.0   memory length: 637780   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2422   score: 13.0   memory length: 638213   epsilon: 0.009998020008555413    steps: 433    lr: 1.0240000000000005e-06     evaluation reward: 9.26\n",
      "episode: 2423   score: 7.0   memory length: 638595   epsilon: 0.009998020008555413    steps: 382    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2424   score: 6.0   memory length: 638967   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 9.17\n",
      "episode: 2425   score: 10.0   memory length: 639496   epsilon: 0.009998020008555413    steps: 529    lr: 1.0240000000000005e-06     evaluation reward: 9.15\n",
      "episode: 2426   score: 10.0   memory length: 639984   epsilon: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     evaluation reward: 9.18\n",
      "episode: 2427   score: 9.0   memory length: 640462   epsilon: 0.009998020008555413    steps: 478    lr: 1.0240000000000005e-06     evaluation reward: 9.17\n",
      "episode: 2428   score: 16.0   memory length: 641053   epsilon: 0.009998020008555413    steps: 591    lr: 1.0240000000000005e-06     evaluation reward: 9.26\n",
      "episode: 2429   score: 9.0   memory length: 641554   epsilon: 0.009998020008555413    steps: 501    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2430   score: 14.0   memory length: 642059   epsilon: 0.009998020008555413    steps: 505    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2431   score: 16.0   memory length: 642635   epsilon: 0.009998020008555413    steps: 576    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2432   score: 13.0   memory length: 643214   epsilon: 0.009998020008555413    steps: 579    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2433   score: 11.0   memory length: 643714   epsilon: 0.009998020008555413    steps: 500    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2434   score: 16.0   memory length: 644277   epsilon: 0.009998020008555413    steps: 563    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2435   score: 11.0   memory length: 644809   epsilon: 0.009998020008555413    steps: 532    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2436   score: 12.0   memory length: 645390   epsilon: 0.009998020008555413    steps: 581    lr: 1.0240000000000005e-06     evaluation reward: 9.47\n",
      "episode: 2437   score: 8.0   memory length: 645844   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2438   score: 10.0   memory length: 646306   epsilon: 0.009998020008555413    steps: 462    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2439   score: 5.0   memory length: 646595   epsilon: 0.009998020008555413    steps: 289    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2440   score: 6.0   memory length: 646951   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2441   score: 8.0   memory length: 647388   epsilon: 0.009998020008555413    steps: 437    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2442   score: 9.0   memory length: 647833   epsilon: 0.009998020008555413    steps: 445    lr: 1.0240000000000005e-06     evaluation reward: 9.29\n",
      "episode: 2443   score: 6.0   memory length: 648207   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 9.27\n",
      "episode: 2444   score: 9.0   memory length: 648654   epsilon: 0.009998020008555413    steps: 447    lr: 1.0240000000000005e-06     evaluation reward: 9.19\n",
      "episode: 2445   score: 5.0   memory length: 648944   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 9.16\n",
      "episode: 2446   score: 10.0   memory length: 649463   epsilon: 0.009998020008555413    steps: 519    lr: 1.0240000000000005e-06     evaluation reward: 9.13\n",
      "episode: 2447   score: 11.0   memory length: 650017   epsilon: 0.009998020008555413    steps: 554    lr: 1.0240000000000005e-06     evaluation reward: 9.15\n",
      "episode: 2448   score: 8.0   memory length: 650435   epsilon: 0.009998020008555413    steps: 418    lr: 1.0240000000000005e-06     evaluation reward: 9.14\n",
      "episode: 2449   score: 7.0   memory length: 650805   epsilon: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2450   score: 10.0   memory length: 651317   epsilon: 0.009998020008555413    steps: 512    lr: 1.0240000000000005e-06     evaluation reward: 9.12\n",
      "episode: 2451   score: 6.0   memory length: 651680   epsilon: 0.009998020008555413    steps: 363    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2452   score: 6.0   memory length: 652000   epsilon: 0.009998020008555413    steps: 320    lr: 1.0240000000000005e-06     evaluation reward: 9.08\n",
      "episode: 2453   score: 7.0   memory length: 652349   epsilon: 0.009998020008555413    steps: 349    lr: 1.0240000000000005e-06     evaluation reward: 9.07\n",
      "episode: 2454   score: 12.0   memory length: 652784   epsilon: 0.009998020008555413    steps: 435    lr: 1.0240000000000005e-06     evaluation reward: 9.1\n",
      "episode: 2455   score: 9.0   memory length: 653248   epsilon: 0.009998020008555413    steps: 464    lr: 1.0240000000000005e-06     evaluation reward: 9.1\n",
      "episode: 2456   score: 9.0   memory length: 653685   epsilon: 0.009998020008555413    steps: 437    lr: 1.0240000000000005e-06     evaluation reward: 9.09\n",
      "episode: 2457   score: 6.0   memory length: 654006   epsilon: 0.009998020008555413    steps: 321    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2458   score: 7.0   memory length: 654389   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 9.05\n",
      "episode: 2459   score: 7.0   memory length: 654749   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2460   score: 10.0   memory length: 655237   epsilon: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     evaluation reward: 9.07\n",
      "episode: 2461   score: 12.0   memory length: 655708   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 9.13\n",
      "episode: 2462   score: 11.0   memory length: 656275   epsilon: 0.009998020008555413    steps: 567    lr: 1.0240000000000005e-06     evaluation reward: 9.12\n",
      "episode: 2463   score: 14.0   memory length: 656693   epsilon: 0.009998020008555413    steps: 418    lr: 1.0240000000000005e-06     evaluation reward: 9.17\n",
      "episode: 2464   score: 13.0   memory length: 657275   epsilon: 0.009998020008555413    steps: 582    lr: 1.0240000000000005e-06     evaluation reward: 9.19\n",
      "episode: 2465   score: 9.0   memory length: 657775   epsilon: 0.009998020008555413    steps: 500    lr: 1.0240000000000005e-06     evaluation reward: 9.19\n",
      "episode: 2466   score: 9.0   memory length: 658255   epsilon: 0.009998020008555413    steps: 480    lr: 1.0240000000000005e-06     evaluation reward: 9.22\n",
      "episode: 2467   score: 8.0   memory length: 658680   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2468   score: 10.0   memory length: 659176   epsilon: 0.009998020008555413    steps: 496    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2469   score: 8.0   memory length: 659600   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 9.29\n",
      "episode: 2470   score: 10.0   memory length: 660125   epsilon: 0.009998020008555413    steps: 525    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2471   score: 10.0   memory length: 660639   epsilon: 0.009998020008555413    steps: 514    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2472   score: 10.0   memory length: 661105   epsilon: 0.009998020008555413    steps: 466    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2473   score: 10.0   memory length: 661476   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2474   score: 8.0   memory length: 661909   epsilon: 0.009998020008555413    steps: 433    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2475   score: 13.0   memory length: 662498   epsilon: 0.009998020008555413    steps: 589    lr: 1.0240000000000005e-06     evaluation reward: 9.42\n",
      "episode: 2476   score: 11.0   memory length: 663020   epsilon: 0.009998020008555413    steps: 522    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2477   score: 7.0   memory length: 663408   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2478   score: 10.0   memory length: 663746   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2479   score: 13.0   memory length: 664311   epsilon: 0.009998020008555413    steps: 565    lr: 1.0240000000000005e-06     evaluation reward: 9.49\n",
      "episode: 2480   score: 8.0   memory length: 664740   epsilon: 0.009998020008555413    steps: 429    lr: 1.0240000000000005e-06     evaluation reward: 9.46\n",
      "episode: 2481   score: 9.0   memory length: 665146   epsilon: 0.009998020008555413    steps: 406    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2482   score: 13.0   memory length: 665657   epsilon: 0.009998020008555413    steps: 511    lr: 1.0240000000000005e-06     evaluation reward: 9.49\n",
      "episode: 2483   score: 10.0   memory length: 666012   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 9.5\n",
      "episode: 2484   score: 6.0   memory length: 666359   epsilon: 0.009998020008555413    steps: 347    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2485   score: 10.0   memory length: 666866   epsilon: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2486   score: 11.0   memory length: 667441   epsilon: 0.009998020008555413    steps: 575    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2487   score: 8.0   memory length: 667862   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2488   score: 7.0   memory length: 668284   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 9.43\n",
      "episode: 2489   score: 7.0   memory length: 668714   epsilon: 0.009998020008555413    steps: 430    lr: 1.0240000000000005e-06     evaluation reward: 9.44\n",
      "episode: 2490   score: 6.0   memory length: 669061   epsilon: 0.009998020008555413    steps: 347    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2491   score: 6.0   memory length: 669380   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2492   score: 13.0   memory length: 669871   epsilon: 0.009998020008555413    steps: 491    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2493   score: 6.0   memory length: 670231   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2494   score: 15.0   memory length: 670819   epsilon: 0.009998020008555413    steps: 588    lr: 1.0240000000000005e-06     evaluation reward: 9.42\n",
      "episode: 2495   score: 10.0   memory length: 671190   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2496   score: 14.0   memory length: 671809   epsilon: 0.009998020008555413    steps: 619    lr: 1.0240000000000005e-06     evaluation reward: 9.48\n",
      "episode: 2497   score: 13.0   memory length: 672327   epsilon: 0.009998020008555413    steps: 518    lr: 1.0240000000000005e-06     evaluation reward: 9.52\n",
      "episode: 2498   score: 10.0   memory length: 672804   epsilon: 0.009998020008555413    steps: 477    lr: 1.0240000000000005e-06     evaluation reward: 9.53\n",
      "episode: 2499   score: 7.0   memory length: 673169   epsilon: 0.009998020008555413    steps: 365    lr: 1.0240000000000005e-06     evaluation reward: 9.5\n",
      "episode: 2500   score: 10.0   memory length: 673694   epsilon: 0.009998020008555413    steps: 525    lr: 1.0240000000000005e-06     evaluation reward: 9.55\n",
      "episode: 2501   score: 6.0   memory length: 674033   epsilon: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     evaluation reward: 9.54\n",
      "episode: 2502   score: 12.0   memory length: 674590   epsilon: 0.009998020008555413    steps: 557    lr: 1.0240000000000005e-06     evaluation reward: 9.5\n",
      "episode: 2503   score: 6.0   memory length: 674926   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 9.48\n",
      "episode: 2504   score: 7.0   memory length: 675295   epsilon: 0.009998020008555413    steps: 369    lr: 1.0240000000000005e-06     evaluation reward: 9.46\n",
      "episode: 2505   score: 7.0   memory length: 675648   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 9.42\n",
      "episode: 2506   score: 8.0   memory length: 676050   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2507   score: 10.0   memory length: 676388   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 9.41\n",
      "episode: 2508   score: 11.0   memory length: 676943   epsilon: 0.009998020008555413    steps: 555    lr: 1.0240000000000005e-06     evaluation reward: 9.42\n",
      "episode: 2509   score: 7.0   memory length: 677345   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 9.42\n",
      "episode: 2510   score: 11.0   memory length: 677877   epsilon: 0.009998020008555413    steps: 532    lr: 1.0240000000000005e-06     evaluation reward: 9.45\n",
      "episode: 2511   score: 9.0   memory length: 678329   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.46\n",
      "episode: 2512   score: 5.0   memory length: 678632   epsilon: 0.009998020008555413    steps: 303    lr: 1.0240000000000005e-06     evaluation reward: 9.37\n",
      "episode: 2513   score: 7.0   memory length: 679015   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2514   score: 7.0   memory length: 679439   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2515   score: 10.0   memory length: 679929   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2516   score: 8.0   memory length: 680333   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2517   score: 9.0   memory length: 680790   epsilon: 0.009998020008555413    steps: 457    lr: 1.0240000000000005e-06     evaluation reward: 9.31\n",
      "episode: 2518   score: 7.0   memory length: 681139   epsilon: 0.009998020008555413    steps: 349    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2519   score: 10.0   memory length: 681649   epsilon: 0.009998020008555413    steps: 510    lr: 1.0240000000000005e-06     evaluation reward: 9.31\n",
      "episode: 2520   score: 9.0   memory length: 682094   epsilon: 0.009998020008555413    steps: 445    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2521   score: 11.0   memory length: 682605   epsilon: 0.009998020008555413    steps: 511    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2522   score: 4.0   memory length: 682882   epsilon: 0.009998020008555413    steps: 277    lr: 1.0240000000000005e-06     evaluation reward: 9.27\n",
      "episode: 2523   score: 8.0   memory length: 683322   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2524   score: 10.0   memory length: 683871   epsilon: 0.009998020008555413    steps: 549    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2525   score: 12.0   memory length: 684433   epsilon: 0.009998020008555413    steps: 562    lr: 1.0240000000000005e-06     evaluation reward: 9.34\n",
      "episode: 2526   score: 9.0   memory length: 684903   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2527   score: 7.0   memory length: 685307   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 9.31\n",
      "episode: 2528   score: 8.0   memory length: 685759   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2529   score: 6.0   memory length: 686099   epsilon: 0.009998020008555413    steps: 340    lr: 1.0240000000000005e-06     evaluation reward: 9.2\n",
      "episode: 2530   score: 13.0   memory length: 686640   epsilon: 0.009998020008555413    steps: 541    lr: 1.0240000000000005e-06     evaluation reward: 9.19\n",
      "episode: 2531   score: 11.0   memory length: 687026   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 9.14\n",
      "episode: 2532   score: 18.0   memory length: 687698   epsilon: 0.009998020008555413    steps: 672    lr: 1.0240000000000005e-06     evaluation reward: 9.19\n",
      "episode: 2533   score: 7.0   memory length: 688066   epsilon: 0.009998020008555413    steps: 368    lr: 1.0240000000000005e-06     evaluation reward: 9.15\n",
      "episode: 2534   score: 8.0   memory length: 688498   epsilon: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     evaluation reward: 9.07\n",
      "episode: 2535   score: 10.0   memory length: 689002   epsilon: 0.009998020008555413    steps: 504    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2536   score: 9.0   memory length: 689481   epsilon: 0.009998020008555413    steps: 479    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2537   score: 12.0   memory length: 689956   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 9.07\n",
      "episode: 2538   score: 5.0   memory length: 690282   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 9.02\n",
      "episode: 2539   score: 6.0   memory length: 690637   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2540   score: 9.0   memory length: 691065   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2541   score: 17.0   memory length: 691659   epsilon: 0.009998020008555413    steps: 594    lr: 1.0240000000000005e-06     evaluation reward: 9.15\n",
      "episode: 2542   score: 9.0   memory length: 692103   epsilon: 0.009998020008555413    steps: 444    lr: 1.0240000000000005e-06     evaluation reward: 9.15\n",
      "episode: 2543   score: 6.0   memory length: 692435   epsilon: 0.009998020008555413    steps: 332    lr: 1.0240000000000005e-06     evaluation reward: 9.15\n",
      "episode: 2544   score: 14.0   memory length: 692985   epsilon: 0.009998020008555413    steps: 550    lr: 1.0240000000000005e-06     evaluation reward: 9.2\n",
      "episode: 2545   score: 8.0   memory length: 693404   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2546   score: 9.0   memory length: 693773   epsilon: 0.009998020008555413    steps: 369    lr: 1.0240000000000005e-06     evaluation reward: 9.22\n",
      "episode: 2547   score: 9.0   memory length: 694225   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.2\n",
      "episode: 2548   score: 9.0   memory length: 694551   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 9.21\n",
      "episode: 2549   score: 10.0   memory length: 694923   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 9.24\n",
      "episode: 2550   score: 12.0   memory length: 695447   epsilon: 0.009998020008555413    steps: 524    lr: 1.0240000000000005e-06     evaluation reward: 9.26\n",
      "episode: 2551   score: 6.0   memory length: 695807   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 9.26\n",
      "episode: 2552   score: 10.0   memory length: 696305   epsilon: 0.009998020008555413    steps: 498    lr: 1.0240000000000005e-06     evaluation reward: 9.3\n",
      "episode: 2553   score: 8.0   memory length: 696736   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 9.31\n",
      "episode: 2554   score: 10.0   memory length: 697236   epsilon: 0.009998020008555413    steps: 500    lr: 1.0240000000000005e-06     evaluation reward: 9.29\n",
      "episode: 2555   score: 13.0   memory length: 697779   epsilon: 0.009998020008555413    steps: 543    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2556   score: 9.0   memory length: 698259   epsilon: 0.009998020008555413    steps: 480    lr: 1.0240000000000005e-06     evaluation reward: 9.33\n",
      "episode: 2557   score: 8.0   memory length: 698656   epsilon: 0.009998020008555413    steps: 397    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2558   score: 7.0   memory length: 699069   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 9.35\n",
      "episode: 2559   score: 9.0   memory length: 699395   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 9.37\n",
      "episode: 2560   score: 14.0   memory length: 699923   epsilon: 0.009998020008555413    steps: 528    lr: 1.0240000000000005e-06     evaluation reward: 9.41\n",
      "episode: 2561   score: 8.0   memory length: 700356   epsilon: 0.009998020008555413    steps: 433    lr: 4.0960000000000023e-07     evaluation reward: 9.37\n",
      "episode: 2562   score: 8.0   memory length: 700829   epsilon: 0.009998020008555413    steps: 473    lr: 4.0960000000000023e-07     evaluation reward: 9.34\n",
      "episode: 2563   score: 7.0   memory length: 701218   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 9.27\n",
      "episode: 2564   score: 7.0   memory length: 701603   epsilon: 0.009998020008555413    steps: 385    lr: 4.0960000000000023e-07     evaluation reward: 9.21\n",
      "episode: 2565   score: 8.0   memory length: 702070   epsilon: 0.009998020008555413    steps: 467    lr: 4.0960000000000023e-07     evaluation reward: 9.2\n",
      "episode: 2566   score: 8.0   memory length: 702497   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2567   score: 7.0   memory length: 702865   epsilon: 0.009998020008555413    steps: 368    lr: 4.0960000000000023e-07     evaluation reward: 9.18\n",
      "episode: 2568   score: 8.0   memory length: 703279   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2569   score: 10.0   memory length: 703791   epsilon: 0.009998020008555413    steps: 512    lr: 4.0960000000000023e-07     evaluation reward: 9.18\n",
      "episode: 2570   score: 9.0   memory length: 704257   epsilon: 0.009998020008555413    steps: 466    lr: 4.0960000000000023e-07     evaluation reward: 9.17\n",
      "episode: 2571   score: 12.0   memory length: 704766   epsilon: 0.009998020008555413    steps: 509    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2572   score: 6.0   memory length: 705138   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 9.15\n",
      "episode: 2573   score: 11.0   memory length: 705662   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2574   score: 7.0   memory length: 706027   epsilon: 0.009998020008555413    steps: 365    lr: 4.0960000000000023e-07     evaluation reward: 9.15\n",
      "episode: 2575   score: 10.0   memory length: 706586   epsilon: 0.009998020008555413    steps: 559    lr: 4.0960000000000023e-07     evaluation reward: 9.12\n",
      "episode: 2576   score: 9.0   memory length: 707067   epsilon: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     evaluation reward: 9.1\n",
      "episode: 2577   score: 6.0   memory length: 707422   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2578   score: 10.0   memory length: 707793   epsilon: 0.009998020008555413    steps: 371    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2579   score: 7.0   memory length: 708179   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2580   score: 6.0   memory length: 708539   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2581   score: 5.0   memory length: 708843   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2582   score: 6.0   memory length: 709182   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2583   score: 8.0   memory length: 709583   epsilon: 0.009998020008555413    steps: 401    lr: 4.0960000000000023e-07     evaluation reward: 8.88\n",
      "episode: 2584   score: 7.0   memory length: 709971   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2585   score: 11.0   memory length: 710529   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2586   score: 10.0   memory length: 711034   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2587   score: 8.0   memory length: 711450   epsilon: 0.009998020008555413    steps: 416    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2588   score: 9.0   memory length: 711891   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2589   score: 9.0   memory length: 712371   epsilon: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2590   score: 9.0   memory length: 712874   epsilon: 0.009998020008555413    steps: 503    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2591   score: 10.0   memory length: 713415   epsilon: 0.009998020008555413    steps: 541    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2592   score: 12.0   memory length: 714001   epsilon: 0.009998020008555413    steps: 586    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2593   score: 16.0   memory length: 714608   epsilon: 0.009998020008555413    steps: 607    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2594   score: 14.0   memory length: 715135   epsilon: 0.009998020008555413    steps: 527    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2595   score: 6.0   memory length: 715474   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2596   score: 8.0   memory length: 715863   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2597   score: 10.0   memory length: 716366   epsilon: 0.009998020008555413    steps: 503    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2598   score: 8.0   memory length: 716755   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2599   score: 12.0   memory length: 717230   epsilon: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2600   score: 8.0   memory length: 717665   epsilon: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2601   score: 13.0   memory length: 718225   epsilon: 0.009998020008555413    steps: 560    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2602   score: 7.0   memory length: 718612   epsilon: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2603   score: 12.0   memory length: 719179   epsilon: 0.009998020008555413    steps: 567    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2604   score: 9.0   memory length: 719661   epsilon: 0.009998020008555413    steps: 482    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2605   score: 10.0   memory length: 720141   epsilon: 0.009998020008555413    steps: 480    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2606   score: 7.0   memory length: 720507   epsilon: 0.009998020008555413    steps: 366    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2607   score: 11.0   memory length: 721068   epsilon: 0.009998020008555413    steps: 561    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2608   score: 10.0   memory length: 721624   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2609   score: 5.0   memory length: 721898   epsilon: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2610   score: 9.0   memory length: 722354   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2611   score: 7.0   memory length: 722761   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2612   score: 7.0   memory length: 723096   epsilon: 0.009998020008555413    steps: 335    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2613   score: 10.0   memory length: 723453   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2614   score: 5.0   memory length: 723745   epsilon: 0.009998020008555413    steps: 292    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2615   score: 5.0   memory length: 724037   epsilon: 0.009998020008555413    steps: 292    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2616   score: 6.0   memory length: 724377   epsilon: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2617   score: 10.0   memory length: 724841   epsilon: 0.009998020008555413    steps: 464    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2618   score: 8.0   memory length: 725285   epsilon: 0.009998020008555413    steps: 444    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2619   score: 7.0   memory length: 725639   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2620   score: 11.0   memory length: 726195   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2621   score: 8.0   memory length: 726596   epsilon: 0.009998020008555413    steps: 401    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2622   score: 10.0   memory length: 726967   epsilon: 0.009998020008555413    steps: 371    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2623   score: 9.0   memory length: 727419   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2624   score: 8.0   memory length: 727813   epsilon: 0.009998020008555413    steps: 394    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2625   score: 10.0   memory length: 728290   epsilon: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2626   score: 11.0   memory length: 728820   epsilon: 0.009998020008555413    steps: 530    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2627   score: 9.0   memory length: 729290   epsilon: 0.009998020008555413    steps: 470    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2628   score: 6.0   memory length: 729651   epsilon: 0.009998020008555413    steps: 361    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2629   score: 7.0   memory length: 730010   epsilon: 0.009998020008555413    steps: 359    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2630   score: 8.0   memory length: 730409   epsilon: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2631   score: 12.0   memory length: 730891   epsilon: 0.009998020008555413    steps: 482    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2632   score: 5.0   memory length: 731201   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 8.85\n",
      "episode: 2633   score: 5.0   memory length: 731511   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2634   score: 9.0   memory length: 732020   epsilon: 0.009998020008555413    steps: 509    lr: 4.0960000000000023e-07     evaluation reward: 8.84\n",
      "episode: 2635   score: 5.0   memory length: 732312   epsilon: 0.009998020008555413    steps: 292    lr: 4.0960000000000023e-07     evaluation reward: 8.79\n",
      "episode: 2636   score: 5.0   memory length: 732635   epsilon: 0.009998020008555413    steps: 323    lr: 4.0960000000000023e-07     evaluation reward: 8.75\n",
      "episode: 2637   score: 16.0   memory length: 733202   epsilon: 0.009998020008555413    steps: 567    lr: 4.0960000000000023e-07     evaluation reward: 8.79\n",
      "episode: 2638   score: 5.0   memory length: 733491   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 8.79\n",
      "episode: 2639   score: 12.0   memory length: 733941   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 8.85\n",
      "episode: 2640   score: 8.0   memory length: 734396   epsilon: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     evaluation reward: 8.84\n",
      "episode: 2641   score: 13.0   memory length: 735036   epsilon: 0.009998020008555413    steps: 640    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2642   score: 9.0   memory length: 735490   epsilon: 0.009998020008555413    steps: 454    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2643   score: 6.0   memory length: 735811   epsilon: 0.009998020008555413    steps: 321    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2644   score: 24.0   memory length: 736595   epsilon: 0.009998020008555413    steps: 784    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2645   score: 9.0   memory length: 737036   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2646   score: 7.0   memory length: 737425   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2647   score: 10.0   memory length: 737797   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2648   score: 13.0   memory length: 738331   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2649   score: 8.0   memory length: 738769   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2650   score: 7.0   memory length: 739129   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 8.87\n",
      "episode: 2651   score: 10.0   memory length: 739639   epsilon: 0.009998020008555413    steps: 510    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2652   score: 16.0   memory length: 740241   epsilon: 0.009998020008555413    steps: 602    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2653   score: 8.0   memory length: 740640   epsilon: 0.009998020008555413    steps: 399    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2654   score: 12.0   memory length: 741104   epsilon: 0.009998020008555413    steps: 464    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2655   score: 12.0   memory length: 741617   epsilon: 0.009998020008555413    steps: 513    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2656   score: 8.0   memory length: 742053   epsilon: 0.009998020008555413    steps: 436    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2657   score: 10.0   memory length: 742539   epsilon: 0.009998020008555413    steps: 486    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2658   score: 5.0   memory length: 742812   epsilon: 0.009998020008555413    steps: 273    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2659   score: 5.0   memory length: 743085   epsilon: 0.009998020008555413    steps: 273    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2660   score: 18.0   memory length: 743839   epsilon: 0.009998020008555413    steps: 754    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2661   score: 17.0   memory length: 744300   epsilon: 0.009998020008555413    steps: 461    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2662   score: 8.0   memory length: 744700   epsilon: 0.009998020008555413    steps: 400    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2663   score: 9.0   memory length: 745167   epsilon: 0.009998020008555413    steps: 467    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2664   score: 13.0   memory length: 745653   epsilon: 0.009998020008555413    steps: 486    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2665   score: 11.0   memory length: 746183   epsilon: 0.009998020008555413    steps: 530    lr: 4.0960000000000023e-07     evaluation reward: 9.17\n",
      "episode: 2666   score: 8.0   memory length: 746629   epsilon: 0.009998020008555413    steps: 446    lr: 4.0960000000000023e-07     evaluation reward: 9.17\n",
      "episode: 2667   score: 9.0   memory length: 747079   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2668   score: 12.0   memory length: 747659   epsilon: 0.009998020008555413    steps: 580    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2669   score: 13.0   memory length: 748311   epsilon: 0.009998020008555413    steps: 652    lr: 4.0960000000000023e-07     evaluation reward: 9.26\n",
      "episode: 2670   score: 9.0   memory length: 748792   epsilon: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     evaluation reward: 9.26\n",
      "episode: 2671   score: 10.0   memory length: 749243   epsilon: 0.009998020008555413    steps: 451    lr: 4.0960000000000023e-07     evaluation reward: 9.24\n",
      "episode: 2672   score: 5.0   memory length: 749516   epsilon: 0.009998020008555413    steps: 273    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2673   score: 11.0   memory length: 750070   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2674   score: 5.0   memory length: 750359   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 9.21\n",
      "episode: 2675   score: 9.0   memory length: 750811   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 9.2\n",
      "episode: 2676   score: 7.0   memory length: 751199   epsilon: 0.009998020008555413    steps: 388    lr: 4.0960000000000023e-07     evaluation reward: 9.18\n",
      "episode: 2677   score: 6.0   memory length: 751541   epsilon: 0.009998020008555413    steps: 342    lr: 4.0960000000000023e-07     evaluation reward: 9.18\n",
      "episode: 2678   score: 6.0   memory length: 751886   epsilon: 0.009998020008555413    steps: 345    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2679   score: 7.0   memory length: 752248   epsilon: 0.009998020008555413    steps: 362    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2680   score: 5.0   memory length: 752558   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 9.13\n",
      "episode: 2681   score: 13.0   memory length: 753147   epsilon: 0.009998020008555413    steps: 589    lr: 4.0960000000000023e-07     evaluation reward: 9.21\n",
      "episode: 2682   score: 7.0   memory length: 753499   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 9.22\n",
      "episode: 2683   score: 8.0   memory length: 753914   epsilon: 0.009998020008555413    steps: 415    lr: 4.0960000000000023e-07     evaluation reward: 9.22\n",
      "episode: 2684   score: 9.0   memory length: 754356   epsilon: 0.009998020008555413    steps: 442    lr: 4.0960000000000023e-07     evaluation reward: 9.24\n",
      "episode: 2685   score: 6.0   memory length: 754695   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2686   score: 5.0   memory length: 755005   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2687   score: 8.0   memory length: 755477   epsilon: 0.009998020008555413    steps: 472    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2688   score: 9.0   memory length: 755961   epsilon: 0.009998020008555413    steps: 484    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2689   score: 6.0   memory length: 756300   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2690   score: 13.0   memory length: 756907   epsilon: 0.009998020008555413    steps: 607    lr: 4.0960000000000023e-07     evaluation reward: 9.15\n",
      "episode: 2691   score: 7.0   memory length: 757289   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 9.12\n",
      "episode: 2692   score: 7.0   memory length: 757712   epsilon: 0.009998020008555413    steps: 423    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2693   score: 10.0   memory length: 758260   epsilon: 0.009998020008555413    steps: 548    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2694   score: 8.0   memory length: 758662   epsilon: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2695   score: 6.0   memory length: 759001   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2696   score: 8.0   memory length: 759409   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2697   score: 11.0   memory length: 759840   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2698   score: 11.0   memory length: 760396   epsilon: 0.009998020008555413    steps: 556    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2699   score: 10.0   memory length: 760843   epsilon: 0.009998020008555413    steps: 447    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2700   score: 12.0   memory length: 761433   epsilon: 0.009998020008555413    steps: 590    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2701   score: 9.0   memory length: 761759   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2702   score: 5.0   memory length: 762032   epsilon: 0.009998020008555413    steps: 273    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2703   score: 9.0   memory length: 762479   epsilon: 0.009998020008555413    steps: 447    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2704   score: 15.0   memory length: 762904   epsilon: 0.009998020008555413    steps: 425    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2705   score: 9.0   memory length: 763250   epsilon: 0.009998020008555413    steps: 346    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2706   score: 10.0   memory length: 763762   epsilon: 0.009998020008555413    steps: 512    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2707   score: 14.0   memory length: 764247   epsilon: 0.009998020008555413    steps: 485    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2708   score: 6.0   memory length: 764586   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2709   score: 7.0   memory length: 764939   epsilon: 0.009998020008555413    steps: 353    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2710   score: 10.0   memory length: 765424   epsilon: 0.009998020008555413    steps: 485    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2711   score: 8.0   memory length: 765828   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2712   score: 6.0   memory length: 766167   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2713   score: 9.0   memory length: 766682   epsilon: 0.009998020008555413    steps: 515    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2714   score: 6.0   memory length: 767042   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2715   score: 10.0   memory length: 767461   epsilon: 0.009998020008555413    steps: 419    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2716   score: 10.0   memory length: 767959   epsilon: 0.009998020008555413    steps: 498    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2717   score: 14.0   memory length: 768479   epsilon: 0.009998020008555413    steps: 520    lr: 4.0960000000000023e-07     evaluation reward: 9.15\n",
      "episode: 2718   score: 8.0   memory length: 768975   epsilon: 0.009998020008555413    steps: 496    lr: 4.0960000000000023e-07     evaluation reward: 9.15\n",
      "episode: 2719   score: 8.0   memory length: 769393   epsilon: 0.009998020008555413    steps: 418    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2720   score: 11.0   memory length: 769899   epsilon: 0.009998020008555413    steps: 506    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2721   score: 8.0   memory length: 770319   epsilon: 0.009998020008555413    steps: 420    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2722   score: 10.0   memory length: 770690   epsilon: 0.009998020008555413    steps: 371    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2723   score: 6.0   memory length: 771029   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.13\n",
      "episode: 2724   score: 7.0   memory length: 771379   epsilon: 0.009998020008555413    steps: 350    lr: 4.0960000000000023e-07     evaluation reward: 9.12\n",
      "episode: 2725   score: 7.0   memory length: 771800   epsilon: 0.009998020008555413    steps: 421    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2726   score: 10.0   memory length: 772307   epsilon: 0.009998020008555413    steps: 507    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2727   score: 10.0   memory length: 772700   epsilon: 0.009998020008555413    steps: 393    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2728   score: 8.0   memory length: 773150   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2729   score: 15.0   memory length: 773730   epsilon: 0.009998020008555413    steps: 580    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2730   score: 10.0   memory length: 774264   epsilon: 0.009998020008555413    steps: 534    lr: 4.0960000000000023e-07     evaluation reward: 9.21\n",
      "episode: 2731   score: 5.0   memory length: 774553   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2732   score: 10.0   memory length: 774996   epsilon: 0.009998020008555413    steps: 443    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2733   score: 10.0   memory length: 775535   epsilon: 0.009998020008555413    steps: 539    lr: 4.0960000000000023e-07     evaluation reward: 9.24\n",
      "episode: 2734   score: 7.0   memory length: 775904   epsilon: 0.009998020008555413    steps: 369    lr: 4.0960000000000023e-07     evaluation reward: 9.22\n",
      "episode: 2735   score: 7.0   memory length: 776307   epsilon: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     evaluation reward: 9.24\n",
      "episode: 2736   score: 6.0   memory length: 776648   epsilon: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     evaluation reward: 9.25\n",
      "episode: 2737   score: 7.0   memory length: 777021   epsilon: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2738   score: 5.0   memory length: 777331   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2739   score: 17.0   memory length: 777857   epsilon: 0.009998020008555413    steps: 526    lr: 4.0960000000000023e-07     evaluation reward: 9.21\n",
      "episode: 2740   score: 13.0   memory length: 778484   epsilon: 0.009998020008555413    steps: 627    lr: 4.0960000000000023e-07     evaluation reward: 9.26\n",
      "episode: 2741   score: 10.0   memory length: 778953   epsilon: 0.009998020008555413    steps: 469    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2742   score: 14.0   memory length: 779630   epsilon: 0.009998020008555413    steps: 677    lr: 4.0960000000000023e-07     evaluation reward: 9.28\n",
      "episode: 2743   score: 9.0   memory length: 780071   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 9.31\n",
      "episode: 2744   score: 7.0   memory length: 780473   epsilon: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2745   score: 6.0   memory length: 780816   epsilon: 0.009998020008555413    steps: 343    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2746   score: 6.0   memory length: 781155   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.1\n",
      "episode: 2747   score: 7.0   memory length: 781575   epsilon: 0.009998020008555413    steps: 420    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2748   score: 10.0   memory length: 781947   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2749   score: 13.0   memory length: 782504   epsilon: 0.009998020008555413    steps: 557    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2750   score: 4.0   memory length: 782765   epsilon: 0.009998020008555413    steps: 261    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2751   score: 13.0   memory length: 783189   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2752   score: 8.0   memory length: 783593   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2753   score: 4.0   memory length: 783868   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2754   score: 5.0   memory length: 784194   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2755   score: 11.0   memory length: 784766   epsilon: 0.009998020008555413    steps: 572    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2756   score: 10.0   memory length: 785272   epsilon: 0.009998020008555413    steps: 506    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2757   score: 6.0   memory length: 785628   epsilon: 0.009998020008555413    steps: 356    lr: 4.0960000000000023e-07     evaluation reward: 8.87\n",
      "episode: 2758   score: 10.0   memory length: 786128   epsilon: 0.009998020008555413    steps: 500    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2759   score: 13.0   memory length: 786599   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2760   score: 7.0   memory length: 786986   epsilon: 0.009998020008555413    steps: 387    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2761   score: 8.0   memory length: 787400   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2762   score: 12.0   memory length: 787902   epsilon: 0.009998020008555413    steps: 502    lr: 4.0960000000000023e-07     evaluation reward: 8.84\n",
      "episode: 2763   score: 8.0   memory length: 788346   epsilon: 0.009998020008555413    steps: 444    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2764   score: 11.0   memory length: 788850   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 8.81\n",
      "episode: 2765   score: 20.0   memory length: 789517   epsilon: 0.009998020008555413    steps: 667    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2766   score: 5.0   memory length: 789790   epsilon: 0.009998020008555413    steps: 273    lr: 4.0960000000000023e-07     evaluation reward: 8.87\n",
      "episode: 2767   score: 6.0   memory length: 790126   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 8.84\n",
      "episode: 2768   score: 9.0   memory length: 790607   epsilon: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     evaluation reward: 8.81\n",
      "episode: 2769   score: 9.0   memory length: 791031   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2770   score: 8.0   memory length: 791445   epsilon: 0.009998020008555413    steps: 414    lr: 4.0960000000000023e-07     evaluation reward: 8.76\n",
      "episode: 2771   score: 8.0   memory length: 791855   epsilon: 0.009998020008555413    steps: 410    lr: 4.0960000000000023e-07     evaluation reward: 8.74\n",
      "episode: 2772   score: 6.0   memory length: 792194   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 8.75\n",
      "episode: 2773   score: 10.0   memory length: 792718   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 8.74\n",
      "episode: 2774   score: 12.0   memory length: 793261   epsilon: 0.009998020008555413    steps: 543    lr: 4.0960000000000023e-07     evaluation reward: 8.81\n",
      "episode: 2775   score: 5.0   memory length: 793550   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2776   score: 10.0   memory length: 794009   epsilon: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2777   score: 17.0   memory length: 794643   epsilon: 0.009998020008555413    steps: 634    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2778   score: 10.0   memory length: 795201   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2779   score: 6.0   memory length: 795575   epsilon: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2780   score: 8.0   memory length: 795958   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2781   score: 7.0   memory length: 796318   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2782   score: 5.0   memory length: 796607   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2783   score: 9.0   memory length: 797013   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2784   score: 11.0   memory length: 797494   epsilon: 0.009998020008555413    steps: 481    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2785   score: 12.0   memory length: 798094   epsilon: 0.009998020008555413    steps: 600    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2786   score: 6.0   memory length: 798457   epsilon: 0.009998020008555413    steps: 363    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2787   score: 10.0   memory length: 799025   epsilon: 0.009998020008555413    steps: 568    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2788   score: 16.0   memory length: 799637   epsilon: 0.009998020008555413    steps: 612    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2789   score: 9.0   memory length: 800123   epsilon: 0.009998020008555413    steps: 486    lr: 1.638400000000001e-07     evaluation reward: 9.11\n",
      "episode: 2790   score: 7.0   memory length: 800496   epsilon: 0.009998020008555413    steps: 373    lr: 1.638400000000001e-07     evaluation reward: 9.05\n",
      "episode: 2791   score: 6.0   memory length: 800838   epsilon: 0.009998020008555413    steps: 342    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 2792   score: 6.0   memory length: 801198   epsilon: 0.009998020008555413    steps: 360    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2793   score: 12.0   memory length: 801793   epsilon: 0.009998020008555413    steps: 595    lr: 1.638400000000001e-07     evaluation reward: 9.05\n",
      "episode: 2794   score: 5.0   memory length: 802103   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2795   score: 12.0   memory length: 802597   epsilon: 0.009998020008555413    steps: 494    lr: 1.638400000000001e-07     evaluation reward: 9.08\n",
      "episode: 2796   score: 10.0   memory length: 803166   epsilon: 0.009998020008555413    steps: 569    lr: 1.638400000000001e-07     evaluation reward: 9.1\n",
      "episode: 2797   score: 5.0   memory length: 803476   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 2798   score: 11.0   memory length: 804025   epsilon: 0.009998020008555413    steps: 549    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 2799   score: 9.0   memory length: 804531   epsilon: 0.009998020008555413    steps: 506    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2800   score: 7.0   memory length: 804901   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 8.98\n",
      "episode: 2801   score: 9.0   memory length: 805307   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 8.98\n",
      "episode: 2802   score: 8.0   memory length: 805709   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2803   score: 8.0   memory length: 806111   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.0\n",
      "episode: 2804   score: 9.0   memory length: 806636   epsilon: 0.009998020008555413    steps: 525    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2805   score: 11.0   memory length: 807166   epsilon: 0.009998020008555413    steps: 530    lr: 1.638400000000001e-07     evaluation reward: 8.96\n",
      "episode: 2806   score: 11.0   memory length: 807659   epsilon: 0.009998020008555413    steps: 493    lr: 1.638400000000001e-07     evaluation reward: 8.97\n",
      "episode: 2807   score: 4.0   memory length: 807936   epsilon: 0.009998020008555413    steps: 277    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2808   score: 11.0   memory length: 808390   epsilon: 0.009998020008555413    steps: 454    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2809   score: 6.0   memory length: 808747   epsilon: 0.009998020008555413    steps: 357    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2810   score: 10.0   memory length: 809215   epsilon: 0.009998020008555413    steps: 468    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2811   score: 10.0   memory length: 809707   epsilon: 0.009998020008555413    steps: 492    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2812   score: 5.0   memory length: 810017   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2813   score: 5.0   memory length: 810327   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2814   score: 11.0   memory length: 810833   epsilon: 0.009998020008555413    steps: 506    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2815   score: 9.0   memory length: 811306   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2816   score: 10.0   memory length: 811783   epsilon: 0.009998020008555413    steps: 477    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2817   score: 8.0   memory length: 812200   epsilon: 0.009998020008555413    steps: 417    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2818   score: 8.0   memory length: 812608   epsilon: 0.009998020008555413    steps: 408    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2819   score: 11.0   memory length: 813105   epsilon: 0.009998020008555413    steps: 497    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 2820   score: 9.0   memory length: 813588   epsilon: 0.009998020008555413    steps: 483    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2821   score: 9.0   memory length: 814046   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2822   score: 10.0   memory length: 814595   epsilon: 0.009998020008555413    steps: 549    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2823   score: 13.0   memory length: 815085   epsilon: 0.009998020008555413    steps: 490    lr: 1.638400000000001e-07     evaluation reward: 8.95\n",
      "episode: 2824   score: 8.0   memory length: 815485   epsilon: 0.009998020008555413    steps: 400    lr: 1.638400000000001e-07     evaluation reward: 8.96\n",
      "episode: 2825   score: 7.0   memory length: 815854   epsilon: 0.009998020008555413    steps: 369    lr: 1.638400000000001e-07     evaluation reward: 8.96\n",
      "episode: 2826   score: 12.0   memory length: 816378   epsilon: 0.009998020008555413    steps: 524    lr: 1.638400000000001e-07     evaluation reward: 8.98\n",
      "episode: 2827   score: 4.0   memory length: 816620   epsilon: 0.009998020008555413    steps: 242    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2828   score: 7.0   memory length: 816990   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2829   score: 11.0   memory length: 817429   epsilon: 0.009998020008555413    steps: 439    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2830   score: 9.0   memory length: 817915   epsilon: 0.009998020008555413    steps: 486    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2831   score: 12.0   memory length: 818477   epsilon: 0.009998020008555413    steps: 562    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2832   score: 7.0   memory length: 818827   epsilon: 0.009998020008555413    steps: 350    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2833   score: 10.0   memory length: 819291   epsilon: 0.009998020008555413    steps: 464    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2834   score: 8.0   memory length: 819709   epsilon: 0.009998020008555413    steps: 418    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2835   score: 8.0   memory length: 820149   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2836   score: 8.0   memory length: 820566   epsilon: 0.009998020008555413    steps: 417    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2837   score: 15.0   memory length: 821084   epsilon: 0.009998020008555413    steps: 518    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2838   score: 10.0   memory length: 821516   epsilon: 0.009998020008555413    steps: 432    lr: 1.638400000000001e-07     evaluation reward: 9.07\n",
      "episode: 2839   score: 9.0   memory length: 821966   epsilon: 0.009998020008555413    steps: 450    lr: 1.638400000000001e-07     evaluation reward: 8.99\n",
      "episode: 2840   score: 4.0   memory length: 822243   epsilon: 0.009998020008555413    steps: 277    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2841   score: 6.0   memory length: 822616   epsilon: 0.009998020008555413    steps: 373    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2842   score: 9.0   memory length: 823121   epsilon: 0.009998020008555413    steps: 505    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2843   score: 8.0   memory length: 823589   epsilon: 0.009998020008555413    steps: 468    lr: 1.638400000000001e-07     evaluation reward: 8.8\n",
      "episode: 2844   score: 7.0   memory length: 823977   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 8.8\n",
      "episode: 2845   score: 7.0   memory length: 824347   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2846   score: 7.0   memory length: 824717   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 8.82\n",
      "episode: 2847   score: 8.0   memory length: 825100   epsilon: 0.009998020008555413    steps: 383    lr: 1.638400000000001e-07     evaluation reward: 8.83\n",
      "episode: 2848   score: 5.0   memory length: 825409   epsilon: 0.009998020008555413    steps: 309    lr: 1.638400000000001e-07     evaluation reward: 8.78\n",
      "episode: 2849   score: 10.0   memory length: 825912   epsilon: 0.009998020008555413    steps: 503    lr: 1.638400000000001e-07     evaluation reward: 8.75\n",
      "episode: 2850   score: 5.0   memory length: 826222   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 8.76\n",
      "episode: 2851   score: 15.0   memory length: 826791   epsilon: 0.009998020008555413    steps: 569    lr: 1.638400000000001e-07     evaluation reward: 8.78\n",
      "episode: 2852   score: 9.0   memory length: 827260   epsilon: 0.009998020008555413    steps: 469    lr: 1.638400000000001e-07     evaluation reward: 8.79\n",
      "episode: 2853   score: 9.0   memory length: 827662   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 8.84\n",
      "episode: 2854   score: 9.0   memory length: 828135   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2855   score: 9.0   memory length: 828563   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2856   score: 12.0   memory length: 829087   epsilon: 0.009998020008555413    steps: 524    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2857   score: 12.0   memory length: 829688   epsilon: 0.009998020008555413    steps: 601    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2858   score: 9.0   memory length: 830094   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2859   score: 10.0   memory length: 830575   epsilon: 0.009998020008555413    steps: 481    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2860   score: 7.0   memory length: 830981   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2861   score: 13.0   memory length: 831437   epsilon: 0.009998020008555413    steps: 456    lr: 1.638400000000001e-07     evaluation reward: 8.95\n",
      "episode: 2862   score: 10.0   memory length: 831835   epsilon: 0.009998020008555413    steps: 398    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2863   score: 9.0   memory length: 832241   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2864   score: 6.0   memory length: 832570   epsilon: 0.009998020008555413    steps: 329    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 2865   score: 8.0   memory length: 833008   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 8.77\n",
      "episode: 2866   score: 10.0   memory length: 833499   epsilon: 0.009998020008555413    steps: 491    lr: 1.638400000000001e-07     evaluation reward: 8.82\n",
      "episode: 2867   score: 9.0   memory length: 833924   epsilon: 0.009998020008555413    steps: 425    lr: 1.638400000000001e-07     evaluation reward: 8.85\n",
      "episode: 2868   score: 10.0   memory length: 834418   epsilon: 0.009998020008555413    steps: 494    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2869   score: 7.0   memory length: 834788   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 8.84\n",
      "episode: 2870   score: 11.0   memory length: 835347   epsilon: 0.009998020008555413    steps: 559    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2871   score: 8.0   memory length: 835804   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2872   score: 10.0   memory length: 836302   epsilon: 0.009998020008555413    steps: 498    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2873   score: 13.0   memory length: 836822   epsilon: 0.009998020008555413    steps: 520    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2874   score: 6.0   memory length: 837179   epsilon: 0.009998020008555413    steps: 357    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2875   score: 9.0   memory length: 837668   epsilon: 0.009998020008555413    steps: 489    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2876   score: 10.0   memory length: 838135   epsilon: 0.009998020008555413    steps: 467    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2877   score: 6.0   memory length: 838458   epsilon: 0.009998020008555413    steps: 323    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2878   score: 9.0   memory length: 838923   epsilon: 0.009998020008555413    steps: 465    lr: 1.638400000000001e-07     evaluation reward: 8.8\n",
      "episode: 2879   score: 7.0   memory length: 839343   epsilon: 0.009998020008555413    steps: 420    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2880   score: 8.0   memory length: 839768   epsilon: 0.009998020008555413    steps: 425    lr: 1.638400000000001e-07     evaluation reward: 8.81\n",
      "episode: 2881   score: 12.0   memory length: 840374   epsilon: 0.009998020008555413    steps: 606    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2882   score: 9.0   memory length: 840879   epsilon: 0.009998020008555413    steps: 505    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2883   score: 7.0   memory length: 841258   epsilon: 0.009998020008555413    steps: 379    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2884   score: 15.0   memory length: 841873   epsilon: 0.009998020008555413    steps: 615    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2885   score: 14.0   memory length: 842408   epsilon: 0.009998020008555413    steps: 535    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2886   score: 11.0   memory length: 842813   epsilon: 0.009998020008555413    steps: 405    lr: 1.638400000000001e-07     evaluation reward: 8.99\n",
      "episode: 2887   score: 7.0   memory length: 843233   epsilon: 0.009998020008555413    steps: 420    lr: 1.638400000000001e-07     evaluation reward: 8.96\n",
      "episode: 2888   score: 8.0   memory length: 843680   epsilon: 0.009998020008555413    steps: 447    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2889   score: 8.0   memory length: 844094   epsilon: 0.009998020008555413    steps: 414    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2890   score: 5.0   memory length: 844403   epsilon: 0.009998020008555413    steps: 309    lr: 1.638400000000001e-07     evaluation reward: 8.85\n",
      "episode: 2891   score: 8.0   memory length: 844785   epsilon: 0.009998020008555413    steps: 382    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2892   score: 7.0   memory length: 845155   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2893   score: 11.0   memory length: 845680   epsilon: 0.009998020008555413    steps: 525    lr: 1.638400000000001e-07     evaluation reward: 8.87\n",
      "episode: 2894   score: 7.0   memory length: 846045   epsilon: 0.009998020008555413    steps: 365    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 2895   score: 8.0   memory length: 846466   epsilon: 0.009998020008555413    steps: 421    lr: 1.638400000000001e-07     evaluation reward: 8.85\n",
      "episode: 2896   score: 18.0   memory length: 847015   epsilon: 0.009998020008555413    steps: 549    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2897   score: 14.0   memory length: 847560   epsilon: 0.009998020008555413    steps: 545    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2898   score: 9.0   memory length: 848018   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 9.0\n",
      "episode: 2899   score: 11.0   memory length: 848567   epsilon: 0.009998020008555413    steps: 549    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2900   score: 8.0   memory length: 848969   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2901   score: 9.0   memory length: 849427   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2902   score: 7.0   memory length: 849816   epsilon: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2903   score: 7.0   memory length: 850203   epsilon: 0.009998020008555413    steps: 387    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2904   score: 7.0   memory length: 850558   epsilon: 0.009998020008555413    steps: 355    lr: 1.638400000000001e-07     evaluation reward: 8.99\n",
      "episode: 2905   score: 10.0   memory length: 851084   epsilon: 0.009998020008555413    steps: 526    lr: 1.638400000000001e-07     evaluation reward: 8.98\n",
      "episode: 2906   score: 7.0   memory length: 851473   epsilon: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     evaluation reward: 8.94\n",
      "episode: 2907   score: 11.0   memory length: 851875   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2908   score: 9.0   memory length: 852328   epsilon: 0.009998020008555413    steps: 453    lr: 1.638400000000001e-07     evaluation reward: 8.99\n",
      "episode: 2909   score: 13.0   memory length: 852858   epsilon: 0.009998020008555413    steps: 530    lr: 1.638400000000001e-07     evaluation reward: 9.06\n",
      "episode: 2910   score: 7.0   memory length: 853228   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2911   score: 9.0   memory length: 853710   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2912   score: 11.0   memory length: 854227   epsilon: 0.009998020008555413    steps: 517    lr: 1.638400000000001e-07     evaluation reward: 9.08\n",
      "episode: 2913   score: 8.0   memory length: 854629   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.11\n",
      "episode: 2914   score: 7.0   memory length: 855002   epsilon: 0.009998020008555413    steps: 373    lr: 1.638400000000001e-07     evaluation reward: 9.07\n",
      "episode: 2915   score: 9.0   memory length: 855426   epsilon: 0.009998020008555413    steps: 424    lr: 1.638400000000001e-07     evaluation reward: 9.07\n",
      "episode: 2916   score: 5.0   memory length: 855715   epsilon: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2917   score: 9.0   memory length: 856153   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2918   score: 8.0   memory length: 856570   epsilon: 0.009998020008555413    steps: 417    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2919   score: 9.0   memory length: 857007   epsilon: 0.009998020008555413    steps: 437    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2920   score: 13.0   memory length: 857539   epsilon: 0.009998020008555413    steps: 532    lr: 1.638400000000001e-07     evaluation reward: 9.05\n",
      "episode: 2921   score: 8.0   memory length: 857989   epsilon: 0.009998020008555413    steps: 450    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 2922   score: 15.0   memory length: 858588   epsilon: 0.009998020008555413    steps: 599    lr: 1.638400000000001e-07     evaluation reward: 9.09\n",
      "episode: 2923   score: 7.0   memory length: 858937   epsilon: 0.009998020008555413    steps: 349    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2924   score: 4.0   memory length: 859214   epsilon: 0.009998020008555413    steps: 277    lr: 1.638400000000001e-07     evaluation reward: 8.99\n",
      "episode: 2925   score: 7.0   memory length: 859578   epsilon: 0.009998020008555413    steps: 364    lr: 1.638400000000001e-07     evaluation reward: 8.99\n",
      "episode: 2926   score: 10.0   memory length: 860066   epsilon: 0.009998020008555413    steps: 488    lr: 1.638400000000001e-07     evaluation reward: 8.97\n",
      "episode: 2927   score: 14.0   memory length: 860589   epsilon: 0.009998020008555413    steps: 523    lr: 1.638400000000001e-07     evaluation reward: 9.07\n",
      "episode: 2928   score: 8.0   memory length: 860994   epsilon: 0.009998020008555413    steps: 405    lr: 1.638400000000001e-07     evaluation reward: 9.08\n",
      "episode: 2929   score: 7.0   memory length: 861374   epsilon: 0.009998020008555413    steps: 380    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 2930   score: 11.0   memory length: 861925   epsilon: 0.009998020008555413    steps: 551    lr: 1.638400000000001e-07     evaluation reward: 9.06\n",
      "episode: 2931   score: 9.0   memory length: 862376   epsilon: 0.009998020008555413    steps: 451    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2932   score: 19.0   memory length: 862988   epsilon: 0.009998020008555413    steps: 612    lr: 1.638400000000001e-07     evaluation reward: 9.15\n",
      "episode: 2933   score: 10.0   memory length: 863514   epsilon: 0.009998020008555413    steps: 526    lr: 1.638400000000001e-07     evaluation reward: 9.15\n",
      "episode: 2934   score: 9.0   memory length: 864037   epsilon: 0.009998020008555413    steps: 523    lr: 1.638400000000001e-07     evaluation reward: 9.16\n",
      "episode: 2935   score: 8.0   memory length: 864508   epsilon: 0.009998020008555413    steps: 471    lr: 1.638400000000001e-07     evaluation reward: 9.16\n",
      "episode: 2936   score: 9.0   memory length: 864941   epsilon: 0.009998020008555413    steps: 433    lr: 1.638400000000001e-07     evaluation reward: 9.17\n",
      "episode: 2937   score: 9.0   memory length: 865446   epsilon: 0.009998020008555413    steps: 505    lr: 1.638400000000001e-07     evaluation reward: 9.11\n",
      "episode: 2938   score: 9.0   memory length: 865852   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 9.1\n",
      "episode: 2939   score: 7.0   memory length: 866222   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 9.08\n",
      "episode: 2940   score: 13.0   memory length: 866717   epsilon: 0.009998020008555413    steps: 495    lr: 1.638400000000001e-07     evaluation reward: 9.17\n",
      "episode: 2941   score: 6.0   memory length: 867056   epsilon: 0.009998020008555413    steps: 339    lr: 1.638400000000001e-07     evaluation reward: 9.17\n",
      "episode: 2942   score: 11.0   memory length: 867616   epsilon: 0.009998020008555413    steps: 560    lr: 1.638400000000001e-07     evaluation reward: 9.19\n",
      "episode: 2943   score: 7.0   memory length: 867981   epsilon: 0.009998020008555413    steps: 365    lr: 1.638400000000001e-07     evaluation reward: 9.18\n",
      "episode: 2944   score: 12.0   memory length: 868594   epsilon: 0.009998020008555413    steps: 613    lr: 1.638400000000001e-07     evaluation reward: 9.23\n",
      "episode: 2945   score: 12.0   memory length: 869143   epsilon: 0.009998020008555413    steps: 549    lr: 1.638400000000001e-07     evaluation reward: 9.28\n",
      "episode: 2946   score: 19.0   memory length: 869711   epsilon: 0.009998020008555413    steps: 568    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 2947   score: 11.0   memory length: 870302   epsilon: 0.009998020008555413    steps: 591    lr: 1.638400000000001e-07     evaluation reward: 9.43\n",
      "episode: 2948   score: 10.0   memory length: 870799   epsilon: 0.009998020008555413    steps: 497    lr: 1.638400000000001e-07     evaluation reward: 9.48\n",
      "episode: 2949   score: 10.0   memory length: 871254   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 9.48\n",
      "episode: 2950   score: 9.0   memory length: 871759   epsilon: 0.009998020008555413    steps: 505    lr: 1.638400000000001e-07     evaluation reward: 9.52\n",
      "episode: 2951   score: 5.0   memory length: 872069   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 9.42\n",
      "episode: 2952   score: 7.0   memory length: 872439   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 2953   score: 13.0   memory length: 872938   epsilon: 0.009998020008555413    steps: 499    lr: 1.638400000000001e-07     evaluation reward: 9.44\n",
      "episode: 2954   score: 6.0   memory length: 873299   epsilon: 0.009998020008555413    steps: 361    lr: 1.638400000000001e-07     evaluation reward: 9.41\n",
      "episode: 2955   score: 9.0   memory length: 873759   epsilon: 0.009998020008555413    steps: 460    lr: 1.638400000000001e-07     evaluation reward: 9.41\n",
      "episode: 2956   score: 11.0   memory length: 874197   epsilon: 0.009998020008555413    steps: 438    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 2957   score: 6.0   memory length: 874538   epsilon: 0.009998020008555413    steps: 341    lr: 1.638400000000001e-07     evaluation reward: 9.34\n",
      "episode: 2958   score: 8.0   memory length: 875011   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 9.33\n",
      "episode: 2959   score: 11.0   memory length: 875571   epsilon: 0.009998020008555413    steps: 560    lr: 1.638400000000001e-07     evaluation reward: 9.34\n",
      "episode: 2960   score: 11.0   memory length: 876109   epsilon: 0.009998020008555413    steps: 538    lr: 1.638400000000001e-07     evaluation reward: 9.38\n",
      "episode: 2961   score: 10.0   memory length: 876481   epsilon: 0.009998020008555413    steps: 372    lr: 1.638400000000001e-07     evaluation reward: 9.35\n",
      "episode: 2962   score: 9.0   memory length: 876977   epsilon: 0.009998020008555413    steps: 496    lr: 1.638400000000001e-07     evaluation reward: 9.34\n",
      "episode: 2963   score: 7.0   memory length: 877383   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 2964   score: 10.0   memory length: 877883   epsilon: 0.009998020008555413    steps: 500    lr: 1.638400000000001e-07     evaluation reward: 9.36\n",
      "episode: 2965   score: 6.0   memory length: 878203   epsilon: 0.009998020008555413    steps: 320    lr: 1.638400000000001e-07     evaluation reward: 9.34\n",
      "episode: 2966   score: 8.0   memory length: 878673   epsilon: 0.009998020008555413    steps: 470    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 2967   score: 7.0   memory length: 879095   epsilon: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     evaluation reward: 9.3\n",
      "episode: 2968   score: 7.0   memory length: 879460   epsilon: 0.009998020008555413    steps: 365    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 2969   score: 6.0   memory length: 879799   epsilon: 0.009998020008555413    steps: 339    lr: 1.638400000000001e-07     evaluation reward: 9.26\n",
      "episode: 2970   score: 7.0   memory length: 880168   epsilon: 0.009998020008555413    steps: 369    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 2971   score: 6.0   memory length: 880489   epsilon: 0.009998020008555413    steps: 321    lr: 1.638400000000001e-07     evaluation reward: 9.2\n",
      "episode: 2972   score: 6.0   memory length: 880810   epsilon: 0.009998020008555413    steps: 321    lr: 1.638400000000001e-07     evaluation reward: 9.16\n",
      "episode: 2973   score: 19.0   memory length: 881435   epsilon: 0.009998020008555413    steps: 625    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 2974   score: 11.0   memory length: 881916   epsilon: 0.009998020008555413    steps: 481    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 2975   score: 12.0   memory length: 882459   epsilon: 0.009998020008555413    steps: 543    lr: 1.638400000000001e-07     evaluation reward: 9.3\n",
      "episode: 2976   score: 9.0   memory length: 882925   epsilon: 0.009998020008555413    steps: 466    lr: 1.638400000000001e-07     evaluation reward: 9.29\n",
      "episode: 2977   score: 9.0   memory length: 883331   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 2978   score: 8.0   memory length: 883733   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.31\n",
      "episode: 2979   score: 11.0   memory length: 884295   epsilon: 0.009998020008555413    steps: 562    lr: 1.638400000000001e-07     evaluation reward: 9.35\n",
      "episode: 2980   score: 8.0   memory length: 884693   epsilon: 0.009998020008555413    steps: 398    lr: 1.638400000000001e-07     evaluation reward: 9.35\n",
      "episode: 2981   score: 10.0   memory length: 885203   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 9.33\n",
      "episode: 2982   score: 8.0   memory length: 885602   epsilon: 0.009998020008555413    steps: 399    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 2983   score: 8.0   memory length: 886000   epsilon: 0.009998020008555413    steps: 398    lr: 1.638400000000001e-07     evaluation reward: 9.33\n",
      "episode: 2984   score: 7.0   memory length: 886370   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 9.25\n",
      "episode: 2985   score: 9.0   memory length: 886812   epsilon: 0.009998020008555413    steps: 442    lr: 1.638400000000001e-07     evaluation reward: 9.2\n",
      "episode: 2986   score: 8.0   memory length: 887281   epsilon: 0.009998020008555413    steps: 469    lr: 1.638400000000001e-07     evaluation reward: 9.17\n",
      "episode: 2987   score: 7.0   memory length: 887720   epsilon: 0.009998020008555413    steps: 439    lr: 1.638400000000001e-07     evaluation reward: 9.17\n",
      "episode: 2988   score: 11.0   memory length: 888295   epsilon: 0.009998020008555413    steps: 575    lr: 1.638400000000001e-07     evaluation reward: 9.2\n",
      "episode: 2989   score: 9.0   memory length: 888719   epsilon: 0.009998020008555413    steps: 424    lr: 1.638400000000001e-07     evaluation reward: 9.21\n",
      "episode: 2990   score: 16.0   memory length: 889337   epsilon: 0.009998020008555413    steps: 618    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 2991   score: 12.0   memory length: 889905   epsilon: 0.009998020008555413    steps: 568    lr: 1.638400000000001e-07     evaluation reward: 9.36\n",
      "episode: 2992   score: 9.0   memory length: 890365   epsilon: 0.009998020008555413    steps: 460    lr: 1.638400000000001e-07     evaluation reward: 9.38\n",
      "episode: 2993   score: 9.0   memory length: 890793   epsilon: 0.009998020008555413    steps: 428    lr: 1.638400000000001e-07     evaluation reward: 9.36\n",
      "episode: 2994   score: 9.0   memory length: 891318   epsilon: 0.009998020008555413    steps: 525    lr: 1.638400000000001e-07     evaluation reward: 9.38\n",
      "episode: 2995   score: 9.0   memory length: 891782   epsilon: 0.009998020008555413    steps: 464    lr: 1.638400000000001e-07     evaluation reward: 9.39\n",
      "episode: 2996   score: 6.0   memory length: 892121   epsilon: 0.009998020008555413    steps: 339    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 2997   score: 11.0   memory length: 892649   epsilon: 0.009998020008555413    steps: 528    lr: 1.638400000000001e-07     evaluation reward: 9.24\n",
      "episode: 2998   score: 7.0   memory length: 893008   epsilon: 0.009998020008555413    steps: 359    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 2999   score: 7.0   memory length: 893361   epsilon: 0.009998020008555413    steps: 353    lr: 1.638400000000001e-07     evaluation reward: 9.18\n",
      "episode: 3000   score: 6.0   memory length: 893697   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 9.16\n",
      "episode: 3001   score: 8.0   memory length: 894164   epsilon: 0.009998020008555413    steps: 467    lr: 1.638400000000001e-07     evaluation reward: 9.15\n",
      "episode: 3002   score: 12.0   memory length: 894729   epsilon: 0.009998020008555413    steps: 565    lr: 1.638400000000001e-07     evaluation reward: 9.2\n",
      "episode: 3003   score: 12.0   memory length: 895312   epsilon: 0.009998020008555413    steps: 583    lr: 1.638400000000001e-07     evaluation reward: 9.25\n",
      "episode: 3004   score: 8.0   memory length: 895787   epsilon: 0.009998020008555413    steps: 475    lr: 1.638400000000001e-07     evaluation reward: 9.26\n",
      "episode: 3005   score: 14.0   memory length: 896307   epsilon: 0.009998020008555413    steps: 520    lr: 1.638400000000001e-07     evaluation reward: 9.3\n",
      "episode: 3006   score: 7.0   memory length: 896696   epsilon: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     evaluation reward: 9.3\n",
      "episode: 3007   score: 10.0   memory length: 897066   epsilon: 0.009998020008555413    steps: 370    lr: 1.638400000000001e-07     evaluation reward: 9.29\n",
      "episode: 3008   score: 9.0   memory length: 897537   epsilon: 0.009998020008555413    steps: 471    lr: 1.638400000000001e-07     evaluation reward: 9.29\n",
      "episode: 3009   score: 9.0   memory length: 898047   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 9.25\n",
      "episode: 3010   score: 9.0   memory length: 898546   epsilon: 0.009998020008555413    steps: 499    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 3011   score: 9.0   memory length: 898956   epsilon: 0.009998020008555413    steps: 410    lr: 1.638400000000001e-07     evaluation reward: 9.27\n",
      "episode: 3012   score: 10.0   memory length: 899477   epsilon: 0.009998020008555413    steps: 521    lr: 1.638400000000001e-07     evaluation reward: 9.26\n",
      "episode: 3013   score: 10.0   memory length: 900003   epsilon: 0.009998020008555413    steps: 526    lr: 6.553600000000004e-08     evaluation reward: 9.28\n",
      "episode: 3014   score: 6.0   memory length: 900343   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.27\n",
      "episode: 3015   score: 6.0   memory length: 900682   epsilon: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     evaluation reward: 9.24\n",
      "episode: 3016   score: 9.0   memory length: 901110   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 9.28\n",
      "episode: 3017   score: 10.0   memory length: 901615   epsilon: 0.009998020008555413    steps: 505    lr: 6.553600000000004e-08     evaluation reward: 9.29\n",
      "episode: 3018   score: 8.0   memory length: 902062   epsilon: 0.009998020008555413    steps: 447    lr: 6.553600000000004e-08     evaluation reward: 9.29\n",
      "episode: 3019   score: 17.0   memory length: 902649   epsilon: 0.009998020008555413    steps: 587    lr: 6.553600000000004e-08     evaluation reward: 9.37\n",
      "episode: 3020   score: 7.0   memory length: 903040   epsilon: 0.009998020008555413    steps: 391    lr: 6.553600000000004e-08     evaluation reward: 9.31\n",
      "episode: 3021   score: 8.0   memory length: 903442   epsilon: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     evaluation reward: 9.31\n",
      "episode: 3022   score: 17.0   memory length: 903941   epsilon: 0.009998020008555413    steps: 499    lr: 6.553600000000004e-08     evaluation reward: 9.33\n",
      "episode: 3023   score: 8.0   memory length: 904341   epsilon: 0.009998020008555413    steps: 400    lr: 6.553600000000004e-08     evaluation reward: 9.34\n",
      "episode: 3024   score: 14.0   memory length: 904833   epsilon: 0.009998020008555413    steps: 492    lr: 6.553600000000004e-08     evaluation reward: 9.44\n",
      "episode: 3025   score: 10.0   memory length: 905314   epsilon: 0.009998020008555413    steps: 481    lr: 6.553600000000004e-08     evaluation reward: 9.47\n",
      "episode: 3026   score: 9.0   memory length: 905837   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 9.46\n",
      "episode: 3027   score: 11.0   memory length: 906311   epsilon: 0.009998020008555413    steps: 474    lr: 6.553600000000004e-08     evaluation reward: 9.43\n",
      "episode: 3028   score: 15.0   memory length: 906948   epsilon: 0.009998020008555413    steps: 637    lr: 6.553600000000004e-08     evaluation reward: 9.5\n",
      "episode: 3029   score: 7.0   memory length: 907327   epsilon: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     evaluation reward: 9.5\n",
      "episode: 3030   score: 9.0   memory length: 907780   epsilon: 0.009998020008555413    steps: 453    lr: 6.553600000000004e-08     evaluation reward: 9.48\n",
      "episode: 3031   score: 9.0   memory length: 908240   epsilon: 0.009998020008555413    steps: 460    lr: 6.553600000000004e-08     evaluation reward: 9.48\n",
      "episode: 3032   score: 8.0   memory length: 908629   epsilon: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     evaluation reward: 9.37\n",
      "episode: 3033   score: 10.0   memory length: 909125   epsilon: 0.009998020008555413    steps: 496    lr: 6.553600000000004e-08     evaluation reward: 9.37\n",
      "episode: 3034   score: 6.0   memory length: 909446   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.34\n",
      "episode: 3035   score: 6.0   memory length: 909767   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.32\n",
      "episode: 3036   score: 11.0   memory length: 910183   epsilon: 0.009998020008555413    steps: 416    lr: 6.553600000000004e-08     evaluation reward: 9.34\n",
      "episode: 3037   score: 15.0   memory length: 910689   epsilon: 0.009998020008555413    steps: 506    lr: 6.553600000000004e-08     evaluation reward: 9.4\n",
      "episode: 3038   score: 9.0   memory length: 911144   epsilon: 0.009998020008555413    steps: 455    lr: 6.553600000000004e-08     evaluation reward: 9.4\n",
      "episode: 3039   score: 6.0   memory length: 911465   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.39\n",
      "episode: 3040   score: 10.0   memory length: 911946   epsilon: 0.009998020008555413    steps: 481    lr: 6.553600000000004e-08     evaluation reward: 9.36\n",
      "episode: 3041   score: 8.0   memory length: 912346   epsilon: 0.009998020008555413    steps: 400    lr: 6.553600000000004e-08     evaluation reward: 9.38\n",
      "episode: 3042   score: 8.0   memory length: 912766   epsilon: 0.009998020008555413    steps: 420    lr: 6.553600000000004e-08     evaluation reward: 9.35\n",
      "episode: 3043   score: 14.0   memory length: 913268   epsilon: 0.009998020008555413    steps: 502    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3044   score: 7.0   memory length: 913669   epsilon: 0.009998020008555413    steps: 401    lr: 6.553600000000004e-08     evaluation reward: 9.37\n",
      "episode: 3045   score: 8.0   memory length: 914142   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 9.33\n",
      "episode: 3046   score: 9.0   memory length: 914643   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 9.23\n",
      "episode: 3047   score: 9.0   memory length: 915112   epsilon: 0.009998020008555413    steps: 469    lr: 6.553600000000004e-08     evaluation reward: 9.21\n",
      "episode: 3048   score: 10.0   memory length: 915607   epsilon: 0.009998020008555413    steps: 495    lr: 6.553600000000004e-08     evaluation reward: 9.21\n",
      "episode: 3049   score: 12.0   memory length: 916079   epsilon: 0.009998020008555413    steps: 472    lr: 6.553600000000004e-08     evaluation reward: 9.23\n",
      "episode: 3050   score: 9.0   memory length: 916529   epsilon: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     evaluation reward: 9.23\n",
      "episode: 3051   score: 17.0   memory length: 916992   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 9.35\n",
      "episode: 3052   score: 12.0   memory length: 917510   epsilon: 0.009998020008555413    steps: 518    lr: 6.553600000000004e-08     evaluation reward: 9.4\n",
      "episode: 3053   score: 8.0   memory length: 917941   epsilon: 0.009998020008555413    steps: 431    lr: 6.553600000000004e-08     evaluation reward: 9.35\n",
      "episode: 3054   score: 11.0   memory length: 918382   epsilon: 0.009998020008555413    steps: 441    lr: 6.553600000000004e-08     evaluation reward: 9.4\n",
      "episode: 3055   score: 10.0   memory length: 918885   epsilon: 0.009998020008555413    steps: 503    lr: 6.553600000000004e-08     evaluation reward: 9.41\n",
      "episode: 3056   score: 9.0   memory length: 919346   epsilon: 0.009998020008555413    steps: 461    lr: 6.553600000000004e-08     evaluation reward: 9.39\n",
      "episode: 3057   score: 12.0   memory length: 919816   epsilon: 0.009998020008555413    steps: 470    lr: 6.553600000000004e-08     evaluation reward: 9.45\n",
      "episode: 3058   score: 10.0   memory length: 920188   epsilon: 0.009998020008555413    steps: 372    lr: 6.553600000000004e-08     evaluation reward: 9.47\n",
      "episode: 3059   score: 6.0   memory length: 920543   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3060   score: 11.0   memory length: 921133   epsilon: 0.009998020008555413    steps: 590    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3061   score: 12.0   memory length: 921743   epsilon: 0.009998020008555413    steps: 610    lr: 6.553600000000004e-08     evaluation reward: 9.44\n",
      "episode: 3062   score: 13.0   memory length: 922368   epsilon: 0.009998020008555413    steps: 625    lr: 6.553600000000004e-08     evaluation reward: 9.48\n",
      "episode: 3063   score: 10.0   memory length: 922738   epsilon: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     evaluation reward: 9.51\n",
      "episode: 3064   score: 7.0   memory length: 923169   epsilon: 0.009998020008555413    steps: 431    lr: 6.553600000000004e-08     evaluation reward: 9.48\n",
      "episode: 3065   score: 8.0   memory length: 923623   epsilon: 0.009998020008555413    steps: 454    lr: 6.553600000000004e-08     evaluation reward: 9.5\n",
      "episode: 3066   score: 9.0   memory length: 924083   epsilon: 0.009998020008555413    steps: 460    lr: 6.553600000000004e-08     evaluation reward: 9.51\n",
      "episode: 3067   score: 10.0   memory length: 924561   epsilon: 0.009998020008555413    steps: 478    lr: 6.553600000000004e-08     evaluation reward: 9.54\n",
      "episode: 3068   score: 14.0   memory length: 925076   epsilon: 0.009998020008555413    steps: 515    lr: 6.553600000000004e-08     evaluation reward: 9.61\n",
      "episode: 3069   score: 9.0   memory length: 925539   epsilon: 0.009998020008555413    steps: 463    lr: 6.553600000000004e-08     evaluation reward: 9.64\n",
      "episode: 3070   score: 6.0   memory length: 925879   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.63\n",
      "episode: 3071   score: 10.0   memory length: 926371   epsilon: 0.009998020008555413    steps: 492    lr: 6.553600000000004e-08     evaluation reward: 9.67\n",
      "episode: 3072   score: 6.0   memory length: 926711   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.67\n",
      "episode: 3073   score: 7.0   memory length: 927114   epsilon: 0.009998020008555413    steps: 403    lr: 6.553600000000004e-08     evaluation reward: 9.55\n",
      "episode: 3074   score: 16.0   memory length: 927696   epsilon: 0.009998020008555413    steps: 582    lr: 6.553600000000004e-08     evaluation reward: 9.6\n",
      "episode: 3075   score: 9.0   memory length: 928133   epsilon: 0.009998020008555413    steps: 437    lr: 6.553600000000004e-08     evaluation reward: 9.57\n",
      "episode: 3076   score: 17.0   memory length: 928750   epsilon: 0.009998020008555413    steps: 617    lr: 6.553600000000004e-08     evaluation reward: 9.65\n",
      "episode: 3077   score: 9.0   memory length: 929234   epsilon: 0.009998020008555413    steps: 484    lr: 6.553600000000004e-08     evaluation reward: 9.65\n",
      "episode: 3078   score: 6.0   memory length: 929555   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.63\n",
      "episode: 3079   score: 11.0   memory length: 930151   epsilon: 0.009998020008555413    steps: 596    lr: 6.553600000000004e-08     evaluation reward: 9.63\n",
      "episode: 3080   score: 9.0   memory length: 930616   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 9.64\n",
      "episode: 3081   score: 7.0   memory length: 930975   epsilon: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     evaluation reward: 9.61\n",
      "episode: 3082   score: 7.0   memory length: 931397   epsilon: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     evaluation reward: 9.6\n",
      "episode: 3083   score: 6.0   memory length: 931718   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.58\n",
      "episode: 3084   score: 11.0   memory length: 932217   epsilon: 0.009998020008555413    steps: 499    lr: 6.553600000000004e-08     evaluation reward: 9.62\n",
      "episode: 3085   score: 6.0   memory length: 932538   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.59\n",
      "episode: 3086   score: 13.0   memory length: 933154   epsilon: 0.009998020008555413    steps: 616    lr: 6.553600000000004e-08     evaluation reward: 9.64\n",
      "episode: 3087   score: 5.0   memory length: 933443   epsilon: 0.009998020008555413    steps: 289    lr: 6.553600000000004e-08     evaluation reward: 9.62\n",
      "episode: 3088   score: 11.0   memory length: 933884   epsilon: 0.009998020008555413    steps: 441    lr: 6.553600000000004e-08     evaluation reward: 9.62\n",
      "episode: 3089   score: 8.0   memory length: 934299   epsilon: 0.009998020008555413    steps: 415    lr: 6.553600000000004e-08     evaluation reward: 9.61\n",
      "episode: 3090   score: 9.0   memory length: 934727   epsilon: 0.009998020008555413    steps: 428    lr: 6.553600000000004e-08     evaluation reward: 9.54\n",
      "episode: 3091   score: 6.0   memory length: 935068   epsilon: 0.009998020008555413    steps: 341    lr: 6.553600000000004e-08     evaluation reward: 9.48\n",
      "episode: 3092   score: 24.0   memory length: 935577   epsilon: 0.009998020008555413    steps: 509    lr: 6.553600000000004e-08     evaluation reward: 9.63\n",
      "episode: 3093   score: 8.0   memory length: 936011   epsilon: 0.009998020008555413    steps: 434    lr: 6.553600000000004e-08     evaluation reward: 9.62\n",
      "episode: 3094   score: 12.0   memory length: 936587   epsilon: 0.009998020008555413    steps: 576    lr: 6.553600000000004e-08     evaluation reward: 9.65\n",
      "episode: 3095   score: 10.0   memory length: 937116   epsilon: 0.009998020008555413    steps: 529    lr: 6.553600000000004e-08     evaluation reward: 9.66\n",
      "episode: 3096   score: 11.0   memory length: 937621   epsilon: 0.009998020008555413    steps: 505    lr: 6.553600000000004e-08     evaluation reward: 9.71\n",
      "episode: 3097   score: 11.0   memory length: 938159   epsilon: 0.009998020008555413    steps: 538    lr: 6.553600000000004e-08     evaluation reward: 9.71\n",
      "episode: 3098   score: 7.0   memory length: 938554   epsilon: 0.009998020008555413    steps: 395    lr: 6.553600000000004e-08     evaluation reward: 9.71\n",
      "episode: 3099   score: 7.0   memory length: 938919   epsilon: 0.009998020008555413    steps: 365    lr: 6.553600000000004e-08     evaluation reward: 9.71\n",
      "episode: 3100   score: 9.0   memory length: 939384   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 9.74\n",
      "episode: 3101   score: 6.0   memory length: 939724   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.72\n",
      "episode: 3102   score: 9.0   memory length: 940169   epsilon: 0.009998020008555413    steps: 445    lr: 6.553600000000004e-08     evaluation reward: 9.69\n",
      "episode: 3103   score: 9.0   memory length: 940600   epsilon: 0.009998020008555413    steps: 431    lr: 6.553600000000004e-08     evaluation reward: 9.66\n",
      "episode: 3104   score: 12.0   memory length: 941199   epsilon: 0.009998020008555413    steps: 599    lr: 6.553600000000004e-08     evaluation reward: 9.7\n",
      "episode: 3105   score: 12.0   memory length: 941621   epsilon: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     evaluation reward: 9.68\n",
      "episode: 3106   score: 14.0   memory length: 942137   epsilon: 0.009998020008555413    steps: 516    lr: 6.553600000000004e-08     evaluation reward: 9.75\n",
      "episode: 3107   score: 6.0   memory length: 942458   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.71\n",
      "episode: 3108   score: 6.0   memory length: 942779   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.68\n",
      "episode: 3109   score: 8.0   memory length: 943183   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 9.67\n",
      "episode: 3110   score: 6.0   memory length: 943504   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.64\n",
      "episode: 3111   score: 6.0   memory length: 943825   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.61\n",
      "episode: 3112   score: 6.0   memory length: 944146   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.57\n",
      "episode: 3113   score: 12.0   memory length: 944563   epsilon: 0.009998020008555413    steps: 417    lr: 6.553600000000004e-08     evaluation reward: 9.59\n",
      "episode: 3114   score: 8.0   memory length: 944974   epsilon: 0.009998020008555413    steps: 411    lr: 6.553600000000004e-08     evaluation reward: 9.61\n",
      "episode: 3115   score: 9.0   memory length: 945477   epsilon: 0.009998020008555413    steps: 503    lr: 6.553600000000004e-08     evaluation reward: 9.64\n",
      "episode: 3116   score: 8.0   memory length: 945947   epsilon: 0.009998020008555413    steps: 470    lr: 6.553600000000004e-08     evaluation reward: 9.63\n",
      "episode: 3117   score: 8.0   memory length: 946349   epsilon: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     evaluation reward: 9.61\n",
      "episode: 3118   score: 9.0   memory length: 946773   epsilon: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     evaluation reward: 9.62\n",
      "episode: 3119   score: 7.0   memory length: 947164   epsilon: 0.009998020008555413    steps: 391    lr: 6.553600000000004e-08     evaluation reward: 9.52\n",
      "episode: 3120   score: 7.0   memory length: 947516   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 9.52\n",
      "episode: 3121   score: 6.0   memory length: 947856   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.5\n",
      "episode: 3122   score: 9.0   memory length: 948324   epsilon: 0.009998020008555413    steps: 468    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3123   score: 12.0   memory length: 948904   epsilon: 0.009998020008555413    steps: 580    lr: 6.553600000000004e-08     evaluation reward: 9.46\n",
      "episode: 3124   score: 9.0   memory length: 949401   epsilon: 0.009998020008555413    steps: 497    lr: 6.553600000000004e-08     evaluation reward: 9.41\n",
      "episode: 3125   score: 11.0   memory length: 949946   epsilon: 0.009998020008555413    steps: 545    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3126   score: 9.0   memory length: 950416   epsilon: 0.009998020008555413    steps: 470    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3127   score: 7.0   memory length: 950835   epsilon: 0.009998020008555413    steps: 419    lr: 6.553600000000004e-08     evaluation reward: 9.38\n",
      "episode: 3128   score: 13.0   memory length: 951344   epsilon: 0.009998020008555413    steps: 509    lr: 6.553600000000004e-08     evaluation reward: 9.36\n",
      "episode: 3129   score: 5.0   memory length: 951689   epsilon: 0.009998020008555413    steps: 345    lr: 6.553600000000004e-08     evaluation reward: 9.34\n",
      "episode: 3130   score: 5.0   memory length: 952034   epsilon: 0.009998020008555413    steps: 345    lr: 6.553600000000004e-08     evaluation reward: 9.3\n",
      "episode: 3131   score: 11.0   memory length: 952473   epsilon: 0.009998020008555413    steps: 439    lr: 6.553600000000004e-08     evaluation reward: 9.32\n",
      "episode: 3132   score: 10.0   memory length: 952949   epsilon: 0.009998020008555413    steps: 476    lr: 6.553600000000004e-08     evaluation reward: 9.34\n",
      "episode: 3133   score: 11.0   memory length: 953457   epsilon: 0.009998020008555413    steps: 508    lr: 6.553600000000004e-08     evaluation reward: 9.35\n",
      "episode: 3134   score: 6.0   memory length: 953797   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.35\n",
      "episode: 3135   score: 8.0   memory length: 954203   epsilon: 0.009998020008555413    steps: 406    lr: 6.553600000000004e-08     evaluation reward: 9.37\n",
      "episode: 3136   score: 10.0   memory length: 954716   epsilon: 0.009998020008555413    steps: 513    lr: 6.553600000000004e-08     evaluation reward: 9.36\n",
      "episode: 3137   score: 6.0   memory length: 955037   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.27\n",
      "episode: 3138   score: 9.0   memory length: 955512   epsilon: 0.009998020008555413    steps: 475    lr: 6.553600000000004e-08     evaluation reward: 9.27\n",
      "episode: 3139   score: 8.0   memory length: 955920   epsilon: 0.009998020008555413    steps: 408    lr: 6.553600000000004e-08     evaluation reward: 9.29\n",
      "episode: 3140   score: 8.0   memory length: 956347   epsilon: 0.009998020008555413    steps: 427    lr: 6.553600000000004e-08     evaluation reward: 9.27\n",
      "episode: 3141   score: 8.0   memory length: 956769   epsilon: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     evaluation reward: 9.27\n",
      "episode: 3142   score: 9.0   memory length: 957229   epsilon: 0.009998020008555413    steps: 460    lr: 6.553600000000004e-08     evaluation reward: 9.28\n",
      "episode: 3143   score: 11.0   memory length: 957755   epsilon: 0.009998020008555413    steps: 526    lr: 6.553600000000004e-08     evaluation reward: 9.25\n",
      "episode: 3144   score: 12.0   memory length: 958273   epsilon: 0.009998020008555413    steps: 518    lr: 6.553600000000004e-08     evaluation reward: 9.3\n",
      "episode: 3145   score: 12.0   memory length: 958821   epsilon: 0.009998020008555413    steps: 548    lr: 6.553600000000004e-08     evaluation reward: 9.34\n",
      "episode: 3146   score: 17.0   memory length: 959449   epsilon: 0.009998020008555413    steps: 628    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3147   score: 9.0   memory length: 959898   epsilon: 0.009998020008555413    steps: 449    lr: 6.553600000000004e-08     evaluation reward: 9.42\n",
      "episode: 3148   score: 5.0   memory length: 960190   epsilon: 0.009998020008555413    steps: 292    lr: 6.553600000000004e-08     evaluation reward: 9.37\n",
      "episode: 3149   score: 7.0   memory length: 960543   epsilon: 0.009998020008555413    steps: 353    lr: 6.553600000000004e-08     evaluation reward: 9.32\n",
      "episode: 3150   score: 10.0   memory length: 961088   epsilon: 0.009998020008555413    steps: 545    lr: 6.553600000000004e-08     evaluation reward: 9.33\n",
      "episode: 3151   score: 8.0   memory length: 961506   epsilon: 0.009998020008555413    steps: 418    lr: 6.553600000000004e-08     evaluation reward: 9.24\n",
      "episode: 3152   score: 8.0   memory length: 961933   epsilon: 0.009998020008555413    steps: 427    lr: 6.553600000000004e-08     evaluation reward: 9.2\n",
      "episode: 3153   score: 7.0   memory length: 962295   epsilon: 0.009998020008555413    steps: 362    lr: 6.553600000000004e-08     evaluation reward: 9.19\n",
      "episode: 3154   score: 9.0   memory length: 962762   epsilon: 0.009998020008555413    steps: 467    lr: 6.553600000000004e-08     evaluation reward: 9.17\n",
      "episode: 3155   score: 8.0   memory length: 963170   epsilon: 0.009998020008555413    steps: 408    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3156   score: 15.0   memory length: 963755   epsilon: 0.009998020008555413    steps: 585    lr: 6.553600000000004e-08     evaluation reward: 9.21\n",
      "episode: 3157   score: 6.0   memory length: 964095   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3158   score: 7.0   memory length: 964447   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 9.12\n",
      "episode: 3159   score: 6.0   memory length: 964821   epsilon: 0.009998020008555413    steps: 374    lr: 6.553600000000004e-08     evaluation reward: 9.12\n",
      "episode: 3160   score: 24.0   memory length: 965330   epsilon: 0.009998020008555413    steps: 509    lr: 6.553600000000004e-08     evaluation reward: 9.25\n",
      "episode: 3161   score: 7.0   memory length: 965719   epsilon: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     evaluation reward: 9.2\n",
      "episode: 3162   score: 7.0   memory length: 966071   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 9.14\n",
      "episode: 3163   score: 14.0   memory length: 966606   epsilon: 0.009998020008555413    steps: 535    lr: 6.553600000000004e-08     evaluation reward: 9.18\n",
      "episode: 3164   score: 8.0   memory length: 967017   epsilon: 0.009998020008555413    steps: 411    lr: 6.553600000000004e-08     evaluation reward: 9.19\n",
      "episode: 3165   score: 6.0   memory length: 967356   epsilon: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     evaluation reward: 9.17\n",
      "episode: 3166   score: 6.0   memory length: 967693   epsilon: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     evaluation reward: 9.14\n",
      "episode: 3167   score: 7.0   memory length: 968088   epsilon: 0.009998020008555413    steps: 395    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3168   score: 7.0   memory length: 968483   epsilon: 0.009998020008555413    steps: 395    lr: 6.553600000000004e-08     evaluation reward: 9.04\n",
      "episode: 3169   score: 11.0   memory length: 969017   epsilon: 0.009998020008555413    steps: 534    lr: 6.553600000000004e-08     evaluation reward: 9.06\n",
      "episode: 3170   score: 6.0   memory length: 969338   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.06\n",
      "episode: 3171   score: 12.0   memory length: 969784   epsilon: 0.009998020008555413    steps: 446    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3172   score: 10.0   memory length: 970304   epsilon: 0.009998020008555413    steps: 520    lr: 6.553600000000004e-08     evaluation reward: 9.12\n",
      "episode: 3173   score: 10.0   memory length: 970674   epsilon: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3174   score: 10.0   memory length: 971155   epsilon: 0.009998020008555413    steps: 481    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3175   score: 16.0   memory length: 971746   epsilon: 0.009998020008555413    steps: 591    lr: 6.553600000000004e-08     evaluation reward: 9.16\n",
      "episode: 3176   score: 9.0   memory length: 972247   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3177   score: 11.0   memory length: 972792   epsilon: 0.009998020008555413    steps: 545    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3178   score: 7.0   memory length: 973201   epsilon: 0.009998020008555413    steps: 409    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3179   score: 11.0   memory length: 973746   epsilon: 0.009998020008555413    steps: 545    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3180   score: 8.0   memory length: 974218   epsilon: 0.009998020008555413    steps: 472    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3181   score: 5.0   memory length: 974528   epsilon: 0.009998020008555413    steps: 310    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3182   score: 7.0   memory length: 974897   epsilon: 0.009998020008555413    steps: 369    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3183   score: 9.0   memory length: 975398   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3184   score: 9.0   memory length: 975869   epsilon: 0.009998020008555413    steps: 471    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3185   score: 8.0   memory length: 976323   epsilon: 0.009998020008555413    steps: 454    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3186   score: 6.0   memory length: 976644   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.04\n",
      "episode: 3187   score: 12.0   memory length: 977218   epsilon: 0.009998020008555413    steps: 574    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3188   score: 8.0   memory length: 977691   epsilon: 0.009998020008555413    steps: 473    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3189   score: 8.0   memory length: 978163   epsilon: 0.009998020008555413    steps: 472    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3190   score: 10.0   memory length: 978642   epsilon: 0.009998020008555413    steps: 479    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3191   score: 8.0   memory length: 979096   epsilon: 0.009998020008555413    steps: 454    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3192   score: 8.0   memory length: 979509   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 8.95\n",
      "episode: 3193   score: 9.0   memory length: 979974   epsilon: 0.009998020008555413    steps: 465    lr: 6.553600000000004e-08     evaluation reward: 8.96\n",
      "episode: 3194   score: 13.0   memory length: 980612   epsilon: 0.009998020008555413    steps: 638    lr: 6.553600000000004e-08     evaluation reward: 8.97\n",
      "episode: 3195   score: 8.0   memory length: 981056   epsilon: 0.009998020008555413    steps: 444    lr: 6.553600000000004e-08     evaluation reward: 8.95\n",
      "episode: 3196   score: 6.0   memory length: 981377   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 8.9\n",
      "episode: 3197   score: 7.0   memory length: 981723   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 8.86\n",
      "episode: 3198   score: 7.0   memory length: 982132   epsilon: 0.009998020008555413    steps: 409    lr: 6.553600000000004e-08     evaluation reward: 8.86\n",
      "episode: 3199   score: 6.0   memory length: 982453   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 8.85\n",
      "episode: 3200   score: 8.0   memory length: 982867   epsilon: 0.009998020008555413    steps: 414    lr: 6.553600000000004e-08     evaluation reward: 8.84\n",
      "episode: 3201   score: 10.0   memory length: 983411   epsilon: 0.009998020008555413    steps: 544    lr: 6.553600000000004e-08     evaluation reward: 8.88\n",
      "episode: 3202   score: 7.0   memory length: 983833   epsilon: 0.009998020008555413    steps: 422    lr: 6.553600000000004e-08     evaluation reward: 8.86\n",
      "episode: 3203   score: 9.0   memory length: 984239   epsilon: 0.009998020008555413    steps: 406    lr: 6.553600000000004e-08     evaluation reward: 8.86\n",
      "episode: 3204   score: 7.0   memory length: 984642   epsilon: 0.009998020008555413    steps: 403    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3205   score: 24.0   memory length: 985151   epsilon: 0.009998020008555413    steps: 509    lr: 6.553600000000004e-08     evaluation reward: 8.93\n",
      "episode: 3206   score: 10.0   memory length: 985521   epsilon: 0.009998020008555413    steps: 370    lr: 6.553600000000004e-08     evaluation reward: 8.89\n",
      "episode: 3207   score: 24.0   memory length: 986030   epsilon: 0.009998020008555413    steps: 509    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3208   score: 8.0   memory length: 986409   epsilon: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3209   score: 7.0   memory length: 986770   epsilon: 0.009998020008555413    steps: 361    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3210   score: 6.0   memory length: 987128   epsilon: 0.009998020008555413    steps: 358    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3211   score: 6.0   memory length: 987480   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 9.08\n",
      "episode: 3212   score: 7.0   memory length: 987871   epsilon: 0.009998020008555413    steps: 391    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3213   score: 10.0   memory length: 988400   epsilon: 0.009998020008555413    steps: 529    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3214   score: 8.0   memory length: 988813   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3215   score: 11.0   memory length: 989272   epsilon: 0.009998020008555413    steps: 459    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3216   score: 9.0   memory length: 989696   epsilon: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3217   score: 11.0   memory length: 990232   epsilon: 0.009998020008555413    steps: 536    lr: 6.553600000000004e-08     evaluation reward: 9.13\n",
      "episode: 3218   score: 11.0   memory length: 990789   epsilon: 0.009998020008555413    steps: 557    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3219   score: 6.0   memory length: 991110   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.14\n",
      "episode: 3220   score: 8.0   memory length: 991542   epsilon: 0.009998020008555413    steps: 432    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3221   score: 9.0   memory length: 992029   epsilon: 0.009998020008555413    steps: 487    lr: 6.553600000000004e-08     evaluation reward: 9.18\n",
      "episode: 3222   score: 6.0   memory length: 992350   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3223   score: 8.0   memory length: 992745   epsilon: 0.009998020008555413    steps: 395    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3224   score: 9.0   memory length: 993222   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3225   score: 7.0   memory length: 993646   epsilon: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3226   score: 8.0   memory length: 994060   epsilon: 0.009998020008555413    steps: 414    lr: 6.553600000000004e-08     evaluation reward: 9.06\n",
      "episode: 3227   score: 6.0   memory length: 994381   epsilon: 0.009998020008555413    steps: 321    lr: 6.553600000000004e-08     evaluation reward: 9.05\n",
      "episode: 3228   score: 7.0   memory length: 994733   epsilon: 0.009998020008555413    steps: 352    lr: 6.553600000000004e-08     evaluation reward: 8.99\n",
      "episode: 3229   score: 8.0   memory length: 995166   epsilon: 0.009998020008555413    steps: 433    lr: 6.553600000000004e-08     evaluation reward: 9.02\n",
      "episode: 3230   score: 16.0   memory length: 995809   epsilon: 0.009998020008555413    steps: 643    lr: 6.553600000000004e-08     evaluation reward: 9.13\n",
      "episode: 3231   score: 10.0   memory length: 996313   epsilon: 0.009998020008555413    steps: 504    lr: 6.553600000000004e-08     evaluation reward: 9.12\n",
      "episode: 3232   score: 10.0   memory length: 996817   epsilon: 0.009998020008555413    steps: 504    lr: 6.553600000000004e-08     evaluation reward: 9.12\n",
      "episode: 3233   score: 14.0   memory length: 997371   epsilon: 0.009998020008555413    steps: 554    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3234   score: 9.0   memory length: 997829   epsilon: 0.009998020008555413    steps: 458    lr: 6.553600000000004e-08     evaluation reward: 9.18\n",
      "episode: 3235   score: 12.0   memory length: 998422   epsilon: 0.009998020008555413    steps: 593    lr: 6.553600000000004e-08     evaluation reward: 9.22\n",
      "episode: 3236   score: 10.0   memory length: 998933   epsilon: 0.009998020008555413    steps: 511    lr: 6.553600000000004e-08     evaluation reward: 9.22\n",
      "episode: 3237   score: 12.0   memory length: 999549   epsilon: 0.009998020008555413    steps: 616    lr: 6.553600000000004e-08     evaluation reward: 9.28\n",
      "episode: 3238   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 9.28\n",
      "episode: 3239   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 462    lr: 2.6214400000000017e-08     evaluation reward: 9.29\n",
      "episode: 3240   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 549    lr: 2.6214400000000017e-08     evaluation reward: 9.31\n",
      "episode: 3241   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 483    lr: 2.6214400000000017e-08     evaluation reward: 9.32\n",
      "episode: 3242   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 433    lr: 2.6214400000000017e-08     evaluation reward: 9.32\n",
      "episode: 3243   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 437    lr: 2.6214400000000017e-08     evaluation reward: 9.33\n",
      "episode: 3244   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 370    lr: 2.6214400000000017e-08     evaluation reward: 9.31\n",
      "episode: 3245   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 9.27\n",
      "episode: 3246   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 446    lr: 2.6214400000000017e-08     evaluation reward: 9.18\n",
      "episode: 3247   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 9.19\n",
      "episode: 3248   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 9.24\n",
      "episode: 3249   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 550    lr: 2.6214400000000017e-08     evaluation reward: 9.29\n",
      "episode: 3250   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 643    lr: 2.6214400000000017e-08     evaluation reward: 9.35\n",
      "episode: 3251   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 607    lr: 2.6214400000000017e-08     evaluation reward: 9.42\n",
      "episode: 3252   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 9.43\n",
      "episode: 3253   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 372    lr: 2.6214400000000017e-08     evaluation reward: 9.46\n",
      "episode: 3254   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 620    lr: 2.6214400000000017e-08     evaluation reward: 9.49\n",
      "episode: 3255   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 9.54\n",
      "episode: 3256   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 403    lr: 2.6214400000000017e-08     evaluation reward: 9.46\n",
      "episode: 3257   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 9.55\n",
      "episode: 3258   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 463    lr: 2.6214400000000017e-08     evaluation reward: 9.6\n",
      "episode: 3259   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 370    lr: 2.6214400000000017e-08     evaluation reward: 9.64\n",
      "episode: 3260   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 641    lr: 2.6214400000000017e-08     evaluation reward: 9.54\n",
      "episode: 3261   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 9.56\n",
      "episode: 3262   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 607    lr: 2.6214400000000017e-08     evaluation reward: 9.64\n",
      "episode: 3263   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 9.64\n",
      "episode: 3264   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 482    lr: 2.6214400000000017e-08     evaluation reward: 9.65\n",
      "episode: 3265   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 9.67\n",
      "episode: 3266   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 607    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3267   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 529    lr: 2.6214400000000017e-08     evaluation reward: 9.79\n",
      "episode: 3268   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 578    lr: 2.6214400000000017e-08     evaluation reward: 9.86\n",
      "episode: 3269   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 2.6214400000000017e-08     evaluation reward: 9.81\n",
      "episode: 3270   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 458    lr: 2.6214400000000017e-08     evaluation reward: 9.84\n",
      "episode: 3271   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 2.6214400000000017e-08     evaluation reward: 9.8\n",
      "episode: 3272   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 9.78\n",
      "episode: 3273   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 499    lr: 2.6214400000000017e-08     evaluation reward: 9.8\n",
      "episode: 3274   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 453    lr: 2.6214400000000017e-08     evaluation reward: 9.82\n",
      "episode: 3275   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 675    lr: 2.6214400000000017e-08     evaluation reward: 9.79\n",
      "episode: 3276   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 453    lr: 2.6214400000000017e-08     evaluation reward: 9.78\n",
      "episode: 3277   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3278   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 563    lr: 2.6214400000000017e-08     evaluation reward: 9.81\n",
      "episode: 3279   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 456    lr: 2.6214400000000017e-08     evaluation reward: 9.79\n",
      "episode: 3280   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 335    lr: 2.6214400000000017e-08     evaluation reward: 9.78\n",
      "episode: 3281   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.81\n",
      "episode: 3282   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 618    lr: 2.6214400000000017e-08     evaluation reward: 9.86\n",
      "episode: 3283   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 547    lr: 2.6214400000000017e-08     evaluation reward: 9.88\n",
      "episode: 3284   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 607    lr: 2.6214400000000017e-08     evaluation reward: 9.94\n",
      "episode: 3285   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.93\n",
      "episode: 3286   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 552    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3287   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 433    lr: 2.6214400000000017e-08     evaluation reward: 9.96\n",
      "episode: 3288   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 578    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3289   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 545    lr: 2.6214400000000017e-08     evaluation reward: 10.02\n",
      "episode: 3290   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.01\n",
      "episode: 3291   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 467    lr: 2.6214400000000017e-08     evaluation reward: 10.01\n",
      "episode: 3292   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 2.6214400000000017e-08     evaluation reward: 10.01\n",
      "episode: 3293   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.01\n",
      "episode: 3294   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 403    lr: 2.6214400000000017e-08     evaluation reward: 9.95\n",
      "episode: 3295   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 601    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3296   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.02\n",
      "episode: 3297   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 473    lr: 2.6214400000000017e-08     evaluation reward: 10.08\n",
      "episode: 3298   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 545    lr: 2.6214400000000017e-08     evaluation reward: 10.12\n",
      "episode: 3299   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 10.13\n",
      "episode: 3300   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 2.6214400000000017e-08     evaluation reward: 10.13\n",
      "episode: 3301   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 503    lr: 2.6214400000000017e-08     evaluation reward: 10.12\n",
      "episode: 3302   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 551    lr: 2.6214400000000017e-08     evaluation reward: 10.16\n",
      "episode: 3303   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 593    lr: 2.6214400000000017e-08     evaluation reward: 10.19\n",
      "episode: 3304   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 563    lr: 2.6214400000000017e-08     evaluation reward: 10.23\n",
      "episode: 3305   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.08\n",
      "episode: 3306   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 584    lr: 2.6214400000000017e-08     evaluation reward: 10.12\n",
      "episode: 3307   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 468    lr: 2.6214400000000017e-08     evaluation reward: 9.97\n",
      "episode: 3308   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 487    lr: 2.6214400000000017e-08     evaluation reward: 9.98\n",
      "episode: 3309   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 460    lr: 2.6214400000000017e-08     evaluation reward: 10.01\n",
      "episode: 3310   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 421    lr: 2.6214400000000017e-08     evaluation reward: 10.03\n",
      "episode: 3311   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.05\n",
      "episode: 3312   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.07\n",
      "episode: 3313   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 607    lr: 2.6214400000000017e-08     evaluation reward: 10.12\n",
      "episode: 3314   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 453    lr: 2.6214400000000017e-08     evaluation reward: 10.16\n",
      "episode: 3315   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 567    lr: 2.6214400000000017e-08     evaluation reward: 10.16\n",
      "episode: 3316   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.15\n",
      "episode: 3317   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 439    lr: 2.6214400000000017e-08     evaluation reward: 10.15\n",
      "episode: 3318   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 526    lr: 2.6214400000000017e-08     evaluation reward: 10.17\n",
      "episode: 3319   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.19\n",
      "episode: 3320   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 10.22\n",
      "episode: 3321   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 508    lr: 2.6214400000000017e-08     evaluation reward: 10.27\n",
      "episode: 3322   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.29\n",
      "episode: 3323   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 2.6214400000000017e-08     evaluation reward: 10.29\n",
      "episode: 3324   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 415    lr: 2.6214400000000017e-08     evaluation reward: 10.28\n",
      "episode: 3325   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 419    lr: 2.6214400000000017e-08     evaluation reward: 10.29\n",
      "episode: 3326   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 463    lr: 2.6214400000000017e-08     evaluation reward: 10.3\n",
      "episode: 3327   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 487    lr: 2.6214400000000017e-08     evaluation reward: 10.33\n",
      "episode: 3328   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 415    lr: 2.6214400000000017e-08     evaluation reward: 10.35\n",
      "episode: 3329   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.35\n",
      "episode: 3330   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 449    lr: 2.6214400000000017e-08     evaluation reward: 10.28\n",
      "episode: 3331   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 551    lr: 2.6214400000000017e-08     evaluation reward: 10.29\n",
      "episode: 3332   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 633    lr: 2.6214400000000017e-08     evaluation reward: 10.36\n",
      "episode: 3333   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 450    lr: 2.6214400000000017e-08     evaluation reward: 10.3\n",
      "episode: 3334   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.3\n",
      "episode: 3335   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 488    lr: 2.6214400000000017e-08     evaluation reward: 10.28\n",
      "episode: 3336   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.27\n",
      "episode: 3337   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 503    lr: 2.6214400000000017e-08     evaluation reward: 10.24\n",
      "episode: 3338   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 439    lr: 2.6214400000000017e-08     evaluation reward: 10.24\n",
      "episode: 3339   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 336    lr: 2.6214400000000017e-08     evaluation reward: 10.21\n",
      "episode: 3340   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.19\n",
      "episode: 3341   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     evaluation reward: 10.18\n",
      "episode: 3342   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 518    lr: 2.6214400000000017e-08     evaluation reward: 10.23\n",
      "episode: 3343   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 494    lr: 2.6214400000000017e-08     evaluation reward: 10.22\n",
      "episode: 3344   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 488    lr: 2.6214400000000017e-08     evaluation reward: 10.22\n",
      "episode: 3345   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 2.6214400000000017e-08     evaluation reward: 10.23\n",
      "episode: 3346   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.23\n",
      "episode: 3347   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     evaluation reward: 10.19\n",
      "episode: 3348   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     evaluation reward: 10.16\n",
      "episode: 3349   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 2.6214400000000017e-08     evaluation reward: 10.13\n",
      "episode: 3350   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 10.05\n",
      "episode: 3351   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 487    lr: 2.6214400000000017e-08     evaluation reward: 10.0\n",
      "episode: 3352   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3353   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 390    lr: 2.6214400000000017e-08     evaluation reward: 9.97\n",
      "episode: 3354   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 555    lr: 2.6214400000000017e-08     evaluation reward: 9.96\n",
      "episode: 3355   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 600    lr: 2.6214400000000017e-08     evaluation reward: 9.98\n",
      "episode: 3356   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 529    lr: 2.6214400000000017e-08     evaluation reward: 10.04\n",
      "episode: 3357   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 530    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3358   score: 18.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 730    lr: 2.6214400000000017e-08     evaluation reward: 10.05\n",
      "episode: 3359   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 597    lr: 2.6214400000000017e-08     evaluation reward: 10.11\n",
      "episode: 3360   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 10.06\n",
      "episode: 3361   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     evaluation reward: 10.05\n",
      "episode: 3362   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 9.98\n",
      "episode: 3363   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 581    lr: 2.6214400000000017e-08     evaluation reward: 9.98\n",
      "episode: 3364   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 555    lr: 2.6214400000000017e-08     evaluation reward: 10.0\n",
      "episode: 3365   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 507    lr: 2.6214400000000017e-08     evaluation reward: 10.01\n",
      "episode: 3366   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 610    lr: 2.6214400000000017e-08     evaluation reward: 9.99\n",
      "episode: 3367   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 9.98\n",
      "episode: 3368   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 2.6214400000000017e-08     evaluation reward: 9.9\n",
      "episode: 3369   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 261    lr: 2.6214400000000017e-08     evaluation reward: 9.88\n",
      "episode: 3370   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 353    lr: 2.6214400000000017e-08     evaluation reward: 9.86\n",
      "episode: 3371   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 9.88\n",
      "episode: 3372   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 2.6214400000000017e-08     evaluation reward: 9.88\n",
      "episode: 3373   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 349    lr: 2.6214400000000017e-08     evaluation reward: 9.83\n",
      "episode: 3374   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 2.6214400000000017e-08     evaluation reward: 9.79\n",
      "episode: 3375   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 261    lr: 2.6214400000000017e-08     evaluation reward: 9.7\n",
      "episode: 3376   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 2.6214400000000017e-08     evaluation reward: 9.72\n",
      "episode: 3377   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 2.6214400000000017e-08     evaluation reward: 9.71\n",
      "episode: 3378   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 414    lr: 2.6214400000000017e-08     evaluation reward: 9.67\n",
      "episode: 3379   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 524    lr: 2.6214400000000017e-08     evaluation reward: 9.71\n",
      "episode: 3380   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 558    lr: 2.6214400000000017e-08     evaluation reward: 9.77\n",
      "episode: 3381   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 9.77\n",
      "episode: 3382   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 600    lr: 2.6214400000000017e-08     evaluation reward: 9.8\n",
      "episode: 3383   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 372    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3384   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 459    lr: 2.6214400000000017e-08     evaluation reward: 9.77\n",
      "episode: 3385   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 411    lr: 2.6214400000000017e-08     evaluation reward: 9.77\n",
      "episode: 3386   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 475    lr: 2.6214400000000017e-08     evaluation reward: 9.75\n",
      "episode: 3387   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 508    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3388   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 435    lr: 2.6214400000000017e-08     evaluation reward: 9.74\n",
      "episode: 3389   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 623    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3390   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3391   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 9.77\n",
      "episode: 3392   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 772    lr: 2.6214400000000017e-08     evaluation reward: 9.86\n",
      "episode: 3393   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 650    lr: 2.6214400000000017e-08     evaluation reward: 9.93\n",
      "episode: 3394   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 340    lr: 2.6214400000000017e-08     evaluation reward: 9.92\n",
      "episode: 3395   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 9.86\n",
      "episode: 3396   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 9.83\n",
      "episode: 3397   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 9.76\n",
      "episode: 3398   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 340    lr: 2.6214400000000017e-08     evaluation reward: 9.71\n",
      "episode: 3399   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 460    lr: 2.6214400000000017e-08     evaluation reward: 9.73\n",
      "episode: 3400   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 402    lr: 2.6214400000000017e-08     evaluation reward: 9.73\n",
      "episode: 3401   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 486    lr: 2.6214400000000017e-08     evaluation reward: 9.74\n",
      "episode: 3402   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 9.69\n",
      "episode: 3403   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 440    lr: 2.6214400000000017e-08     evaluation reward: 9.66\n",
      "episode: 3404   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 9.61\n",
      "episode: 3405   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 402    lr: 2.6214400000000017e-08     evaluation reward: 9.6\n",
      "episode: 3406   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 469    lr: 2.6214400000000017e-08     evaluation reward: 9.6\n",
      "episode: 3407   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 2.6214400000000017e-08     evaluation reward: 9.59\n",
      "episode: 3408   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     evaluation reward: 9.55\n",
      "episode: 3409   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 452    lr: 2.6214400000000017e-08     evaluation reward: 9.53\n",
      "episode: 3410   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 500    lr: 2.6214400000000017e-08     evaluation reward: 9.55\n",
      "episode: 3411   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 388    lr: 2.6214400000000017e-08     evaluation reward: 9.55\n",
      "episode: 3412   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 467    lr: 2.6214400000000017e-08     evaluation reward: 9.55\n",
      "episode: 3413   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 515    lr: 2.6214400000000017e-08     evaluation reward: 9.54\n",
      "episode: 3414   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 530    lr: 2.6214400000000017e-08     evaluation reward: 9.55\n",
      "episode: 3415   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 352    lr: 2.6214400000000017e-08     evaluation reward: 9.51\n",
      "episode: 3416   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 9.49\n",
      "episode: 3417   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 402    lr: 2.6214400000000017e-08     evaluation reward: 9.46\n",
      "episode: 3418   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 310    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3419   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 492    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3420   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 310    lr: 2.6214400000000017e-08     evaluation reward: 9.32\n",
      "episode: 3421   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 526    lr: 2.6214400000000017e-08     evaluation reward: 9.31\n",
      "episode: 3422   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 507    lr: 2.6214400000000017e-08     evaluation reward: 9.33\n",
      "episode: 3423   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 547    lr: 2.6214400000000017e-08     evaluation reward: 9.39\n",
      "episode: 3424   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 516    lr: 2.6214400000000017e-08     evaluation reward: 9.42\n",
      "episode: 3425   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 402    lr: 2.6214400000000017e-08     evaluation reward: 9.41\n",
      "episode: 3426   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     evaluation reward: 9.4\n",
      "episode: 3427   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 2.6214400000000017e-08     evaluation reward: 9.37\n",
      "episode: 3428   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 550    lr: 2.6214400000000017e-08     evaluation reward: 9.39\n",
      "episode: 3429   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 568    lr: 2.6214400000000017e-08     evaluation reward: 9.42\n",
      "episode: 3430   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     evaluation reward: 9.41\n",
      "episode: 3431   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 574    lr: 2.6214400000000017e-08     evaluation reward: 9.46\n",
      "episode: 3432   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 9.4\n",
      "episode: 3433   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3434   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 339    lr: 2.6214400000000017e-08     evaluation reward: 9.35\n",
      "episode: 3435   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 611    lr: 2.6214400000000017e-08     evaluation reward: 9.4\n",
      "episode: 3436   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 403    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3437   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3438   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 443    lr: 2.6214400000000017e-08     evaluation reward: 9.42\n",
      "episode: 3439   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.45\n",
      "episode: 3440   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.46\n",
      "episode: 3441   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.47\n",
      "episode: 3442   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 394    lr: 2.6214400000000017e-08     evaluation reward: 9.39\n",
      "episode: 3443   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 527    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3444   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 2.6214400000000017e-08     evaluation reward: 9.39\n",
      "episode: 3445   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 500    lr: 2.6214400000000017e-08     evaluation reward: 9.4\n",
      "episode: 3446   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 568    lr: 2.6214400000000017e-08     evaluation reward: 9.43\n",
      "episode: 3447   score: 20.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 633    lr: 2.6214400000000017e-08     evaluation reward: 9.57\n",
      "episode: 3448   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 639    lr: 2.6214400000000017e-08     evaluation reward: 9.67\n",
      "episode: 3449   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 554    lr: 1.0485760000000008e-08     evaluation reward: 9.73\n",
      "episode: 3450   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 1.0485760000000008e-08     evaluation reward: 9.76\n",
      "episode: 3451   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 1.0485760000000008e-08     evaluation reward: 9.75\n",
      "episode: 3452   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 1.0485760000000008e-08     evaluation reward: 9.78\n",
      "episode: 3453   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 1.0485760000000008e-08     evaluation reward: 9.76\n",
      "episode: 3454   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 455    lr: 1.0485760000000008e-08     evaluation reward: 9.74\n",
      "episode: 3455   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 310    lr: 1.0485760000000008e-08     evaluation reward: 9.64\n",
      "episode: 3456   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 1.0485760000000008e-08     evaluation reward: 9.59\n",
      "episode: 3457   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 544    lr: 1.0485760000000008e-08     evaluation reward: 9.63\n",
      "episode: 3458   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 533    lr: 1.0485760000000008e-08     evaluation reward: 9.6\n",
      "episode: 3459   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 1.0485760000000008e-08     evaluation reward: 9.52\n",
      "episode: 3460   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 666    lr: 1.0485760000000008e-08     evaluation reward: 9.57\n",
      "episode: 3461   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 1.0485760000000008e-08     evaluation reward: 9.55\n",
      "episode: 3462   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 501    lr: 1.0485760000000008e-08     evaluation reward: 9.61\n",
      "episode: 3463   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 1.0485760000000008e-08     evaluation reward: 9.53\n",
      "episode: 3464   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 532    lr: 1.0485760000000008e-08     evaluation reward: 9.53\n",
      "episode: 3465   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.52\n",
      "episode: 3466   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 411    lr: 1.0485760000000008e-08     evaluation reward: 9.47\n",
      "episode: 3467   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 362    lr: 1.0485760000000008e-08     evaluation reward: 9.44\n",
      "episode: 3468   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.46\n",
      "episode: 3469   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.5\n",
      "episode: 3470   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 540    lr: 1.0485760000000008e-08     evaluation reward: 9.6\n",
      "episode: 3471   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 1.0485760000000008e-08     evaluation reward: 9.56\n",
      "episode: 3472   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 1.0485760000000008e-08     evaluation reward: 9.57\n",
      "episode: 3473   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.58\n",
      "episode: 3474   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 1.0485760000000008e-08     evaluation reward: 9.56\n",
      "episode: 3475   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.6\n",
      "episode: 3476   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 477    lr: 1.0485760000000008e-08     evaluation reward: 9.6\n",
      "episode: 3477   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 1.0485760000000008e-08     evaluation reward: 9.58\n",
      "episode: 3478   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 465    lr: 1.0485760000000008e-08     evaluation reward: 9.59\n",
      "episode: 3479   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 1.0485760000000008e-08     evaluation reward: 9.53\n",
      "episode: 3480   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 323    lr: 1.0485760000000008e-08     evaluation reward: 9.46\n",
      "episode: 3481   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 480    lr: 1.0485760000000008e-08     evaluation reward: 9.47\n",
      "episode: 3482   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 1.0485760000000008e-08     evaluation reward: 9.38\n",
      "episode: 3483   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 405    lr: 1.0485760000000008e-08     evaluation reward: 9.4\n",
      "episode: 3484   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 353    lr: 1.0485760000000008e-08     evaluation reward: 9.31\n",
      "episode: 3485   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 1.0485760000000008e-08     evaluation reward: 9.3\n",
      "episode: 3486   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 310    lr: 1.0485760000000008e-08     evaluation reward: 9.25\n",
      "episode: 3487   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 292    lr: 1.0485760000000008e-08     evaluation reward: 9.2\n",
      "episode: 3488   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 530    lr: 1.0485760000000008e-08     evaluation reward: 9.21\n",
      "episode: 3489   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 452    lr: 1.0485760000000008e-08     evaluation reward: 9.16\n",
      "episode: 3490   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 467    lr: 1.0485760000000008e-08     evaluation reward: 9.17\n",
      "episode: 3491   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 624    lr: 1.0485760000000008e-08     evaluation reward: 9.25\n",
      "episode: 3492   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.16\n",
      "episode: 3493   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 310    lr: 1.0485760000000008e-08     evaluation reward: 9.05\n",
      "episode: 3494   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 421    lr: 1.0485760000000008e-08     evaluation reward: 9.07\n",
      "episode: 3495   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 476    lr: 1.0485760000000008e-08     evaluation reward: 9.11\n",
      "episode: 3496   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 411    lr: 1.0485760000000008e-08     evaluation reward: 9.12\n",
      "episode: 3497   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 310    lr: 1.0485760000000008e-08     evaluation reward: 9.11\n",
      "episode: 3498   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 673    lr: 1.0485760000000008e-08     evaluation reward: 9.19\n",
      "episode: 3499   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 427    lr: 1.0485760000000008e-08     evaluation reward: 9.18\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    state = env.reset()[0]\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state, HISTORY_SIZE)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "        state = next_state\n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['lives'])\n",
    "\n",
    "        life = info['lives']\n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 5 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Agent Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n",
    "\n",
    "Please save your model before running this portion of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T10:15:50.270243Z",
     "start_time": "2023-04-22T10:15:50.239472Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T10:38:32.097565Z",
     "start_time": "2023-04-22T10:38:32.056519Z"
    }
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import RecordVideo # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# Displaying the game live\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    \n",
    "# Recording the game and replaying the game afterwards\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, './video', force=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "XStartTimeoutError",
     "evalue": "No reply from program Xvfb. command:['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '300x200x24', '-displayfd', '110']",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mXStartTimeoutError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3652/4224672792.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdisplay\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvisible\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m300\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m200\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdisplay\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Load agent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pyvirtualdisplay/display.py\u001B[0m in \u001B[0;36mstart\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0mrtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \"\"\"\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pyvirtualdisplay/abstractdisplay.py\u001B[0m in \u001B[0;36mstart\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_has_displayfd\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 149\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start1_has_displayfd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    150\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m             \u001B[0mi\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pyvirtualdisplay/abstractdisplay.py\u001B[0m in \u001B[0;36m_start1_has_displayfd\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    195\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muse_pass_fds\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 197\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_wait_for_pipe_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrfd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    198\u001B[0m         \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrfd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m         \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pipe_wfd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pyvirtualdisplay/abstractdisplay.py\u001B[0m in \u001B[0;36m_wait_for_pipe_text\u001B[0;34m(self, rfd)\u001B[0m\n\u001B[1;32m    311\u001B[0m                     % (\n\u001B[1;32m    312\u001B[0m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_program\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 313\u001B[0;31m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_command\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    314\u001B[0m                     )\n\u001B[1;32m    315\u001B[0m                 )\n",
      "\u001B[0;31mXStartTimeoutError\u001B[0m: No reply from program Xvfb. command:['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '300x200x24', '-displayfd', '110']"
     ]
    }
   ],
   "source": [
    "display = Display(visible=0, size=(300, 200))\n",
    "display.start()\n",
    "\n",
    "# Load agent\n",
    "# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n",
    "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "env = wrap_env(env)\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "state = env.reset()\n",
    "next_state = state\n",
    "life = number_lives\n",
    "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "get_init_state(history, state)\n",
    "\n",
    "while not done:\n",
    "    print(\"Step: \", step)\n",
    "    # Render breakout\n",
    "    env.render()\n",
    "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
    "\n",
    "    step += 1\n",
    "    frame += 1\n",
    "\n",
    "    # Perform a fire action if ball is no longer on screen\n",
    "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "    state = next_state\n",
    "    \n",
    "    next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "    frame_next_state = get_frame(next_state)\n",
    "    history[4, :, :] = frame_next_state\n",
    "    terminal_state = check_live(life, info['ale.lives'])\n",
    "        \n",
    "    life = info['ale.lives']\n",
    "    r = np.clip(reward, -1, 1) \n",
    "    r = reward\n",
    "\n",
    "    # Store the transition in memory \n",
    "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "    # Start training after random sample generation\n",
    "    score += reward\n",
    "    \n",
    "    history[:4, :, :] = history[1:, :, :]\n",
    "env.close()\n",
    "show_video()\n",
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
